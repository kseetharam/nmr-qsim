{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test to effectively remove the mixing evolution time from the protocol\n",
    "###Since the precise step at which a dissipative channel is probabilitically sampled during the mixin time does not seem to matter in the quality of the spectrum\n",
    "#we might as well \"commute through\" the dissipative channelt to the end of the T1 time scale or the beginning of the T2 time scale...\n",
    "#and potentially eliminate the need to prpagate \n",
    " \n",
    "import openfermion as of\n",
    "\n",
    "import sys\n",
    "sys.path.append('./utils/')\n",
    "\n",
    "from basis_utils import Sz,Sx,Sz, Sy\n",
    "from basis_utils import read_spinach_info, build_list_ISTs, NormalizeBasis, build_symbolic_list_ISTs, MatRepLib\n",
    "from simulation_utils import GenH0_Ham, HamMatRep, GenNOESYSpectrum, sqcosbell_2d_apod, GenFIDsignals\n",
    "import scipy.io as spio\n",
    "#from \n",
    "from scipy.linalg import expm\n",
    "import cirq\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import savemat\n",
    "import pickle\n",
    "\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize_and_weightOps(ListOps):\n",
    "    \"\"\"\n",
    "    ListOps contains the generators of evolution, either the representation of the coherent part of evolution or the jump operators \n",
    "    \"\"\"\n",
    "    List_weights=[]\n",
    "\n",
    "    for i in range(len(ListOps)):\n",
    "        List_weights.append(np.max(np.abs(np.linalg.eigvals(ListOps[i]))))\n",
    "\n",
    "    #Normalize the operator according to the weights...\n",
    "    Norm_ops =[]\n",
    "\n",
    "    for i in range(len(ListOps)):\n",
    "        Norm_ops.append(ListOps[i]/List_weights[i])\n",
    "\n",
    "    return Norm_ops, List_weights\n",
    "\n",
    "\n",
    "def QDriftChann(List_gens,time_evol):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    List_gens: list of the generators of the time evolution, it is assumed that the first element is H_{0}\n",
    "    list_probs: list of the corresponding probabilities to sample the exponentials of generators\n",
    "    Gamma: sum of the weights of each of the normalized operators\n",
    "    time_evol: the time for which we perform the propagation\n",
    "    \"\"\"\n",
    "\n",
    "    Norm_ops, List_weights = Normalize_and_weightOps(List_gens)\n",
    "\n",
    "    List_weights = np.array(List_weights)\n",
    "    Gamma =  np.sum(List_weights)\n",
    "\n",
    "    pks = (1.0/Gamma)*List_weights\n",
    "\n",
    "    Qdrift_chann = pks[0]*expm(-1j*Norm_ops[0]*time_evol*Gamma)\n",
    "    for i in range(1,len(pks)):\n",
    "        Qdrift_chann = pks[i]*expm(Norm_ops[i]*time_evol*Gamma)\n",
    "\n",
    "    return Qdrift_chann\n",
    "\n",
    "\n",
    "def BuildQDriftChann_fromOps(time_evol,Norm_ops,pks,Gamma):\n",
    "\n",
    "    Qdrift_chann = pks[0]*expm(-1j*Norm_ops[0]*time_evol*Gamma)\n",
    "    for i in range(1,len(pks)):\n",
    "        Qdrift_chann = pks[i]*expm(Norm_ops[i]*time_evol*Gamma)\n",
    "\n",
    "    return Qdrift_chann\n",
    "\n",
    "def QDriftEvol_fromNormOps(Norm_ops,pks,Gamma,time_evol,Nsteps,rho):\n",
    "    \n",
    "    rho_c = np.copy(rho)\n",
    "\n",
    "    if time_evol==0:\n",
    "        chann = np.eye(rho_c.shape[0])\n",
    "    else:\n",
    "        chann= BuildQDriftChann_fromOps(time_evol/Nsteps,Norm_ops,pks,Gamma)\n",
    "\n",
    "    for i in range(Nsteps):\n",
    "        rho_c = chann@rho_c\n",
    "\n",
    "    return rho_c\n",
    "\n",
    "\n",
    "\n",
    "def QDriftEvol(List_gens,time_evol,Nsteps,rho):\n",
    "    \n",
    "    rho_c = np.copy(rho)\n",
    "\n",
    "    if time_evol == 0:\n",
    "        chann = np.eye(rho_c.shape[0])\n",
    "    else:\n",
    "        chann = QDriftChann(List_gens,time_evol/Nsteps)\n",
    "\n",
    "    for i in range(Nsteps):\n",
    "        rho_c = chann@rho_c\n",
    "\n",
    "    return rho_c\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eff_QDriftChann_InitJump_Factorized(List_gens,time_evol,NSteps,U):\n",
    "    \"\"\"\n",
    "    Calculation of an effective QDrift channel. Based on the observation that the action of jump operators are in essence rare events \n",
    "    \"\"\"\n",
    "    Norm_ops, List_weights = Normalize_and_weightOps(List_gens)\n",
    "\n",
    "    List_weights = np.array(List_weights)\n",
    "    Gamma =  np.sum(List_weights)\n",
    "\n",
    "    pks = (1.0/Gamma)*List_weights\n",
    "\n",
    "    Eff_probs = np.zeros(len(List_gens))\n",
    "\n",
    "    Eff_probs[0] = pks[0]**(NSteps) #probability of sampling coherent evolution only\n",
    "\n",
    "    ###We define this channel as the product of two channels: the right one applies the jump operator before the action of the unitary pulse U\n",
    "    omega = time_evol*Gamma/NSteps\n",
    "    Right_chan = pks[0]*expm(-1j*Norm_ops[0]*omega)@U\n",
    "    for k in range(1,len(pks)):\n",
    "        Right_chan+=NSteps*pks[k]*U@expm(omega*np.transpose(np.conjugate(U))@Norm_ops[k]@U)\n",
    "\n",
    "    ##left channel...\n",
    "    Left_chan = pks[0]**(NSteps-1)*expm(-1j*Norm_ops[0]*(NSteps-1)*omega)\n",
    "\n",
    "\n",
    "    return Left_chan, Right_chan\n",
    "\n",
    "\n",
    "def eff_QDriftChann_FinJump_Factorized(List_gens,time_evol,NSteps,U):\n",
    "    \"\"\"\n",
    "    Calculation of an effective QDrift channel. Based on the observation that the action of jump operators are in essence rare events \n",
    "    \"\"\"\n",
    "    Norm_ops, List_weights = Normalize_and_weightOps(List_gens)\n",
    "\n",
    "    List_weights = np.array(List_weights)\n",
    "    Gamma =  np.sum(List_weights)\n",
    "\n",
    "    pks = (1.0/Gamma)*List_weights\n",
    "\n",
    "    Eff_probs = np.zeros(len(List_gens))\n",
    "\n",
    "    Eff_probs[0] = pks[0]**(NSteps) #probability of sampling coherent evolution only\n",
    "\n",
    "    ###We define this channel as the product of two channels: the right one applies the jump operator before the action of the unitary pulse U\n",
    "    omega = time_evol*Gamma/NSteps\n",
    "    Left_chan = pks[0]*U@expm(-1j*Norm_ops[0]*omega)\n",
    "    for k in range(1,len(pks)):\n",
    "        Left_chan+=NSteps*pks[k]*expm(omega*U@Norm_ops[k]@np.conjugate(np.transpose(U)))@U\n",
    "\n",
    "    ##right channel...\n",
    "    Right_chan = pks[0]**(NSteps-1)*expm(-1j*Norm_ops[0]*(NSteps-1)*omega)\n",
    "\n",
    "\n",
    "    return Left_chan, Right_chan\n",
    "\n",
    "\n",
    "def get_last_QDriftJump(List_gens,time_evol,NSteps,U):\n",
    "    \"\"\"\n",
    "    Calculation of an effective QDrift channel. Based on the observation that the action of jump operators are in essence rare events \n",
    "    \"\"\"\n",
    "    Norm_ops, List_weights = Normalize_and_weightOps(List_gens)\n",
    "\n",
    "    List_weights = np.array(List_weights)\n",
    "    Gamma =  np.sum(List_weights)\n",
    "\n",
    "    pks = (1.0/Gamma)*List_weights\n",
    "\n",
    "    #Eff_probs = np.zeros(len(List_gens))\n",
    "\n",
    "    #Eff_probs[0] = pks[0]**(NSteps) #probability of sampling coherent evolution only\n",
    "\n",
    "    ###We define this channel as the product of two channels: the right one applies the jump operator before the action of the unitary pulse U\n",
    "    omega = time_evol*Gamma/NSteps\n",
    "    Left_chan = pks[0]*U@expm(-1j*Norm_ops[0]*omega)\n",
    "    for k in range(1,len(pks)):\n",
    "        Left_chan+=NSteps*pks[k]*expm(omega*U@Norm_ops[k]@np.conjugate(np.transpose(U)))@U\n",
    "\n",
    "    ##right channel...\n",
    "    #Right_chan = pks[0]**(NSteps-1)*expm(-1j*Norm_ops[0]*(NSteps-1)*omega)\n",
    "\n",
    "\n",
    "    return pks[0]**(NSteps-1)*Left_chan\n",
    "\n",
    "\n",
    "\n",
    "def eff_QDriftEndOfProtocol(List_gens,time_evol,NSteps,U):\n",
    "    \"\"\"\n",
    "    Calculation of factors that compose a QDrift-type channel that probabilitically applies a Jump operator at the end of the NOESY protocol \n",
    "    \"\"\"\n",
    "    Norm_ops, List_weights = Normalize_and_weightOps(List_gens)\n",
    "\n",
    "    List_weights = np.array(List_weights)\n",
    "    Gamma =  np.sum(List_weights)\n",
    "\n",
    "    pks = (1.0/Gamma)*List_weights\n",
    "\n",
    "    #Eff_probs = np.zeros(len(List_gens))\n",
    "\n",
    "    #Eff_probs[0] = pks[0]**(NSteps) #probability of sampling coherent evolution only\n",
    "\n",
    "    ###We define this channel as the product of two channels: the right one applies the jump operator before the action of the unitary pulse U\n",
    "    omega = time_evol*Gamma/NSteps\n",
    "    #Left_chan = U@expm(-1j*Norm_ops[0]*omega)@np.conjugate(np.transpose(U))\n",
    "    #Left_chan = pks[0]*U@expm(-1j*Norm_ops[0]*omega)@np.conjugate(np.transpose(U))\n",
    "    #Left_chan = pks[0]*U@expm(-1j*Norm_ops[0]*omega)@np.conjugate(np.transpose(U))\n",
    "    Left_chan = pks[0]*expm(-1j*Norm_ops[0]*omega)\n",
    "#\n",
    "    for k in range(1,len(pks)):\n",
    "        Left_chan+=NSteps*pks[k]*expm(omega*U@Norm_ops[k]@np.conjugate(np.transpose(U)))\n",
    "\n",
    "    ##right channel...\n",
    "    #Right_chan = expm(-1j*Norm_ops[0]*(NSteps-1)*omega)\n",
    "\n",
    "    Right_chan = pks[0]**(NSteps-1)*expm(-1j*Norm_ops[0]*(NSteps-1)*omega)\n",
    "\n",
    "\n",
    "    return Left_chan, Right_chan\n",
    "\n",
    "\n",
    "\n",
    "def GenFID_cohevol(Ham,T1,T2,rho0,coil,tmix,dt1,dt2,Lx,Ly):\n",
    "\n",
    "    #R = sum(List_jumps)\n",
    "\n",
    "    #In this version, we drop the dissipation channels of the evolution during T1 and T2\n",
    "    L_dt1 = expm((-1j*Ham)*dt1)\n",
    "\n",
    "    L_dt2 = expm((-1j*Ham)*dt2)\n",
    "\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    #print(\"Number of Trotter steps for deterministic simulation of T1\",Tpts1)\n",
    "    #print(\"Number of Trotter steps for deterministic simulation of T2\",Tpts2)\n",
    "    #print(\"Number of Trotter steps for QDrift simulation of tmix\", Ntmix)\n",
    "    \n",
    "    #pulse_mix = eff_QDriftChann_OneJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #pulse_mix = eff_QDriftChann_InitJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #QDriftChann([Ham]+List_jumps,tmix)\n",
    "    #for i in range(Ntmix):\n",
    "    #    pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    #print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*tmix)))\n",
    "\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    pulse_mix = expm(-1j*Ham*tmix)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        rho_temp = np.dot(L_dt1,rho_temp)\n",
    "        rho_stack.append(rho_temp)\n",
    "\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        \n",
    "        rho_stack1_1.append(pulse_90y@pulse_mix@pulse_90x@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@pulse_mix@pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90y@pulse_mix@pulse_90mx@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90y@pulse_mix@pulse_90my@rho_stack[i])\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho1 = rho_stack1_1[i]\n",
    "        rho2 = rho_stack1_2[i]\n",
    "        rho3 = rho_stack1_3[i]\n",
    "        rho4 = rho_stack1_4[i]\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1)\n",
    "            rho1 = L_dt2@rho1\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2)\n",
    "            rho2 = L_dt2@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3)\n",
    "            rho3 = L_dt2@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4)\n",
    "            rho4 = L_dt2@rho4\n",
    "    \n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n",
    "\n",
    "\n",
    "def GenFID_cohevol_noJsInTmix(Ham,HamNoJs,T1,T2,rho0,coil,tmix,dt1,dt2,Lx,Ly):\n",
    "\n",
    "    #R = sum(List_jumps)\n",
    "\n",
    "    #In this version, we drop the dissipation channels of the evolution during T1 and T2\n",
    "    L_dt1 = expm((-1j*Ham)*dt1)\n",
    "\n",
    "    L_dt2 = expm((-1j*Ham)*dt2)\n",
    "\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    #print(\"Number of Trotter steps for deterministic simulation of T1\",Tpts1)\n",
    "    #print(\"Number of Trotter steps for deterministic simulation of T2\",Tpts2)\n",
    "    #print(\"Number of Trotter steps for QDrift simulation of tmix\", Ntmix)\n",
    "    \n",
    "    #pulse_mix = eff_QDriftChann_OneJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #pulse_mix = eff_QDriftChann_InitJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #QDriftChann([Ham]+List_jumps,tmix)\n",
    "    #for i in range(Ntmix):\n",
    "    #    pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    #print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*tmix)))\n",
    "\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    pulse_mix = expm(-1j*HamNoJs*tmix)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        rho_temp = np.dot(L_dt1,rho_temp)\n",
    "        rho_stack.append(rho_temp)\n",
    "\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        \n",
    "        rho_stack1_1.append(pulse_90y@pulse_mix@pulse_90x@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@pulse_mix@pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90y@pulse_mix@pulse_90mx@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90y@pulse_mix@pulse_90my@rho_stack[i])\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho1 = rho_stack1_1[i]\n",
    "        rho2 = rho_stack1_2[i]\n",
    "        rho3 = rho_stack1_3[i]\n",
    "        rho4 = rho_stack1_4[i]\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1)\n",
    "            rho1 = L_dt2@rho1\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2)\n",
    "            rho2 = L_dt2@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3)\n",
    "            rho3 = L_dt2@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4)\n",
    "            rho4 = L_dt2@rho4\n",
    "    \n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n",
    "\n",
    "\n",
    "def GenFID_NoTmix_cohT1T2(Ham,List_jumps,T1,T2,rho0,coil,dt1,dt2,Lx,Ly):\n",
    "    \"\"\"\n",
    "    Implement a first-order deterministic Trotter simulation of the FID NOESY signals, to numerically explore optimization of number of Trotter steps needed in the simulation\n",
    "    for a target precision\n",
    "    Args:\n",
    "    Ham: matrix representation of the \"coherent\" part of the Liouvillian superoperator\n",
    "    List_jumps: list of the matrix representation of the jump operators\n",
    "    T1: maximal simulation time for the first phase of the protocol\n",
    "    T2: maximal simulation time for the second phase of the protocol\n",
    "    rho0: initial density matrix vector\n",
    "    coil: vector that represents the obervable we trace over to compute FID\n",
    "    Ntmix: number of samples to drawn in QDrift for the simulation of the system for tmix\n",
    "    \"\"\"\n",
    "    \n",
    "    R = sum(List_jumps)\n",
    "\n",
    "    #In this version, we drop the dissipation channels of the evolution during T1 and T2\n",
    "    L_dt1 = expm((-1j*Ham)*dt1)\n",
    "\n",
    "    L_dt2 = expm((-1j*Ham)*dt2)\n",
    "\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T1\",Tpts1)\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T2\",Tpts2)\n",
    "    #print(\"Number of Trotter steps for QDrift simulation of tmix\", Ntmix)\n",
    "    \n",
    "    #pulse_mix = eff_QDriftChann_OneJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #pulse_mix = eff_QDriftChann_InitJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #QDriftChann([Ham]+List_jumps,tmix)\n",
    "    #for i in range(Ntmix):\n",
    "    #    pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    #print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*tmix)))\n",
    "\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        rho_temp = np.dot(L_dt1,rho_temp)\n",
    "        rho_stack.append(rho_temp)\n",
    "\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        \n",
    "\n",
    "        rho_stack1_1.append(pulse_90y@pulse_90x@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90y@pulse_90mx@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90y@pulse_90my@rho_stack[i])\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho1 = rho_stack1_1[i]\n",
    "        rho2 = rho_stack1_2[i]\n",
    "        rho3 = rho_stack1_3[i]\n",
    "        rho4 = rho_stack1_4[i]\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1)\n",
    "            rho1 = L_dt2@rho1\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2)\n",
    "            rho2 = L_dt2@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3)\n",
    "            rho3 = L_dt2@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4)\n",
    "            rho4 = L_dt2@rho4\n",
    "    \n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n",
    "\n",
    "\n",
    "def GenFID_TmixInitJumpQFact_cohT1T2(Ham,List_jumps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly):\n",
    "    \"\"\"\n",
    "    Implement a first-order deterministic Trotter simulation of the FID NOESY signals, to numerically explore optimization of number of Trotter steps needed in the simulation\n",
    "    for a target precision\n",
    "    Args:\n",
    "    Ham: matrix representation of the \"coherent\" part of the Liouvillian superoperator\n",
    "    List_jumps: list of the matrix representation of the jump operators\n",
    "    T1: maximal simulation time for the first phase of the protocol\n",
    "    T2: maximal simulation time for the second phase of the protocol\n",
    "    rho0: initial density matrix vector\n",
    "    coil: vector that represents the obervable we trace over to compute FID\n",
    "    Ntmix: number of samples to drawn in QDrift for the simulation of the system for tmix\n",
    "    \"\"\"\n",
    "    \n",
    "    R = sum(List_jumps)\n",
    "\n",
    "    #In this version, we drop the dissipation channels of the evolution during T1 and T2\n",
    "    L_dt1 = expm((-1j*Ham)*dt1)\n",
    "\n",
    "    L_dt2 = expm((-1j*Ham)*dt2)\n",
    "\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T1\",Tpts1)\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T2\",Tpts2)\n",
    "    print(\"Number of Trotter steps for QDrift simulation of tmix\", Ntmix)\n",
    "    \n",
    "    #pulse_mix = eff_QDriftChann_OneJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #pulse_mix = eff_QDriftChann_InitJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #QDriftChann([Ham]+List_jumps,tmix)\n",
    "    #for i in range(Ntmix):\n",
    "    #    pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    #print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*tmix)))\n",
    "\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        rho_temp = np.dot(L_dt1,rho_temp)\n",
    "        rho_stack.append(rho_temp)\n",
    "\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    leftmix, rightmix = eff_QDriftChann_InitJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90x)\n",
    "    pulse_mix1 = leftmix@rightmix\n",
    "    leftmix, rightmix = eff_QDriftChann_InitJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90y)\n",
    "    pulse_mix2 = leftmix@rightmix\n",
    "    leftmix,rightmix = eff_QDriftChann_InitJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90mx)\n",
    "    pulse_mix3 = leftmix@rightmix\n",
    "    leftmix,rightmix = eff_QDriftChann_InitJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90my)\n",
    "    pulse_mix4 = leftmix@rightmix\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        \n",
    "\n",
    "        rho_stack1_1.append(pulse_90y@pulse_mix1@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@pulse_mix2@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90y@pulse_mix3@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90y@pulse_mix4@rho_stack[i])\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho1 = rho_stack1_1[i]\n",
    "        rho2 = rho_stack1_2[i]\n",
    "        rho3 = rho_stack1_3[i]\n",
    "        rho4 = rho_stack1_4[i]\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1)\n",
    "            rho1 = L_dt2@rho1\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2)\n",
    "            rho2 = L_dt2@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3)\n",
    "            rho3 = L_dt2@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4)\n",
    "            rho4 = L_dt2@rho4\n",
    "    \n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n",
    "\n",
    "\n",
    "def GenFID_TmixFinJumpQFact_cohT1T2(Ham,List_jumps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly):\n",
    "    \"\"\"\n",
    "    Implement a first-order deterministic Trotter simulation of the FID NOESY signals, to numerically explore optimization of number of Trotter steps needed in the simulation\n",
    "    for a target precision\n",
    "    Args:\n",
    "    Ham: matrix representation of the \"coherent\" part of the Liouvillian superoperator\n",
    "    List_jumps: list of the matrix representation of the jump operators\n",
    "    T1: maximal simulation time for the first phase of the protocol\n",
    "    T2: maximal simulation time for the second phase of the protocol\n",
    "    rho0: initial density matrix vector\n",
    "    coil: vector that represents the obervable we trace over to compute FID\n",
    "    Ntmix: number of samples to drawn in QDrift for the simulation of the system for tmix\n",
    "    \"\"\"\n",
    "    \n",
    "    R = sum(List_jumps)\n",
    "\n",
    "    #In this version, we drop the dissipation channels of the evolution during T1 and T2\n",
    "    L_dt1 = expm((-1j*Ham)*dt1)\n",
    "\n",
    "    L_dt2 = expm((-1j*Ham)*dt2)\n",
    "\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T1\",Tpts1)\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T2\",Tpts2)\n",
    "    print(\"Number of Trotter steps for QDrift simulation of tmix\", Ntmix)\n",
    "    \n",
    "    #pulse_mix = eff_QDriftChann_OneJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #pulse_mix = eff_QDriftChann_InitJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #QDriftChann([Ham]+List_jumps,tmix)\n",
    "    #for i in range(Ntmix):\n",
    "    #    pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    #print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*tmix)))\n",
    "\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        rho_temp = np.dot(L_dt1,rho_temp)\n",
    "        rho_stack.append(rho_temp)\n",
    "\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    #leftmix, rightmix = eff_QDriftChann_FinJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90x)\n",
    "    #pulse_mix1 = leftmix@rightmix\n",
    "    #leftmix, rightmix = eff_QDriftChann_FinJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90y)\n",
    "    #pulse_mix2 = leftmix@rightmix\n",
    "    #leftmix,rightmix = eff_QDriftChann_FinJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90mx)\n",
    "    #pulse_mix3 = leftmix@rightmix\n",
    "    leftmix,rightmix = eff_QDriftChann_FinJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90y)\n",
    "    pulse_mix = leftmix@rightmix\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        \n",
    "\n",
    "        rho_stack1_1.append(pulse_mix@pulse_90x@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_mix@pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_mix@pulse_90mx@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_mix@pulse_90my@rho_stack[i])\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho1 = rho_stack1_1[i]\n",
    "        rho2 = rho_stack1_2[i]\n",
    "        rho3 = rho_stack1_3[i]\n",
    "        rho4 = rho_stack1_4[i]\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1)\n",
    "            rho1 = L_dt2@rho1\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2)\n",
    "            rho2 = L_dt2@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3)\n",
    "            rho3 = L_dt2@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4)\n",
    "            rho4 = L_dt2@rho4\n",
    "    \n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n",
    "\n",
    "def GenFID_RemTmixFinJumpQFact_cohT1T2(Ham,List_jumps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly):\n",
    "    \"\"\"\n",
    "    Implement a first-order deterministic Trotter simulation of the FID NOESY signals, to numerically explore optimization of number of Trotter steps needed in the simulation\n",
    "    for a target precision\n",
    "    Args:\n",
    "    Ham: matrix representation of the \"coherent\" part of the Liouvillian superoperator\n",
    "    List_jumps: list of the matrix representation of the jump operators\n",
    "    T1: maximal simulation time for the first phase of the protocol\n",
    "    T2: maximal simulation time for the second phase of the protocol\n",
    "    rho0: initial density matrix vector\n",
    "    coil: vector that represents the obervable we trace over to compute FID\n",
    "    Ntmix: number of samples to drawn in QDrift for the simulation of the system for tmix\n",
    "    \"\"\"\n",
    "    \n",
    "    R = sum(List_jumps)\n",
    "\n",
    "    #In this version, we drop the dissipation channels of the evolution during T1 and T2\n",
    "    L_dt1 = expm((-1j*Ham)*dt1)\n",
    "\n",
    "    L_dt2 = expm((-1j*Ham)*dt2)\n",
    "\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T1\",Tpts1)\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T2\",Tpts2)\n",
    "    print(\"Number of Trotter steps for QDrift simulation of tmix\", Ntmix)\n",
    "    \n",
    "    #pulse_mix = eff_QDriftChann_OneJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #pulse_mix = eff_QDriftChann_InitJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #QDriftChann([Ham]+List_jumps,tmix)\n",
    "    #for i in range(Ntmix):\n",
    "    #    pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    #print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*tmix)))\n",
    "\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        rho_temp = np.dot(L_dt1,rho_temp)\n",
    "        rho_stack.append(rho_temp)\n",
    "\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    leftmix, rightmix = eff_QDriftChann_FinJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90y)\n",
    "    pulse_mix = leftmix@rightmix\n",
    "    #leftmix, rightmix = eff_QDriftChann_FinJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90y)\n",
    "    #pulse_mix2 = leftmix\n",
    "    #leftmix,rightmix = eff_QDriftChann_FinJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90mx)\n",
    "    #pulse_mix3 = leftmix\n",
    "    #leftmix,rightmix = eff_QDriftChann_FinJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90my)\n",
    "    #pulse_mix4 = leftmix\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        \n",
    "\n",
    "        rho_stack1_1.append(pulse_mix@pulse_90x@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_mix@pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_mix@pulse_90mx@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_mix@pulse_90my@rho_stack[i])\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho1 = rho_stack1_1[i]\n",
    "        rho2 = rho_stack1_2[i]\n",
    "        rho3 = rho_stack1_3[i]\n",
    "        rho4 = rho_stack1_4[i]\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1)\n",
    "            rho1 = L_dt2@rho1\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2)\n",
    "            rho2 = L_dt2@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3)\n",
    "            rho3 = L_dt2@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4)\n",
    "            rho4 = L_dt2@rho4\n",
    "    \n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n",
    "\n",
    "def GenFID_RemTmixInitJumpQFact_cohT1T2(Ham,List_jumps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly):\n",
    "    \"\"\"\n",
    "    Implement a first-order deterministic Trotter simulation of the FID NOESY signals, to numerically explore optimization of number of Trotter steps needed in the simulation\n",
    "    for a target precision\n",
    "    Args:\n",
    "    Ham: matrix representation of the \"coherent\" part of the Liouvillian superoperator\n",
    "    List_jumps: list of the matrix representation of the jump operators\n",
    "    T1: maximal simulation time for the first phase of the protocol\n",
    "    T2: maximal simulation time for the second phase of the protocol\n",
    "    rho0: initial density matrix vector\n",
    "    coil: vector that represents the obervable we trace over to compute FID\n",
    "    Ntmix: number of samples to drawn in QDrift for the simulation of the system for tmix\n",
    "    \"\"\"\n",
    "    \n",
    "    R = sum(List_jumps)\n",
    "\n",
    "    #In this version, we drop the dissipation channels of the evolution during T1 and T2\n",
    "    L_dt1 = expm((-1j*Ham)*dt1)\n",
    "\n",
    "    L_dt2 = expm((-1j*Ham)*dt2)\n",
    "\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T1\",Tpts1)\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T2\",Tpts2)\n",
    "    print(\"Number of Trotter steps for QDrift simulation of tmix\", Ntmix)\n",
    "    \n",
    "    #pulse_mix = eff_QDriftChann_OneJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #pulse_mix = eff_QDriftChann_InitJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #QDriftChann([Ham]+List_jumps,tmix)\n",
    "    #for i in range(Ntmix):\n",
    "    #    pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    #print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*tmix)))\n",
    "\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        rho_temp = np.dot(L_dt1,rho_temp)\n",
    "        rho_stack.append(rho_temp)\n",
    "\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    leftmix, rightmix = eff_QDriftChann_InitJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90x)\n",
    "    pulse_mix1 = rightmix\n",
    "    leftmix, rightmix = eff_QDriftChann_InitJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90y)\n",
    "    pulse_mix2 = rightmix\n",
    "    leftmix,rightmix = eff_QDriftChann_InitJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90mx)\n",
    "    pulse_mix3 = rightmix\n",
    "    leftmix,rightmix = eff_QDriftChann_InitJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90my)\n",
    "    pulse_mix4 = rightmix\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        \n",
    "\n",
    "        rho_stack1_1.append(pulse_90y@pulse_mix1@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@pulse_mix2@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90y@pulse_mix3@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90y@pulse_mix4@rho_stack[i])\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho1 = rho_stack1_1[i]\n",
    "        rho2 = rho_stack1_2[i]\n",
    "        rho3 = rho_stack1_3[i]\n",
    "        rho4 = rho_stack1_4[i]\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1)\n",
    "            rho1 = L_dt2@rho1\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2)\n",
    "            rho2 = L_dt2@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3)\n",
    "            rho3 = L_dt2@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4)\n",
    "            rho4 = L_dt2@rho4\n",
    "    \n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n",
    "\n",
    "\n",
    "def GenFID_JumpEOProtocol_cohT1T2(Ham,List_jumps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly):\n",
    "    \"\"\"\n",
    "    Implement a first-order deterministic Trotter simulation of the FID NOESY signals, to numerically explore optimization of number of Trotter steps needed in the simulation\n",
    "    for a target precision\n",
    "    Args:\n",
    "    Ham: matrix representation of the \"coherent\" part of the Liouvillian superoperator\n",
    "    List_jumps: list of the matrix representation of the jump operators\n",
    "    T1: maximal simulation time for the first phase of the protocol\n",
    "    T2: maximal simulation time for the second phase of the protocol\n",
    "    rho0: initial density matrix vector\n",
    "    coil: vector that represents the obervable we trace over to compute FID\n",
    "    Ntmix: number of samples to drawn in QDrift for the simulation of the system for tmix\n",
    "    \"\"\"\n",
    "    \n",
    "    R = sum(List_jumps)\n",
    "\n",
    "    #In this version, we drop the dissipation channels of the evolution during T1 and T2\n",
    "    L_dt1 = expm((-1j*Ham)*dt1)\n",
    "\n",
    "    L_dt2 = expm((-1j*Ham)*dt2)\n",
    "\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T1\",Tpts1)\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T2\",Tpts2)\n",
    "    print(\"Number of Trotter steps for QDrift simulation of tmix\", Ntmix)\n",
    "    \n",
    "    #pulse_mix = eff_QDriftChann_OneJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #pulse_mix = eff_QDriftChann_InitJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #QDriftChann([Ham]+List_jumps,tmix)\n",
    "    #for i in range(Ntmix):\n",
    "    #    pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    #print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*tmix)))\n",
    "\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        rho_temp = np.dot(L_dt1,rho_temp)\n",
    "        rho_stack.append(rho_temp)\n",
    "\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    \n",
    "    leftmix,rightmix = eff_QDriftEndOfProtocol([Ham]+List_jumps,tmix,Ntmix,pulse_90y)\n",
    "    pulse_mix = rightmix\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        \n",
    "\n",
    "        rho_stack1_1.append(pulse_90y@pulse_mix@pulse_90x@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@pulse_mix@pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90y@pulse_mix@pulse_90mx@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90y@pulse_mix@pulse_90my@rho_stack[i])\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    str = np.floor(Tpts1/10)\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho1 = rho_stack1_1[i]\n",
    "        rho2 = rho_stack1_2[i]\n",
    "        rho3 = rho_stack1_3[i]\n",
    "        rho4 = rho_stack1_4[i]\n",
    "\n",
    "        rho1_buff = np.copy(rho1)\n",
    "        rho2_buff = np.copy(rho2)\n",
    "        rho3_buff = np.copy(rho3)\n",
    "        rho4_buff = np.copy(rho4)\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1)\n",
    "            rho1 = L_dt2@rho1\n",
    "            rho1_buff = leftmix@rho1 #probabilistically apply the jump operator at the end of the protocol\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2)\n",
    "            rho2 = L_dt2@rho2\n",
    "            rho2_buff = leftmix@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3)\n",
    "            rho3 = L_dt2@rho3\n",
    "            rho3_buff = leftmix@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4)\n",
    "            rho4 = L_dt2@rho4\n",
    "            rho4_buff = leftmix@rho4\n",
    "        \n",
    "        if i%str==0:\n",
    "            print(\"Processed \", i, \"out of\", Tpts1, \"points\")\n",
    "\n",
    "\n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4=\"\"\"1      (0,0)   (0,0)   (0,0)   (0,0)   \n",
    "  2      (0,0)   (0,0)   (0,0)   (1,1)   \n",
    "  3      (0,0)   (0,0)   (0,0)   (1,0)   \n",
    "  4      (0,0)   (0,0)   (0,0)   (1,-1)  \n",
    "  5      (0,0)   (0,0)   (1,1)   (0,0)   \n",
    "  6      (0,0)   (0,0)   (1,1)   (1,1)   \n",
    "  7      (0,0)   (0,0)   (1,1)   (1,0)   \n",
    "  8      (0,0)   (0,0)   (1,1)   (1,-1)  \n",
    "  9      (0,0)   (0,0)   (1,0)   (0,0)   \n",
    "  10     (0,0)   (0,0)   (1,0)   (1,1)   \n",
    "  11     (0,0)   (0,0)   (1,0)   (1,0)   \n",
    "  12     (0,0)   (0,0)   (1,0)   (1,-1)  \n",
    "  13     (0,0)   (0,0)   (1,-1)  (0,0)   \n",
    "  14     (0,0)   (0,0)   (1,-1)  (1,1)   \n",
    "  15     (0,0)   (0,0)   (1,-1)  (1,0)   \n",
    "  16     (0,0)   (0,0)   (1,-1)  (1,-1)  \n",
    "  17     (0,0)   (1,1)   (0,0)   (0,0)   \n",
    "  18     (0,0)   (1,1)   (0,0)   (1,1)   \n",
    "  19     (0,0)   (1,1)   (0,0)   (1,0)   \n",
    "  20     (0,0)   (1,1)   (0,0)   (1,-1)  \n",
    "  21     (0,0)   (1,1)   (1,1)   (0,0)   \n",
    "  22     (0,0)   (1,1)   (1,1)   (1,1)   \n",
    "  23     (0,0)   (1,1)   (1,1)   (1,0)   \n",
    "  24     (0,0)   (1,1)   (1,1)   (1,-1)  \n",
    "  25     (0,0)   (1,1)   (1,0)   (0,0)   \n",
    "  26     (0,0)   (1,1)   (1,0)   (1,1)   \n",
    "  27     (0,0)   (1,1)   (1,0)   (1,0)   \n",
    "  28     (0,0)   (1,1)   (1,0)   (1,-1)  \n",
    "  29     (0,0)   (1,1)   (1,-1)  (0,0)   \n",
    "  30     (0,0)   (1,1)   (1,-1)  (1,1)   \n",
    "  31     (0,0)   (1,1)   (1,-1)  (1,0)   \n",
    "  32     (0,0)   (1,1)   (1,-1)  (1,-1)  \n",
    "  33     (0,0)   (1,0)   (0,0)   (0,0)   \n",
    "  34     (0,0)   (1,0)   (0,0)   (1,1)   \n",
    "  35     (0,0)   (1,0)   (0,0)   (1,0)   \n",
    "  36     (0,0)   (1,0)   (0,0)   (1,-1)  \n",
    "  37     (0,0)   (1,0)   (1,1)   (0,0)   \n",
    "  38     (0,0)   (1,0)   (1,1)   (1,1)   \n",
    "  39     (0,0)   (1,0)   (1,1)   (1,0)   \n",
    "  40     (0,0)   (1,0)   (1,1)   (1,-1)  \n",
    "  41     (0,0)   (1,0)   (1,0)   (0,0)   \n",
    "  42     (0,0)   (1,0)   (1,0)   (1,1)   \n",
    "  43     (0,0)   (1,0)   (1,0)   (1,0)   \n",
    "  44     (0,0)   (1,0)   (1,0)   (1,-1)  \n",
    "  45     (0,0)   (1,0)   (1,-1)  (0,0)   \n",
    "  46     (0,0)   (1,0)   (1,-1)  (1,1)   \n",
    "  47     (0,0)   (1,0)   (1,-1)  (1,0)   \n",
    "  48     (0,0)   (1,0)   (1,-1)  (1,-1)  \n",
    "  49     (0,0)   (1,-1)  (0,0)   (0,0)   \n",
    "  50     (0,0)   (1,-1)  (0,0)   (1,1)   \n",
    "  51     (0,0)   (1,-1)  (0,0)   (1,0)   \n",
    "  52     (0,0)   (1,-1)  (0,0)   (1,-1)  \n",
    "  53     (0,0)   (1,-1)  (1,1)   (0,0)   \n",
    "  54     (0,0)   (1,-1)  (1,1)   (1,1)   \n",
    "  55     (0,0)   (1,-1)  (1,1)   (1,0)   \n",
    "  56     (0,0)   (1,-1)  (1,1)   (1,-1)  \n",
    "  57     (0,0)   (1,-1)  (1,0)   (0,0)   \n",
    "  58     (0,0)   (1,-1)  (1,0)   (1,1)   \n",
    "  59     (0,0)   (1,-1)  (1,0)   (1,0)   \n",
    "  60     (0,0)   (1,-1)  (1,0)   (1,-1)  \n",
    "  61     (0,0)   (1,-1)  (1,-1)  (0,0)   \n",
    "  62     (0,0)   (1,-1)  (1,-1)  (1,1)   \n",
    "  63     (0,0)   (1,-1)  (1,-1)  (1,0)   \n",
    "  64     (0,0)   (1,-1)  (1,-1)  (1,-1)  \n",
    "  65     (1,1)   (0,0)   (0,0)   (0,0)   \n",
    "  66     (1,1)   (0,0)   (0,0)   (1,1)   \n",
    "  67     (1,1)   (0,0)   (0,0)   (1,0)   \n",
    "  68     (1,1)   (0,0)   (0,0)   (1,-1)  \n",
    "  69     (1,1)   (0,0)   (1,1)   (0,0)   \n",
    "  70     (1,1)   (0,0)   (1,1)   (1,1)   \n",
    "  71     (1,1)   (0,0)   (1,1)   (1,0)   \n",
    "  72     (1,1)   (0,0)   (1,1)   (1,-1)  \n",
    "  73     (1,1)   (0,0)   (1,0)   (0,0)   \n",
    "  74     (1,1)   (0,0)   (1,0)   (1,1)   \n",
    "  75     (1,1)   (0,0)   (1,0)   (1,0)   \n",
    "  76     (1,1)   (0,0)   (1,0)   (1,-1)  \n",
    "  77     (1,1)   (0,0)   (1,-1)  (0,0)   \n",
    "  78     (1,1)   (0,0)   (1,-1)  (1,1)   \n",
    "  79     (1,1)   (0,0)   (1,-1)  (1,0)   \n",
    "  80     (1,1)   (0,0)   (1,-1)  (1,-1)  \n",
    "  81     (1,1)   (1,1)   (0,0)   (0,0)   \n",
    "  82     (1,1)   (1,1)   (0,0)   (1,1)   \n",
    "  83     (1,1)   (1,1)   (0,0)   (1,0)   \n",
    "  84     (1,1)   (1,1)   (0,0)   (1,-1)  \n",
    "  85     (1,1)   (1,1)   (1,1)   (0,0)   \n",
    "  86     (1,1)   (1,1)   (1,1)   (1,1)   \n",
    "  87     (1,1)   (1,1)   (1,1)   (1,0)   \n",
    "  88     (1,1)   (1,1)   (1,1)   (1,-1)  \n",
    "  89     (1,1)   (1,1)   (1,0)   (0,0)   \n",
    "  90     (1,1)   (1,1)   (1,0)   (1,1)   \n",
    "  91     (1,1)   (1,1)   (1,0)   (1,0)   \n",
    "  92     (1,1)   (1,1)   (1,0)   (1,-1)  \n",
    "  93     (1,1)   (1,1)   (1,-1)  (0,0)   \n",
    "  94     (1,1)   (1,1)   (1,-1)  (1,1)   \n",
    "  95     (1,1)   (1,1)   (1,-1)  (1,0)   \n",
    "  96     (1,1)   (1,1)   (1,-1)  (1,-1)  \n",
    "  97     (1,1)   (1,0)   (0,0)   (0,0)   \n",
    "  98     (1,1)   (1,0)   (0,0)   (1,1)   \n",
    "  99     (1,1)   (1,0)   (0,0)   (1,0)   \n",
    "  100    (1,1)   (1,0)   (0,0)   (1,-1)  \n",
    "  101    (1,1)   (1,0)   (1,1)   (0,0)   \n",
    "  102    (1,1)   (1,0)   (1,1)   (1,1)   \n",
    "  103    (1,1)   (1,0)   (1,1)   (1,0)   \n",
    "  104    (1,1)   (1,0)   (1,1)   (1,-1)  \n",
    "  105    (1,1)   (1,0)   (1,0)   (0,0)   \n",
    "  106    (1,1)   (1,0)   (1,0)   (1,1)   \n",
    "  107    (1,1)   (1,0)   (1,0)   (1,0)   \n",
    "  108    (1,1)   (1,0)   (1,0)   (1,-1)  \n",
    "  109    (1,1)   (1,0)   (1,-1)  (0,0)   \n",
    "  110    (1,1)   (1,0)   (1,-1)  (1,1)   \n",
    "  111    (1,1)   (1,0)   (1,-1)  (1,0)   \n",
    "  112    (1,1)   (1,0)   (1,-1)  (1,-1)  \n",
    "  113    (1,1)   (1,-1)  (0,0)   (0,0)   \n",
    "  114    (1,1)   (1,-1)  (0,0)   (1,1)   \n",
    "  115    (1,1)   (1,-1)  (0,0)   (1,0)   \n",
    "  116    (1,1)   (1,-1)  (0,0)   (1,-1)  \n",
    "  117    (1,1)   (1,-1)  (1,1)   (0,0)   \n",
    "  118    (1,1)   (1,-1)  (1,1)   (1,1)   \n",
    "  119    (1,1)   (1,-1)  (1,1)   (1,0)   \n",
    "  120    (1,1)   (1,-1)  (1,1)   (1,-1)  \n",
    "  121    (1,1)   (1,-1)  (1,0)   (0,0)   \n",
    "  122    (1,1)   (1,-1)  (1,0)   (1,1)   \n",
    "  123    (1,1)   (1,-1)  (1,0)   (1,0)   \n",
    "  124    (1,1)   (1,-1)  (1,0)   (1,-1)  \n",
    "  125    (1,1)   (1,-1)  (1,-1)  (0,0)   \n",
    "  126    (1,1)   (1,-1)  (1,-1)  (1,1)   \n",
    "  127    (1,1)   (1,-1)  (1,-1)  (1,0)   \n",
    "  128    (1,1)   (1,-1)  (1,-1)  (1,-1)  \n",
    "  129    (1,0)   (0,0)   (0,0)   (0,0)   \n",
    "  130    (1,0)   (0,0)   (0,0)   (1,1)   \n",
    "  131    (1,0)   (0,0)   (0,0)   (1,0)   \n",
    "  132    (1,0)   (0,0)   (0,0)   (1,-1)  \n",
    "  133    (1,0)   (0,0)   (1,1)   (0,0)   \n",
    "  134    (1,0)   (0,0)   (1,1)   (1,1)   \n",
    "  135    (1,0)   (0,0)   (1,1)   (1,0)   \n",
    "  136    (1,0)   (0,0)   (1,1)   (1,-1)  \n",
    "  137    (1,0)   (0,0)   (1,0)   (0,0)   \n",
    "  138    (1,0)   (0,0)   (1,0)   (1,1)   \n",
    "  139    (1,0)   (0,0)   (1,0)   (1,0)   \n",
    "  140    (1,0)   (0,0)   (1,0)   (1,-1)  \n",
    "  141    (1,0)   (0,0)   (1,-1)  (0,0)   \n",
    "  142    (1,0)   (0,0)   (1,-1)  (1,1)   \n",
    "  143    (1,0)   (0,0)   (1,-1)  (1,0)   \n",
    "  144    (1,0)   (0,0)   (1,-1)  (1,-1)  \n",
    "  145    (1,0)   (1,1)   (0,0)   (0,0)   \n",
    "  146    (1,0)   (1,1)   (0,0)   (1,1)   \n",
    "  147    (1,0)   (1,1)   (0,0)   (1,0)   \n",
    "  148    (1,0)   (1,1)   (0,0)   (1,-1)  \n",
    "  149    (1,0)   (1,1)   (1,1)   (0,0)   \n",
    "  150    (1,0)   (1,1)   (1,1)   (1,1)   \n",
    "  151    (1,0)   (1,1)   (1,1)   (1,0)   \n",
    "  152    (1,0)   (1,1)   (1,1)   (1,-1)  \n",
    "  153    (1,0)   (1,1)   (1,0)   (0,0)   \n",
    "  154    (1,0)   (1,1)   (1,0)   (1,1)   \n",
    "  155    (1,0)   (1,1)   (1,0)   (1,0)   \n",
    "  156    (1,0)   (1,1)   (1,0)   (1,-1)  \n",
    "  157    (1,0)   (1,1)   (1,-1)  (0,0)   \n",
    "  158    (1,0)   (1,1)   (1,-1)  (1,1)   \n",
    "  159    (1,0)   (1,1)   (1,-1)  (1,0)   \n",
    "  160    (1,0)   (1,1)   (1,-1)  (1,-1)  \n",
    "  161    (1,0)   (1,0)   (0,0)   (0,0)   \n",
    "  162    (1,0)   (1,0)   (0,0)   (1,1)   \n",
    "  163    (1,0)   (1,0)   (0,0)   (1,0)   \n",
    "  164    (1,0)   (1,0)   (0,0)   (1,-1)  \n",
    "  165    (1,0)   (1,0)   (1,1)   (0,0)   \n",
    "  166    (1,0)   (1,0)   (1,1)   (1,1)   \n",
    "  167    (1,0)   (1,0)   (1,1)   (1,0)   \n",
    "  168    (1,0)   (1,0)   (1,1)   (1,-1)  \n",
    "  169    (1,0)   (1,0)   (1,0)   (0,0)   \n",
    "  170    (1,0)   (1,0)   (1,0)   (1,1)   \n",
    "  171    (1,0)   (1,0)   (1,0)   (1,0)   \n",
    "  172    (1,0)   (1,0)   (1,0)   (1,-1)  \n",
    "  173    (1,0)   (1,0)   (1,-1)  (0,0)   \n",
    "  174    (1,0)   (1,0)   (1,-1)  (1,1)   \n",
    "  175    (1,0)   (1,0)   (1,-1)  (1,0)   \n",
    "  176    (1,0)   (1,0)   (1,-1)  (1,-1)  \n",
    "  177    (1,0)   (1,-1)  (0,0)   (0,0)   \n",
    "  178    (1,0)   (1,-1)  (0,0)   (1,1)   \n",
    "  179    (1,0)   (1,-1)  (0,0)   (1,0)   \n",
    "  180    (1,0)   (1,-1)  (0,0)   (1,-1)  \n",
    "  181    (1,0)   (1,-1)  (1,1)   (0,0)   \n",
    "  182    (1,0)   (1,-1)  (1,1)   (1,1)   \n",
    "  183    (1,0)   (1,-1)  (1,1)   (1,0)   \n",
    "  184    (1,0)   (1,-1)  (1,1)   (1,-1)  \n",
    "  185    (1,0)   (1,-1)  (1,0)   (0,0)   \n",
    "  186    (1,0)   (1,-1)  (1,0)   (1,1)   \n",
    "  187    (1,0)   (1,-1)  (1,0)   (1,0)   \n",
    "  188    (1,0)   (1,-1)  (1,0)   (1,-1)  \n",
    "  189    (1,0)   (1,-1)  (1,-1)  (0,0)   \n",
    "  190    (1,0)   (1,-1)  (1,-1)  (1,1)   \n",
    "  191    (1,0)   (1,-1)  (1,-1)  (1,0)   \n",
    "  192    (1,0)   (1,-1)  (1,-1)  (1,-1)  \n",
    "  193    (1,-1)  (0,0)   (0,0)   (0,0)   \n",
    "  194    (1,-1)  (0,0)   (0,0)   (1,1)   \n",
    "  195    (1,-1)  (0,0)   (0,0)   (1,0)   \n",
    "  196    (1,-1)  (0,0)   (0,0)   (1,-1)  \n",
    "  197    (1,-1)  (0,0)   (1,1)   (0,0)   \n",
    "  198    (1,-1)  (0,0)   (1,1)   (1,1)   \n",
    "  199    (1,-1)  (0,0)   (1,1)   (1,0)   \n",
    "  200    (1,-1)  (0,0)   (1,1)   (1,-1)  \n",
    "  201    (1,-1)  (0,0)   (1,0)   (0,0)   \n",
    "  202    (1,-1)  (0,0)   (1,0)   (1,1)   \n",
    "  203    (1,-1)  (0,0)   (1,0)   (1,0)   \n",
    "  204    (1,-1)  (0,0)   (1,0)   (1,-1)  \n",
    "  205    (1,-1)  (0,0)   (1,-1)  (0,0)   \n",
    "  206    (1,-1)  (0,0)   (1,-1)  (1,1)   \n",
    "  207    (1,-1)  (0,0)   (1,-1)  (1,0)   \n",
    "  208    (1,-1)  (0,0)   (1,-1)  (1,-1)  \n",
    "  209    (1,-1)  (1,1)   (0,0)   (0,0)   \n",
    "  210    (1,-1)  (1,1)   (0,0)   (1,1)   \n",
    "  211    (1,-1)  (1,1)   (0,0)   (1,0)   \n",
    "  212    (1,-1)  (1,1)   (0,0)   (1,-1)  \n",
    "  213    (1,-1)  (1,1)   (1,1)   (0,0)   \n",
    "  214    (1,-1)  (1,1)   (1,1)   (1,1)   \n",
    "  215    (1,-1)  (1,1)   (1,1)   (1,0)   \n",
    "  216    (1,-1)  (1,1)   (1,1)   (1,-1)  \n",
    "  217    (1,-1)  (1,1)   (1,0)   (0,0)   \n",
    "  218    (1,-1)  (1,1)   (1,0)   (1,1)   \n",
    "  219    (1,-1)  (1,1)   (1,0)   (1,0)   \n",
    "  220    (1,-1)  (1,1)   (1,0)   (1,-1)  \n",
    "  221    (1,-1)  (1,1)   (1,-1)  (0,0)   \n",
    "  222    (1,-1)  (1,1)   (1,-1)  (1,1)   \n",
    "  223    (1,-1)  (1,1)   (1,-1)  (1,0)   \n",
    "  224    (1,-1)  (1,1)   (1,-1)  (1,-1)  \n",
    "  225    (1,-1)  (1,0)   (0,0)   (0,0)   \n",
    "  226    (1,-1)  (1,0)   (0,0)   (1,1)   \n",
    "  227    (1,-1)  (1,0)   (0,0)   (1,0)   \n",
    "  228    (1,-1)  (1,0)   (0,0)   (1,-1)  \n",
    "  229    (1,-1)  (1,0)   (1,1)   (0,0)   \n",
    "  230    (1,-1)  (1,0)   (1,1)   (1,1)   \n",
    "  231    (1,-1)  (1,0)   (1,1)   (1,0)   \n",
    "  232    (1,-1)  (1,0)   (1,1)   (1,-1)  \n",
    "  233    (1,-1)  (1,0)   (1,0)   (0,0)   \n",
    "  234    (1,-1)  (1,0)   (1,0)   (1,1)   \n",
    "  235    (1,-1)  (1,0)   (1,0)   (1,0)   \n",
    "  236    (1,-1)  (1,0)   (1,0)   (1,-1)  \n",
    "  237    (1,-1)  (1,0)   (1,-1)  (0,0)   \n",
    "  238    (1,-1)  (1,0)   (1,-1)  (1,1)   \n",
    "  239    (1,-1)  (1,0)   (1,-1)  (1,0)   \n",
    "  240    (1,-1)  (1,0)   (1,-1)  (1,-1)  \n",
    "  241    (1,-1)  (1,-1)  (0,0)   (0,0)   \n",
    "  242    (1,-1)  (1,-1)  (0,0)   (1,1)   \n",
    "  243    (1,-1)  (1,-1)  (0,0)   (1,0)   \n",
    "  244    (1,-1)  (1,-1)  (0,0)   (1,-1)  \n",
    "  245    (1,-1)  (1,-1)  (1,1)   (0,0)   \n",
    "  246    (1,-1)  (1,-1)  (1,1)   (1,1)   \n",
    "  247    (1,-1)  (1,-1)  (1,1)   (1,0)   \n",
    "  248    (1,-1)  (1,-1)  (1,1)   (1,-1)  \n",
    "  249    (1,-1)  (1,-1)  (1,0)   (0,0)   \n",
    "  250    (1,-1)  (1,-1)  (1,0)   (1,1)   \n",
    "  251    (1,-1)  (1,-1)  (1,0)   (1,0)   \n",
    "  252    (1,-1)  (1,-1)  (1,0)   (1,-1)  \n",
    "  253    (1,-1)  (1,-1)  (1,-1)  (0,0)   \n",
    "  254    (1,-1)  (1,-1)  (1,-1)  (1,1)   \n",
    "  255    (1,-1)  (1,-1)  (1,-1)  (1,0)   \n",
    "  256    (1,-1)  (1,-1)  (1,-1)  (1,-1)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ala = read_spinach_info(text4)\n",
    "\n",
    "basis_ala = build_list_ISTs(data_ala)\n",
    "prefacts,Symb_ALA_basis = build_symbolic_list_ISTs(data_ala)\n",
    "\n",
    "#Normbasis = NormalizeBasis(basis,n_qubits=4,checkOrth=True) I have verified the orthonormalization of the basis\n",
    "Normbasis_ala = NormalizeBasis(basis_ala,n_qubits=4,checkOrth=False)\n",
    "Normbasis_ala = np.array(Normbasis_ala)\n",
    "\n",
    "f = open('./data/ALA_JOps.pk','rb')\n",
    "dat = pickle.load(f)\n",
    "\n",
    "JumpOps = dat['JOps']\n",
    "\n",
    "Rtrunc = sum(JumpOps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/3325980156.py:180: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_1[j,i] = np.dot(coil,rho1)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/3325980156.py:183: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_2[j,i] = np.dot(coil,rho2)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/3325980156.py:186: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_3[j,i] = np.dot(coil,rho3)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/3325980156.py:189: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_4[j,i] = np.dot(coil,rho4)\n"
     ]
    }
   ],
   "source": [
    "loadMat = spio.loadmat('./data/NOESYdata_ALA_withGradients.mat',squeeze_me=True)\n",
    "\n",
    "t_grid1 = loadMat['p']['time_grid1'].item()\n",
    "t_grid2 = loadMat['p']['time_grid2'].item()\n",
    "\n",
    "R_ala = loadMat['p']['R'].item()\n",
    "H_ala = loadMat['p']['H'].item().toarray()\n",
    "\n",
    "rho0 = np.array(loadMat['p']['rho0'].item().toarray())\n",
    "\n",
    "coil = np.array(loadMat['p']['coil'].item())\n",
    "\n",
    "Lx = loadMat['p']['Lx'].item().toarray() \n",
    "Ly = loadMat['p']['Ly'].item().toarray() \n",
    "\n",
    "###Dynamical evolution for calculation of 2D spectra...\n",
    "#Tpts1 = len(t_grid1)\n",
    "#Tpts2 = len(t_grid2)\n",
    "\n",
    "#Parameters taken from Spinach script\n",
    "tmix = 1.0\n",
    "dt1 = 5e-4\n",
    "dt2 = 5e-4\n",
    "#dt1 = 0.00512\n",
    "#dt2 = 0.00512\n",
    "Tpts1 = 512\n",
    "Tpts2 = 512\n",
    "\n",
    "T1 = Tpts1*dt1\n",
    "T2 = Tpts2*dt2\n",
    "\n",
    "Ntmix = 2631\n",
    "####Generation of the different FIDs that consider the commutation through of the single jump operator either to the T1 or T2 timescales of the protocol; and the effective elimination of the \n",
    "# mixing time \n",
    "\n",
    "#fid1_JtoT1, fid2_JtoT1, fid3_JtoT1, fid4_JtoT1 = GenFID_TmixInitJumpQFact_cohT1T2(H_ala,JumpOps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly)\n",
    "\n",
    "#fid1_JtoT2, fid2_JtoT2, fid3_JtoT2, fid4_JtoT2 = GenFID_TmixFinJumpQFact_cohT1T2(H_ala,JumpOps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly)\n",
    "\n",
    "#fid1_JtoT1Rem, fid2_JtoT1Rem, fid3_JtoT1Rem, fid4_JtoT1Rem = GenFID_RemTmixInitJumpQFact_cohT1T2(H_ala,JumpOps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly)\n",
    "\n",
    "#fid1_JtoT2Rem, fid2_JtoT2Rem, fid3_JtoT2Rem, fid4_JtoT2Rem = GenFID_RemTmixFinJumpQFact_cohT1T2(H_ala,JumpOps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly)\n",
    "\n",
    "#fid1_noTmix, fid2_noTmix, fid3_noTmix, fid4_noTmix = GenFID_NoTmix_cohT1T2(H_ala,JumpOps,T1,T2,rho0,coil,dt1,dt2,Lx,Ly)\n",
    "\n",
    "fid1_coh, fid2_coh, fid3_coh, fid4_coh = GenFID_cohevol(H_ala,T1,T2,rho0,coil,tmix,dt1,dt2,Lx,Ly)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.549086109702331-5.96404801196445e-16j)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "\n",
    "rho_t1 = expm(-1j*H_ala*0.256)@pulse_90x@rho0.flatten()\n",
    "#rho_t1 = pulse_90x@rho0.flatten()\n",
    "\n",
    "np.vdot(rho0,pulse_90mx@rho_t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cos_fid = fid1_coh - fid3_coh\n",
    "sin_fid = fid2_coh - fid4_coh\n",
    "\n",
    "savemat('ALA_truncR_FIDcos_coh.mat', {'FID_cos': cos_fid})\n",
    "savemat('ALA_truncR_FIDsin_coh.mat', {'FID_sin': sin_fid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_fid = fid1_noTmix - fid3_noTmix\n",
    "sin_fid = fid2_noTmix - fid4_noTmix\n",
    "\n",
    "savemat('ALA_truncR_FIDcos_noTmix.mat', {'FID_cos': cos_fid})\n",
    "savemat('ALA_truncR_FIDsin_noTmix.mat', {'FID_sin': sin_fid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Saving for postprocessing in Matlab\n",
    "cos_fid = fid1_JtoT1 - fid3_JtoT1\n",
    "sin_fid = fid2_JtoT1 - fid4_JtoT1\n",
    "\n",
    "savemat('ALA_truncR_FIDcos_JtoT1.mat', {'FID_cos': cos_fid})\n",
    "savemat('ALA_truncR_FIDsin_JtoT1.mat', {'FID_sin': sin_fid})\n",
    "\n",
    "\n",
    "cos_fid = fid1_JtoT2 - fid3_JtoT2\n",
    "sin_fid = fid2_JtoT2 - fid4_JtoT2\n",
    "\n",
    "savemat('ALA_truncR_FIDcos_JtoT2.mat', {'FID_cos': cos_fid})\n",
    "savemat('ALA_truncR_FIDsin_JtoT2.mat', {'FID_sin': sin_fid})\n",
    "\n",
    "cos_fid = fid1_JtoT1Rem - fid3_JtoT1Rem\n",
    "sin_fid = fid2_JtoT1Rem - fid4_JtoT1Rem\n",
    "\n",
    "savemat('ALA_truncR_FIDcos_JtoT1Rem.mat', {'FID_cos': cos_fid})\n",
    "savemat('ALA_truncR_FIDsin_JtoT1Rem.mat', {'FID_sin': sin_fid})\n",
    "\n",
    "cos_fid = fid1_JtoT2Rem - fid3_JtoT2Rem\n",
    "sin_fid = fid2_JtoT2Rem - fid4_JtoT2Rem\n",
    "\n",
    "savemat('ALA_truncR_FIDcos_JtoT2Rem.mat', {'FID_cos': cos_fid})\n",
    "savemat('ALA_truncR_FIDsin_JtoT2Rem.mat', {'FID_sin': sin_fid})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trotter steps for deterministic simulation of T1 512\n",
      "Number of Trotter steps for deterministic simulation of T2 512\n",
      "Number of Trotter steps for QDrift simulation of tmix 2631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/2125240492.py:716: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_1[j,i] = np.dot(coil,rho1)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/2125240492.py:720: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_2[j,i] = np.dot(coil,rho2)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/2125240492.py:724: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_3[j,i] = np.dot(coil,rho3)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/2125240492.py:728: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_4[j,i] = np.dot(coil,rho4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed  0 out of 512 points\n",
      "Processed  51 out of 512 points\n",
      "Processed  102 out of 512 points\n",
      "Processed  153 out of 512 points\n",
      "Processed  204 out of 512 points\n",
      "Processed  255 out of 512 points\n",
      "Processed  306 out of 512 points\n",
      "Processed  357 out of 512 points\n",
      "Processed  408 out of 512 points\n",
      "Processed  459 out of 512 points\n",
      "Processed  510 out of 512 points\n"
     ]
    }
   ],
   "source": [
    "####The \"commutation through\" of the jump operator to T1 does not affect the spectrum (in principle, it must be exactly the same, but I noticed a small change in a few signals)\n",
    "\n",
    "#Subsequent elimination of the mixing time leads to qualitative changes, which is consistent with eliminating the mixing time altogether of the protocol\n",
    "\n",
    "#TODO: obtain the FID signals that come out from the probabilistic application of the jump operator at the end of the signal...\n",
    "fid1_J_EOP,fid2_J_EOP,fid3_J_EOP,fid4_J_EOP =GenFID_JumpEOProtocol_cohT1T2(H_ala,JumpOps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_fid = fid1_J_EOP - fid3_J_EOP\n",
    "sin_fid = fid2_J_EOP - fid4_J_EOP\n",
    "\n",
    "savemat('ALA_truncR_FIDcos_J_EOP.mat', {'FID_cos': cos_fid})\n",
    "savemat('ALA_truncR_FIDsin_J_EOP.mat', {'FID_sin': sin_fid})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning off J couplings of the Hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadMat = spio.loadmat('../matlab_analysis/NOESYdata_ALA_NoJs.mat',squeeze_me=True)\n",
    "\n",
    "\n",
    "H_ala_noJs = loadMat['p']['H'].item().toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/3325980156.py:265: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_1[j,i] = np.dot(coil,rho1)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/3325980156.py:268: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_2[j,i] = np.dot(coil,rho2)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/3325980156.py:271: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_3[j,i] = np.dot(coil,rho3)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/3325980156.py:274: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_4[j,i] = np.dot(coil,rho4)\n"
     ]
    }
   ],
   "source": [
    "fid1_noJs, fid2_noJs, fid3_noJs, fid4_noJs =  GenFID_cohevol_noJsInTmix(H_ala,H_ala_noJs,T1,T2,rho0,coil,tmix,dt1,dt2,Lx,Ly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_fid = fid1_noJs - fid3_noJs\n",
    "sin_fid = fid2_noJs - fid4_noJs\n",
    "\n",
    "savemat('ALA_truncR_FIDcos_TmixNoJs.mat', {'FID_cos': cos_fid})\n",
    "savemat('ALA_truncR_FIDsin_TmixNoJs.mat', {'FID_sin': sin_fid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1700.6811411997246"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(H_ala-H_ala_noJs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/3325980156.py:265: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_1[j,i] = np.dot(coil,rho1)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/3325980156.py:268: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_2[j,i] = np.dot(coil,rho2)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/3325980156.py:271: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_3[j,i] = np.dot(coil,rho3)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_25765/3325980156.py:274: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_4[j,i] = np.dot(coil,rho4)\n"
     ]
    }
   ],
   "source": [
    "fid1_allNoJs,fid2_allNoJs, fid3_allNoJs, fid4_allNoJs = GenFID_cohevol_noJsInTmix(H_ala_noJs,H_ala_noJs,T1,T2,rho0,coil,tmix,dt1,dt2,Lx,Ly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_fid = fid1_allNoJs - fid3_allNoJs\n",
    "sin_fid = fid2_allNoJs - fid4_allNoJs\n",
    "\n",
    "savemat('ALA_truncR_FIDcos_AllNoJs.mat', {'FID_cos': cos_fid})\n",
    "savemat('ALA_truncR_FIDsin_AllNoJs.mat', {'FID_sin': sin_fid})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inclusion of field gradient in the calculations and using updated Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a low frequency resolution experiment, where the effect of J-couplings cannot be resolved, the conjecture is that we can prescind from the mixing time phase \n",
    "# during the NOESY protocol. To prove this, we can simply implement a gradient field protocol in the spectrum and compare the results of the simulation when including or\n",
    "#eliminating the mixing time, (do we also need to include the J couplings during t1 and t2? It seems this is the case, as omitting J couplings during these timescales eliminates cross-peaks)\n",
    "#From this we infer that the scalar couplings induce magnetization transfer between spins during t1 and t2 timescales\n",
    "\n",
    "\"\"\"\n",
    "def FieldGrad(Npts_grad,rho_stack,dim,Lz):\n",
    "    \n",
    "    Inclusion of magnetic field gradient in the simulation. Warning: it modifies and returns the rho_stack array\n",
    "    \n",
    "\n",
    "    phi = np.linspace(0,2*np.pi,Npts_grad)\n",
    "\n",
    "    gradmat = np.zeros(dim,dim,Npts_grad)\n",
    "\n",
    "    for k in range(Npts_grad):\n",
    "        gradmat[:,:,k] = expm(-1j*Lz*phi[k])\n",
    "\n",
    "\n",
    "    for j in range(rho_stack.shape[1]): #iterating over the number of time points....\n",
    "        rho_temp = rho_stack[:,j,0]\n",
    "        rho_sum = 0\n",
    "        for i in range(Npts_grad):\n",
    "            rho_sum = rho_sum + gradmat[:,:,i]@rho_temp\n",
    "\n",
    "        rho_sum = rho_sum/Npts_grad\n",
    "        rho_stack[:,j,0] = rho_sum\n",
    "\n",
    "        rho_temp = rho_stack[:,j,1]\n",
    "        rho_sum = 0\n",
    "        for i in range(Npts_grad):\n",
    "            rho_sum = rho_sum + gradmat[:,:,i]@rho_temp\n",
    "\n",
    "        rho_sum = rho_sum/Npts_grad\n",
    "        rho_stack[:,j,1] = rho_sum\n",
    "\n",
    "        rho_temp = rho_stack[:,j,2]\n",
    "        rho_sum = 0\n",
    "        for i in range(Npts_grad):\n",
    "            rho_sum = rho_sum + gradmat[:,:,i]@rho_temp\n",
    "\n",
    "        rho_sum = rho_sum/Npts_grad\n",
    "        rho_stack[:,j,2] = rho_sum\n",
    "\n",
    "        rho_temp = rho_stack[:,j,3]\n",
    "        rho_sum = 0\n",
    "        for i in range(Npts_grad):\n",
    "            rho_sum = rho_sum + gradmat[:,:,i]@rho_temp\n",
    "\n",
    "        rho_sum = rho_sum/Npts_grad\n",
    "        rho_stack[:,j,3] = rho_sum\n",
    "\n",
    "    return rho_stack\n",
    "\"\"\"\n",
    "\n",
    "def FieldGrad(Npts_grad,rho_stack,dim,Lz):\n",
    "    \"\"\" \n",
    "    Inclusion of magnetic field gradient in the simulation. Warning: it modifies and returns the rho_stack array\n",
    "    \"\"\"\n",
    "\n",
    "    phi = np.linspace(0,2*np.pi,Npts_grad)\n",
    "\n",
    "    gradmat = np.zeros([dim,dim,Npts_grad],dtype=complex)\n",
    "\n",
    "    for k in range(Npts_grad):\n",
    "        gradmat[:,:,k] = expm(-1j*Lz*phi[k])\n",
    "\n",
    "\n",
    "    for j in range(len(rho_stack)): #iterating over the number of time points....\n",
    "        rho_temp = rho_stack[j]\n",
    "        rho_sum = 0\n",
    "        for i in range(Npts_grad):\n",
    "            rho_sum = rho_sum + gradmat[:,:,i]@rho_temp\n",
    "\n",
    "        rho_sum = rho_sum/Npts_grad\n",
    "        rho_stack[j] = rho_sum\n",
    "\n",
    "\n",
    "    return rho_stack\n",
    "\n",
    "###TODO: test this function....\n",
    "def GenFID_cohevol_GradField(Ham,T1,T2,rho0,coil,tmix,dt1,dt2,Lx,Ly,Lz):\n",
    "    \"\"\"\n",
    "    Implement a first-order deterministic Trotter simulation of the FID NOESY signals, to numerically explore optimization of number of Trotter steps needed in the simulation\n",
    "    for a target precision\n",
    "    Args:\n",
    "    Ham: matrix representation of the \"coherent\" part of the Liouvillian superoperator\n",
    "    List_jumps: list of the matrix representation of the jump operators\n",
    "    T1: maximal simulation time for the first phase of the protocol\n",
    "    T2: maximal simulation time for the second phase of the protocol\n",
    "    rho0: initial density matrix vector\n",
    "    coil: vector that represents the obervable we trace over to compute FID\n",
    "    Ntmix: number of samples to drawn in QDrift for the simulation of the system for tmix\n",
    "    \"\"\"\n",
    "    rho0 = rho0.flatten()\n",
    "\n",
    "    Npts_grad = 100\n",
    "    dim = rho0.shape[0]\n",
    "    \n",
    "    #R = sum(List_jumps)\n",
    "\n",
    "    #In this version, we drop the dissipation channels of the evolution during T1 and T2\n",
    "    L_dt1 = expm((-1j*Ham)*dt1)\n",
    "\n",
    "    L_dt2 = expm((-1j*Ham)*dt2)\n",
    "\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    print(\"Number of points for simulation of T1\",Tpts1)\n",
    "    print(\"Number of points for simulation of T2\",Tpts2)\n",
    "    #print(\"Number of Trotter steps for QDrift simulation of tmix\", Ntmix)\n",
    "    \n",
    "    #pulse_mix = eff_QDriftChann_OneJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #pulse_mix = eff_QDriftChann_InitJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #QDriftChann([Ham]+List_jumps,tmix)\n",
    "    #for i in range(Ntmix):\n",
    "    #    pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    #print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*tmix)))\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        rho_temp = np.dot(L_dt1,rho_temp)\n",
    "        rho_stack.append(rho_temp)\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    #TODO: change this accordingly to include dissipation....\n",
    "    #leftmix,rightmix = eff_QDriftChann_FinJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90y)\n",
    "    #pulse_mix = leftmix@rightmix\n",
    "    pulse_mix = expm(-1j*Ham*tmix)\n",
    "\n",
    "\n",
    "    ###Aplication of second 90 deg pulse\n",
    "\n",
    "    print(\"Application of second 90 deg pulse\")\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1.append(pulse_90x@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90mx@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90my@rho_stack[i])\n",
    "\n",
    "\n",
    "    #####Aplication of gradient...\n",
    "    rho_stack1_1 = FieldGrad(Npts_grad,rho_stack1_1,dim,Lz)\n",
    "    rho_stack1_2 = FieldGrad(Npts_grad,rho_stack1_2,dim,Lz)\n",
    "    rho_stack1_3 = FieldGrad(Npts_grad,rho_stack1_3,dim,Lz)\n",
    "    rho_stack1_4 = FieldGrad(Npts_grad,rho_stack1_4,dim,Lz)\n",
    "\n",
    "    print(\"Mixing time\")\n",
    "    ###aplication of mixing\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1[i] = pulse_mix@rho_stack1_1[i]\n",
    "        rho_stack1_2[i] = pulse_mix@rho_stack1_2[i]\n",
    "        rho_stack1_3[i] = pulse_mix@rho_stack1_3[i]\n",
    "        rho_stack1_4[i] = pulse_mix@rho_stack1_4[i]\n",
    "\n",
    "    #aplication of gradient...\n",
    "    rho_stack1_1 = FieldGrad(Npts_grad,rho_stack1_1,dim,Lz)\n",
    "    rho_stack1_2 = FieldGrad(Npts_grad,rho_stack1_2,dim,Lz)\n",
    "    rho_stack1_3 = FieldGrad(Npts_grad,rho_stack1_3,dim,Lz)\n",
    "    rho_stack1_4 = FieldGrad(Npts_grad,rho_stack1_4,dim,Lz)\n",
    "\n",
    "    print(\"Application of third 90 deg pulse\")\n",
    "    #application of third pulse...\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1[i] = pulse_90y@rho_stack1_1[i]\n",
    "        rho_stack1_2[i] = pulse_90y@rho_stack1_2[i]\n",
    "        rho_stack1_3[i] = pulse_90y@rho_stack1_3[i]\n",
    "        rho_stack1_4[i] = pulse_90y@rho_stack1_4[i]\n",
    "\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho1 = rho_stack1_1[i]\n",
    "        rho2 = rho_stack1_2[i]\n",
    "        rho3 = rho_stack1_3[i]\n",
    "        rho4 = rho_stack1_4[i]\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1)\n",
    "            rho1 = L_dt2@rho1\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2)\n",
    "            rho2 = L_dt2@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3)\n",
    "            rho3 = L_dt2@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4)\n",
    "            rho4 = L_dt2@rho4\n",
    "    \n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n",
    "    \n",
    "def GenFID_cohevol_noJsinTmix_GradField(Ham,Ham_noJs,T1,T2,rho0,coil,tmix,dt1,dt2,Lx,Ly,Lz):\n",
    "    \"\"\"\n",
    "    Implement a first-order deterministic Trotter simulation of the FID NOESY signals, to numerically explore optimization of number of Trotter steps needed in the simulation\n",
    "    for a target precision\n",
    "    Args:\n",
    "    Ham: matrix representation of the \"coherent\" part of the Liouvillian superoperator\n",
    "    List_jumps: list of the matrix representation of the jump operators\n",
    "    T1: maximal simulation time for the first phase of the protocol\n",
    "    T2: maximal simulation time for the second phase of the protocol\n",
    "    rho0: initial density matrix vector\n",
    "    coil: vector that represents the obervable we trace over to compute FID\n",
    "    Ntmix: number of samples to drawn in QDrift for the simulation of the system for tmix\n",
    "    \"\"\"\n",
    "    rho0 = rho0.flatten()\n",
    "\n",
    "    Npts_grad = 100\n",
    "    dim = rho0.shape[0]\n",
    "    \n",
    "    #R = sum(List_jumps)\n",
    "\n",
    "    #In this version, we drop the dissipation channels of the evolution during T1 and T2\n",
    "    L_dt1 = expm((-1j*Ham)*dt1)\n",
    "\n",
    "    L_dt2 = expm((-1j*Ham)*dt2)\n",
    "\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T1\",Tpts1)\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T2\",Tpts2)\n",
    "    #print(\"Number of Trotter steps for QDrift simulation of tmix\", Ntmix)\n",
    "    \n",
    "    #pulse_mix = eff_QDriftChann_OneJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #pulse_mix = eff_QDriftChann_InitJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #QDriftChann([Ham]+List_jumps,tmix)\n",
    "    #for i in range(Ntmix):\n",
    "    #    pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    #print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*tmix)))\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        rho_temp = np.dot(L_dt1,rho_temp)\n",
    "        rho_stack.append(rho_temp)\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    #TODO: change this accordingly to include dissipation....\n",
    "    #leftmix,rightmix = eff_QDriftChann_FinJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90y)\n",
    "    #pulse_mix = leftmix@rightmix\n",
    "    pulse_mix = expm(-1j*Ham_noJs*tmix)\n",
    "\n",
    "\n",
    "    ###Aplication of second 90 deg pulse\n",
    "\n",
    "    print(\"Application of second 90 deg pulse\")\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1.append(pulse_90x@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90mx@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90my@rho_stack[i])\n",
    "\n",
    "\n",
    "    #####Aplication of gradient...\n",
    "    rho_stack1_1 = FieldGrad(Npts_grad,rho_stack1_1,dim,Lz)\n",
    "    rho_stack1_2 = FieldGrad(Npts_grad,rho_stack1_2,dim,Lz)\n",
    "    rho_stack1_3 = FieldGrad(Npts_grad,rho_stack1_3,dim,Lz)\n",
    "    rho_stack1_4 = FieldGrad(Npts_grad,rho_stack1_4,dim,Lz)\n",
    "\n",
    "    print(\"Mixing time\")\n",
    "    ###aplication of mixing\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1.append(pulse_mix@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_mix@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_mix@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_mix@rho_stack[i])\n",
    "\n",
    "    #aplication of gradient...\n",
    "    rho_stack1_1 = FieldGrad(Npts_grad,rho_stack1_1,dim,Lz)\n",
    "    rho_stack1_2 = FieldGrad(Npts_grad,rho_stack1_2,dim,Lz)\n",
    "    rho_stack1_3 = FieldGrad(Npts_grad,rho_stack1_3,dim,Lz)\n",
    "    rho_stack1_4 = FieldGrad(Npts_grad,rho_stack1_4,dim,Lz)\n",
    "\n",
    "    print(\"Application of third 90 deg pulse\")\n",
    "    #application of third pulse...\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1.append(pulse_90y@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90y@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90y@rho_stack[i])\n",
    "\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho1 = rho_stack1_1[i]\n",
    "        rho2 = rho_stack1_2[i]\n",
    "        rho3 = rho_stack1_3[i]\n",
    "        rho4 = rho_stack1_4[i]\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1)\n",
    "            rho1 = L_dt2@rho1\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2)\n",
    "            rho2 = L_dt2@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3)\n",
    "            rho3 = L_dt2@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4)\n",
    "            rho4 = L_dt2@rho4\n",
    "    \n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n",
    "\n",
    "\n",
    "\n",
    "def GenFID_cohevol_noTmix_GradField(Ham,Ham_noJs,T1,T2,rho0,coil,tmix,dt1,dt2,Lx,Ly,Lz):\n",
    "    \"\"\"\n",
    "    Implement a first-order deterministic Trotter simulation of the FID NOESY signals, to numerically explore optimization of number of Trotter steps needed in the simulation\n",
    "    for a target precision\n",
    "    Args:\n",
    "    Ham: matrix representation of the \"coherent\" part of the Liouvillian superoperator\n",
    "    List_jumps: list of the matrix representation of the jump operators\n",
    "    T1: maximal simulation time for the first phase of the protocol\n",
    "    T2: maximal simulation time for the second phase of the protocol\n",
    "    rho0: initial density matrix vector\n",
    "    coil: vector that represents the obervable we trace over to compute FID\n",
    "    Ntmix: number of samples to drawn in QDrift for the simulation of the system for tmix\n",
    "    \"\"\"\n",
    "    rho0 = rho0.flatten()\n",
    "\n",
    "    Npts_grad = 100\n",
    "    dim = rho0.shape[0]\n",
    "    \n",
    "    #R = sum(List_jumps)\n",
    "\n",
    "    #In this version, we drop the dissipation channels of the evolution during T1 and T2\n",
    "    L_dt1 = expm((-1j*Ham)*dt1)\n",
    "\n",
    "    L_dt2 = expm((-1j*Ham)*dt2)\n",
    "\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T1\",Tpts1)\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T2\",Tpts2)\n",
    "    #print(\"Number of Trotter steps for QDrift simulation of tmix\", Ntmix)\n",
    "    \n",
    "    #pulse_mix = eff_QDriftChann_OneJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #pulse_mix = eff_QDriftChann_InitJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #QDriftChann([Ham]+List_jumps,tmix)\n",
    "    #for i in range(Ntmix):\n",
    "    #    pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    #print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*tmix)))\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        rho_temp = np.dot(L_dt1,rho_temp)\n",
    "        rho_stack.append(rho_temp)\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    #TODO: change this accordingly to include dissipation....\n",
    "    #leftmix,rightmix = eff_QDriftChann_FinJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90y)\n",
    "    #pulse_mix = leftmix@rightmix\n",
    "    pulse_mix = expm(-1j*Ham_noJs*tmix)\n",
    "\n",
    "\n",
    "    ###Aplication of second 90 deg pulse\n",
    "\n",
    "    print(\"Application of second 90 deg pulse\")\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1.append(pulse_90x@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90mx@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90my@rho_stack[i])\n",
    "\n",
    "\n",
    "    #####Aplication of gradient...\n",
    "    rho_stack1_1 = FieldGrad(Npts_grad,rho_stack1_1,dim,Lz)\n",
    "    rho_stack1_2 = FieldGrad(Npts_grad,rho_stack1_2,dim,Lz)\n",
    "    rho_stack1_3 = FieldGrad(Npts_grad,rho_stack1_3,dim,Lz)\n",
    "    rho_stack1_4 = FieldGrad(Npts_grad,rho_stack1_4,dim,Lz)\n",
    "\n",
    "    #print(\"Mixing time\")\n",
    "    ###aplication of mixing\n",
    "    #for i in range(Tpts1):\n",
    "    #    rho_stack1_1.append(pulse_mix@rho_stack[i])\n",
    "    #    rho_stack1_2.append(pulse_mix@rho_stack[i])\n",
    "    #    rho_stack1_3.append(pulse_mix@rho_stack[i])\n",
    "    #    rho_stack1_4.append(pulse_mix@rho_stack[i])\n",
    "\n",
    "    #aplication of gradient...\n",
    "    #rho_stack1_1 = FieldGrad(Npts_grad,rho_stack1_1,dim,Lz)\n",
    "    #rho_stack1_2 = FieldGrad(Npts_grad,rho_stack1_2,dim,Lz)\n",
    "    #rho_stack1_3 = FieldGrad(Npts_grad,rho_stack1_3,dim,Lz)\n",
    "    #rho_stack1_4 = FieldGrad(Npts_grad,rho_stack1_4,dim,Lz)\n",
    "\n",
    "    print(\"Application of third 90 deg pulse\")\n",
    "    #application of third pulse...\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1.append(pulse_90y@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90y@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90y@rho_stack[i])\n",
    "\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho1 = rho_stack1_1[i]\n",
    "        rho2 = rho_stack1_2[i]\n",
    "        rho3 = rho_stack1_3[i]\n",
    "        rho4 = rho_stack1_4[i]\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1)\n",
    "            rho1 = L_dt2@rho1\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2)\n",
    "            rho2 = L_dt2@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3)\n",
    "            rho3 = L_dt2@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4)\n",
    "            rho4 = L_dt2@rho4\n",
    "    \n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n",
    "\n",
    "#####Function to compute FID by neglecting mixing time and using a probabilistic application of the jump operator at the beginning of t2...\n",
    "def GenFID_SingJump_noTmix_GradField(Ham,JumpOps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly,Lz):\n",
    "    \"\"\"\n",
    "    Implement a first-order deterministic Trotter simulation of the FID NOESY signals, to numerically explore optimization of number of Trotter steps needed in the simulation\n",
    "    for a target precision\n",
    "    Args:\n",
    "    Ham: matrix representation of the \"coherent\" part of the Liouvillian superoperator\n",
    "    List_jumps: list of the matrix representation of the jump operators\n",
    "    T1: maximal simulation time for the first phase of the protocol\n",
    "    T2: maximal simulation time for the second phase of the protocol\n",
    "    rho0: initial density matrix vector\n",
    "    coil: vector that represents the obervable we trace over to compute FID\n",
    "    Ntmix: number of samples to drawn in QDrift for the simulation of the system for tmix\n",
    "    \"\"\"\n",
    "    rho0 = rho0.flatten()\n",
    "\n",
    "    Npts_grad = 100\n",
    "    dim = rho0.shape[0]\n",
    "    \n",
    "    #R = sum(List_jumps)\n",
    "\n",
    "    #In this version, we drop the dissipation channels of the evolution during T1 and T2\n",
    "    R = sum(JumpOps)\n",
    "\n",
    "    L_dt1 = expm((-1j*Ham+R)*dt1)\n",
    "\n",
    "    L_dt2 = expm((-1j*Ham+R)*dt2)\n",
    "\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    print(\"Number of points for T1\",Tpts1)\n",
    "    print(\"Number of points for T2\",Tpts2)\n",
    "    #print(\"Number of Trotter steps for QDrift simulation of tmix\", Ntmix)\n",
    "    \n",
    "    #pulse_mix = eff_QDriftChann_OneJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #pulse_mix = eff_QDriftChann_InitJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #QDriftChann([Ham]+List_jumps,tmix)\n",
    "    #for i in range(Ntmix):\n",
    "    #    pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    #print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*tmix)))\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        rho_temp = np.dot(L_dt1,rho_temp)\n",
    "        rho_stack.append(rho_temp)\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    #TODO: change this accordingly to include dissipation....\n",
    "    #leftmix,rightmix = eff_QDriftChann_FinJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90y)\n",
    "    #pulse_mix = leftmix@rightmix\n",
    "\n",
    "    #This is the last pulse that mimics the relaxation ocurring during the mixing time, thus eliminating the need of including mixing time\n",
    "    eff_pulse_90y = get_last_QDriftJump([Ham]+JumpOps,tmix,Ntmix,pulse_90y)\n",
    "    \n",
    "\n",
    "    ###Aplication of second 90 deg pulse\n",
    "\n",
    "    print(\"Application of second 90 deg pulse\")\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1.append(pulse_90x@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90mx@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90my@rho_stack[i])\n",
    "\n",
    "\n",
    "    #####Aplication of gradient...\n",
    "    rho_stack1_1 = FieldGrad(Npts_grad,rho_stack1_1,dim,Lz)\n",
    "    rho_stack1_2 = FieldGrad(Npts_grad,rho_stack1_2,dim,Lz)\n",
    "    rho_stack1_3 = FieldGrad(Npts_grad,rho_stack1_3,dim,Lz)\n",
    "    rho_stack1_4 = FieldGrad(Npts_grad,rho_stack1_4,dim,Lz)\n",
    "\n",
    "    #print(\"Mixing time\")\n",
    "    ###aplication of mixing\n",
    "    #for i in range(Tpts1):\n",
    "    #    rho_stack1_1.append(pulse_mix@rho_stack[i])\n",
    "    #    rho_stack1_2.append(pulse_mix@rho_stack[i])\n",
    "    #    rho_stack1_3.append(pulse_mix@rho_stack[i])\n",
    "    #    rho_stack1_4.append(pulse_mix@rho_stack[i])\n",
    "\n",
    "    #aplication of gradient...\n",
    "    #rho_stack1_1 = FieldGrad(Npts_grad,rho_stack1_1,dim,Lz)\n",
    "    #rho_stack1_2 = FieldGrad(Npts_grad,rho_stack1_2,dim,Lz)\n",
    "    #rho_stack1_3 = FieldGrad(Npts_grad,rho_stack1_3,dim,Lz)\n",
    "    #rho_stack1_4 = FieldGrad(Npts_grad,rho_stack1_4,dim,Lz)\n",
    "\n",
    "    print(\"Application of third 90 deg pulse\")\n",
    "    #application of third pulse...\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1[i] = eff_pulse_90y@rho_stack1_1[i]\n",
    "        rho_stack1_2[i] = eff_pulse_90y@rho_stack1_2[i]\n",
    "        rho_stack1_3[i] = eff_pulse_90y@rho_stack1_3[i]\n",
    "        rho_stack1_4[i] = eff_pulse_90y@rho_stack1_4[i]\n",
    "\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho1 = rho_stack1_1[i]\n",
    "        rho2 = rho_stack1_2[i]\n",
    "        rho3 = rho_stack1_3[i]\n",
    "        rho4 = rho_stack1_4[i]\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1)\n",
    "            rho1 = L_dt2@rho1\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2)\n",
    "            rho2 = L_dt2@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3)\n",
    "            rho3 = L_dt2@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4)\n",
    "            rho4 = L_dt2@rho4\n",
    "    \n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n",
    "\n",
    "\n",
    "def GenFID_SingJump_noTmix_GradField_SetMaxDisc(Ham,JumpOps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly,Lz,Nmax):\n",
    "    \"\"\"\n",
    "    We aim to perform the simulation by setting a maximum number of samples from a QDrift channel to perform the simulation of t1 and t2 timescales\n",
    "    to perform the simulation of NOESY spectrum. \n",
    "    \"\"\"\n",
    "    rho0 = rho0.flatten()\n",
    "\n",
    "    Npts_grad = 100\n",
    "    dim = rho0.shape[0]\n",
    "    \n",
    "    #R = sum(List_jumps)\n",
    "\n",
    "    #In this version, we drop the dissipation channels of the evolution during T1 and T2\n",
    "    #R = sum(JumpOps)\n",
    "\n",
    "    #L_dt1 = expm((-1j*Ham+R)*dt1)\n",
    "\n",
    "    #L_dt2 = expm((-1j*Ham+R)*dt2)\n",
    "\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    print(\"Number of points for T1\",Tpts1)\n",
    "    print(\"Number of points for T2\",Tpts2)\n",
    "    #print(\"Number of Trotter steps for QDrift simulation of tmix\", Ntmix)\n",
    "    \n",
    "    #pulse_mix = eff_QDriftChann_OneJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #pulse_mix = eff_QDriftChann_InitJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #QDriftChann([Ham]+List_jumps,tmix)\n",
    "    #for i in range(Ntmix):\n",
    "    #    pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    #print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*tmix)))\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    ###Getting the list of operators and probabilities for the QDrift channel...\n",
    "    Norm_ops, List_weights = Normalize_and_weightOps([Ham]+JumpOps)\n",
    "\n",
    "    List_weights = np.array(List_weights)\n",
    "    Gamma =  np.sum(List_weights)\n",
    "\n",
    "    pks = (1.0/Gamma)*List_weights\n",
    "\n",
    "    #QDriftEvol_fromNormOps(Norm_ops,pks,Gamma,time_evol,Nsteps,rho)\n",
    "\n",
    "    #rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        ####after the number of time points exceeds the maximum, we keep the number of samples in the QDrift channel fixed...\n",
    "        if i > Nmax:\n",
    "            #rho_t = QDriftEvol([Ham]+JumpOps,i*dt1,Nmax,rho0)\n",
    "            rho_t = QDriftEvol_fromNormOps(Norm_ops,pks,Gamma,i*dt1,Nmax,rho0)\n",
    "\n",
    "            #rho_temp = np.dot(L_dt1,rho_temp)\n",
    "            rho_stack.append(rho_t)\n",
    "\n",
    "        else:\n",
    "            #rho_t = QDriftEvol([Ham]+JumpOps,i*dt1,i,rho0)\n",
    "            rho_t = QDriftEvol_fromNormOps(Norm_ops,pks,Gamma,i*dt1,i,rho0)\n",
    "\n",
    "            #rho_temp = np.dot(L_dt1,rho_temp)\n",
    "            rho_stack.append(rho_t)\n",
    "\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    #TODO: change this accordingly to include dissipation....\n",
    "    #leftmix,rightmix = eff_QDriftChann_FinJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90y)\n",
    "    #pulse_mix = leftmix@rightmix\n",
    "\n",
    "    #This is the last pulse that mimics the relaxation ocurring during the mixing time, thus eliminating the need of including mixing time\n",
    "    eff_pulse_90y = get_last_QDriftJump([Ham]+JumpOps,tmix,Ntmix,pulse_90y)\n",
    "    \n",
    "\n",
    "    ###Aplication of second 90 deg pulse\n",
    "\n",
    "    print(\"Application of second 90 deg pulse\")\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1.append(pulse_90x@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90mx@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90my@rho_stack[i])\n",
    "\n",
    "\n",
    "    #####Aplication of gradient...\n",
    "    rho_stack1_1 = FieldGrad(Npts_grad,rho_stack1_1,dim,Lz)\n",
    "    rho_stack1_2 = FieldGrad(Npts_grad,rho_stack1_2,dim,Lz)\n",
    "    rho_stack1_3 = FieldGrad(Npts_grad,rho_stack1_3,dim,Lz)\n",
    "    rho_stack1_4 = FieldGrad(Npts_grad,rho_stack1_4,dim,Lz)\n",
    "\n",
    "    #print(\"Mixing time\")\n",
    "    ###aplication of mixing\n",
    "    #for i in range(Tpts1):\n",
    "    #    rho_stack1_1.append(pulse_mix@rho_stack[i])\n",
    "    #    rho_stack1_2.append(pulse_mix@rho_stack[i])\n",
    "    #    rho_stack1_3.append(pulse_mix@rho_stack[i])\n",
    "    #    rho_stack1_4.append(pulse_mix@rho_stack[i])\n",
    "\n",
    "    #aplication of gradient...\n",
    "    #rho_stack1_1 = FieldGrad(Npts_grad,rho_stack1_1,dim,Lz)\n",
    "    #rho_stack1_2 = FieldGrad(Npts_grad,rho_stack1_2,dim,Lz)\n",
    "    #rho_stack1_3 = FieldGrad(Npts_grad,rho_stack1_3,dim,Lz)\n",
    "    #rho_stack1_4 = FieldGrad(Npts_grad,rho_stack1_4,dim,Lz)\n",
    "\n",
    "    print(\"Application of third 90 deg pulse\")\n",
    "    #application of third pulse...\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1[i] = eff_pulse_90y@rho_stack1_1[i]\n",
    "        rho_stack1_2[i] = eff_pulse_90y@rho_stack1_2[i]\n",
    "        rho_stack1_3[i] = eff_pulse_90y@rho_stack1_3[i]\n",
    "        rho_stack1_4[i] = eff_pulse_90y@rho_stack1_4[i]\n",
    "\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    \n",
    "    for i in range(Tpts1):\n",
    "        rho1 = np.copy(rho_stack1_1[i])\n",
    "        rho2 = np.copy(rho_stack1_2[i])\n",
    "        rho3 = np.copy(rho_stack1_3[i])\n",
    "        rho4 = np.copy(rho_stack1_4[i])\n",
    "\n",
    "        rho1_t2 = np.copy(rho1)\n",
    "        rho2_t2 = np.copy(rho2)\n",
    "        rho3_t2 = np.copy(rho3)\n",
    "        rho4_t2 = np.copy(rho4)\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1_t2)\n",
    "\n",
    "            if j > Nmax:\n",
    "                #rho1_t2 = QDriftEvol([Ham]+JumpOps,j*dt2,Nmax,rho1)\n",
    "                rho1_t2 = QDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,Nmax,rho1)\n",
    "            else:\n",
    "                rho1_t2 = QDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,j,rho1)\n",
    "            \n",
    "            #rho1 = L_dt2@rho1\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2_t2)\n",
    "            if j > Nmax:\n",
    "                rho2_t2 = QDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,Nmax,rho2)\n",
    "            else:\n",
    "                rho2_t2 = QDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,j,rho2)\n",
    "            #rho2 = L_dt2@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3_t2)\n",
    "            if j > Nmax:\n",
    "                rho3_t2 = QDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,Nmax,rho3)\n",
    "            else:\n",
    "                rho3_t2 = QDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,j,rho3)\n",
    "\n",
    "            #rho3 = L_dt2@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4_t2)\n",
    "            if j > Nmax:\n",
    "                rho4_t2 = QDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,Nmax,rho4)\n",
    "            else:\n",
    "                rho4_t2 = QDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,j,rho4)\n",
    "\n",
    "            #rho4 = L_dt2@rho4\n",
    "        print(\"Finishing iteration: \",i)\n",
    "    \n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points for simulation of T1 1024\n",
      "Number of points for simulation of T2 1024\n",
      "Application of second 90 deg pulse\n",
      "Mixing time\n",
      "Application of third 90 deg pulse\n"
     ]
    }
   ],
   "source": [
    "####TODO: loading the coherent part of the Liouvillian, that can be generated with and without J couplings from MATLAB\n",
    "#2) generate the list of jump operators with the new parameters of the Hamiltonian, only needed if the distances between spins is different than the ones used for Alanine so far\n",
    "#3) if there is a match with the reference Hamiltonian, then we can implement the version without mixing time...\n",
    "\n",
    "\n",
    "#TODO: the jump operator rates are expected to be slightly different from the ones we have previously computed, we can correct for the this small difference later. The only difference is to use the \n",
    "# updated correlation time tc 18.8e-12\n",
    "\n",
    "\n",
    "loadMat = spio.loadmat('./data/NOESYdata_ALA_experiment.mat',squeeze_me=True)\n",
    "\n",
    "#R_ala = loadMat['p']['R'].item()\n",
    "H_ala_exp = loadMat['p']['H'].item().toarray()\n",
    "Lx = loadMat['p']['Lx'].item().toarray() \n",
    "Ly = loadMat['p']['Ly'].item().toarray() \n",
    "Lz = loadMat['p']['Lz'].item().toarray()\n",
    "rho0= loadMat['p']['rho0'].item()\n",
    "coil  = loadMat['p']['coil'].item().toarray().flatten()\n",
    "Tpts = 1024#loadMat['p']['Tpts'].item()\n",
    "#dt = loadMat['p']['dt'].item()\n",
    "dt1 = 0.3126e-3\n",
    "dt2 = 0.2080e-3\n",
    "\n",
    "T1 = dt1*Tpts\n",
    "T2 = dt2*Tpts\n",
    "tmix = 0.80\n",
    "\n",
    "#Load the list of ZZ jump operators....\n",
    "f= open('./data/ALA_expGradField_JOps.pk')\n",
    "dat = pickle.load(f)\n",
    "\n",
    "JumpOps = dat['JumpOps']\n",
    "\n",
    "\n",
    "#fid1_cohGrad, fid2_cohGrad, fid3_cohGrad, fid4_cohGrad = GenFID_cohevol_GradField(H_ala_exp,T1,T2,rho0,coil,tmix,dt1,dt2,Lx,Ly,Lz)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "###saving data...\n",
    "cos_fid = fid1_cohGrad - fid3_cohGrad\n",
    "sin_fid = fid2_cohGrad - fid4_cohGrad\n",
    "\n",
    "savemat('ALA_truncR_FIDcos_cohGrad.mat', {'FID_cos': cos_fid})\n",
    "savemat('ALA_truncR_FIDsin_cohGrad.mat', {'FID_sin': sin_fid})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points for T1 1024\n",
      "Number of points for T2 1024\n",
      "Application of second 90 deg pulse\n",
      "Application of third 90 deg pulse\n"
     ]
    }
   ],
   "source": [
    "fid1_effJ, fid2_effJ, fid3_effJ, fid4_effJ = GenFID_SingJump_noTmix_GradField(H_ala_exp,JumpOps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly,Lz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_fid = fid1_effJ - fid3_effJ\n",
    "sin_fid = fid2_effJ - fid4_effJ\n",
    "\n",
    "savemat('ALA_truncR_FIDcos_effJGrad.mat', {'FID_cos': cos_fid})\n",
    "savemat('ALA_truncR_FIDsin_effJGrad.mat', {'FID_sin': sin_fid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points for T1 1024\n",
      "Number of points for T2 1024\n",
      "Application of second 90 deg pulse\n",
      "Application of third 90 deg pulse\n",
      "Finishing iteration:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[198], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m Nmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 2\u001b[0m fid1_effJN10, fid2_effJN10, fid3_effJN10, fid4_effJN10 \u001b[38;5;241m=\u001b[39m \u001b[43mGenFID_SingJump_noTmix_GradField_SetMaxDisc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH_ala_exp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mJumpOps\u001b[49m\u001b[43m,\u001b[49m\u001b[43mT1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mT2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrho0\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcoil\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtmix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdt2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNtmix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mLx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mLy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mLz\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNmax\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[197], line 778\u001b[0m, in \u001b[0;36mGenFID_SingJump_noTmix_GradField_SetMaxDisc\u001b[0;34m(Ham, JumpOps, T1, T2, rho0, coil, tmix, dt1, dt2, Ntmix, Lx, Ly, Lz, Nmax)\u001b[0m\n\u001b[1;32m    776\u001b[0m fid_temp_2[j,i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(coil,rho2_t2)\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m>\u001b[39m Nmax:\n\u001b[0;32m--> 778\u001b[0m     rho2_t2 \u001b[38;5;241m=\u001b[39m \u001b[43mQDriftEvol\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mHam\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mJumpOps\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdt2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrho2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    780\u001b[0m     rho2_t2 \u001b[38;5;241m=\u001b[39m QDriftEvol([Ham]\u001b[38;5;241m+\u001b[39mJumpOps,j\u001b[38;5;241m*\u001b[39mdt2,j,rho2)\n",
      "Cell \u001b[0;32mIn[196], line 51\u001b[0m, in \u001b[0;36mQDriftEvol\u001b[0;34m(List_gens, time_evol, Nsteps, rho)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     chann \u001b[38;5;241m=\u001b[39m QDriftChann(List_gens,time_evol\u001b[38;5;241m/\u001b[39mNsteps)\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNsteps\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     52\u001b[0m     rho_c \u001b[38;5;241m=\u001b[39m chann\u001b[38;5;129m@rho_c\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rho_c\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Nmax = 10\n",
    "fid1_effJN10, fid2_effJN10, fid3_effJN10, fid4_effJN10 = GenFID_SingJump_noTmix_GradField_SetMaxDisc(H_ala_exp,JumpOps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly,Lz,Nmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of layer estimation for the computation of NOESY spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform optimistic and pessimistic estimation of number of layers for the implementation of a NOESY protocol in a quantum device...\n",
    "# under the following simplifications. For the most optimistic case:\n",
    "#1) we can apply a single probabilistic jump operator right at the beginning of the free evolution time t2\n",
    "# 2) we can remove the mixing time scale \n",
    "# 3)  wether we can remove the scalar couplings during t1 and t2 is subject to exploration, but firstly we assume that we need to consider them  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenH0_Ham_Part(offset,B0,zeeman_scalars,Jcoups,gamma):\n",
    "    \"\"\"\n",
    "    Returns: the zeroth order Hamiltonian considered for dynamical evolution in nthe simulations, in OpenFermion format\n",
    "    Args:\n",
    "    offset: frequency offset for the spin Zeeman frequencies, in Hz\n",
    "    B0: Strength of the magnetic field in Teslas\n",
    "    zeeman_scalars: list of chemical shifts for spins, in ppm\n",
    "    Jcoups: matrix of size N x N, N being the number of spins, that encodes the scalar couplings between spins (in Hz)\n",
    "    gamma: gyromagnetic ratio of the spins (an homonuclear case is assumed) \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #offset = -46681\n",
    "    #B0 = 9.3933\n",
    "    w0 = -gamma*B0\n",
    "    o1 = 2*np.pi*offset\n",
    "    Nspins = len(zeeman_scalars)\n",
    "\n",
    "    Hamiltonian0 = of.QubitOperator()\n",
    "\n",
    "    for i in range(Nspins):\n",
    "        w = o1+w0*zeeman_scalars[i]/1e6\n",
    "        Hamiltonian0+=w*Sz(i)\n",
    "\n",
    "\n",
    "    Interactions = []\n",
    "\n",
    "    for i in range(Nspins):\n",
    "        for j in range(i+1,Nspins):\n",
    "\n",
    "            if Jcoups[i,j] != 0.0:\n",
    "\n",
    "                Interactions.append(2*np.pi*Jcoups[i,j]*(Sx(i)*Sx(j)+Sy(i)*Sy(j)+Sz(i)*Sz(j)))\n",
    "    \n",
    "    return Hamiltonian0, Interactions\n",
    "\n",
    "#####Rewriting, cleaning and tailoring some functions for QDrift simulation of the coherent part of the Hamiltonian\n",
    "def BuildCohQDriftChann_fromOps(time_evol,Norm_ops,pks,Gamma):\n",
    "    \"\"\"\n",
    "    It is assumed that all operators in Norm_ops corresponds to fragments of the coherent part of the Liouvillian \n",
    "    \"\"\"\n",
    "    Qdrift_chann = pks[0]*expm(-1j*Norm_ops[0]*time_evol*Gamma)\n",
    "    for i in range(1,len(pks)):\n",
    "        Qdrift_chann += pks[i]*expm(-1j*Norm_ops[i]*time_evol*Gamma)\n",
    "\n",
    "    return Qdrift_chann\n",
    "\n",
    "def CohQDriftEvol_fromNormOps(Norm_ops,pks,Gamma,time_evol,Nsteps,rho):\n",
    "    \n",
    "    rho_c = np.copy(rho)\n",
    "\n",
    "    if time_evol==0:\n",
    "        chann = np.eye(rho_c.shape[0])\n",
    "    else:\n",
    "        chann= BuildCohQDriftChann_fromOps(time_evol/Nsteps,Norm_ops,pks,Gamma)\n",
    "\n",
    "    for i in range(Nsteps):\n",
    "        rho_c = chann@rho_c\n",
    "\n",
    "    return rho_c\n",
    "\n",
    "def GenFID_SingJump_noTmix_GradField_SetMaxDisc(Ham,IntOps,JumpOps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly,Lz,Nmax):\n",
    "    \"\"\"\n",
    "    We aim to perform the simulation by setting a maximum number of samples from a QDrift channel to perform the simulation of t1 and t2 timescales\n",
    "    to perform the simulation of NOESY spectrum. \n",
    "    Args:\n",
    "    Ham: the Zeeman Hamiltonian \n",
    "    IntOps: the list of Hamiltonian fragments, such that their addition to the Zeeaman Hamiltonian define the coherent contribution to the Liovillian\n",
    "    JumOps: List of jump operators to include in the simulation\n",
    "    T1: total simulation time along the t1 axis\n",
    "    T2: total simulation time along the t2 axis\n",
    "    rho0: initial density matrix\n",
    "    coil: the observable to measure \n",
    "    tmix: the mixing time\n",
    "    dt1: the time step that defines the time-resolution of the grid along the t1 axis \n",
    "    dt2: the time step that defines the time resolution of the grid along the t2 axis\n",
    "    Ntmix: the number of samples assumed to be taken during the mixing time through a QDroft channel. Note that in practice this channel is approximated as an effective one where\n",
    "    the mixing time is removed\n",
    "    Lx,Ly,Lz: collective angular momentum operators\n",
    "    Nmax: maximum number of Qdrift samples for the simulation of t1,t2 times (i.e. the maximum number of samples is fixed to 2*Nmax for time propagation of t1+t2)\n",
    "    \"\"\"\n",
    "    rho0 = rho0.flatten()\n",
    "\n",
    "    Npts_grad = 100\n",
    "    dim = rho0.shape[0]\n",
    "    \n",
    "    #R = sum(List_jumps)\n",
    "\n",
    "    #In this version, we drop the dissipation channels of the evolution during T1 and T2\n",
    "    #R = sum(JumpOps)\n",
    "\n",
    "    #L_dt1 = expm((-1j*Ham+R)*dt1)\n",
    "\n",
    "    #L_dt2 = expm((-1j*Ham+R)*dt2)\n",
    "\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    print(\"Number of points for T1\",Tpts1)\n",
    "    print(\"Number of points for T2\",Tpts2)\n",
    "    #print(\"Number of Trotter steps for QDrift simulation of tmix\", Ntmix)\n",
    "    \n",
    "    #pulse_mix = eff_QDriftChann_OneJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #pulse_mix = eff_QDriftChann_InitJump([Ham]+List_jumps,tmix,Ntmix)\n",
    "    #QDriftChann([Ham]+List_jumps,tmix)\n",
    "    #for i in range(Ntmix):\n",
    "    #    pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    #print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*tmix)))\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    ###Getting the list of operators and probabilities for the QDrift channel...\n",
    "    Norm_ops, List_weights = Normalize_and_weightOps([Ham]+IntOps)\n",
    "\n",
    "    List_weights = np.array(List_weights)\n",
    "    Gamma =  np.sum(List_weights)\n",
    "\n",
    "    pks = (1.0/Gamma)*List_weights\n",
    "\n",
    "    #QDriftEvol_fromNormOps(Norm_ops,pks,Gamma,time_evol,Nsteps,rho)\n",
    "\n",
    "    #rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        ####after the number of time points exceeds the maximum, we keep the number of samples in the QDrift channel fixed...\n",
    "        if i > Nmax:\n",
    "            #rho_t = QDriftEvol([Ham]+JumpOps,i*dt1,Nmax,rho0)\n",
    "            rho_t = CohQDriftEvol_fromNormOps(Norm_ops,pks,Gamma,i*dt1,Nmax,rho0)\n",
    "\n",
    "            #rho_temp = np.dot(L_dt1,rho_temp)\n",
    "            rho_stack.append(rho_t)\n",
    "\n",
    "        else:\n",
    "            #rho_t = QDriftEvol([Ham]+JumpOps,i*dt1,i,rho0)\n",
    "            rho_t = CohQDriftEvol_fromNormOps(Norm_ops,pks,Gamma,i*dt1,i,rho0)\n",
    "\n",
    "            #rho_temp = np.dot(L_dt1,rho_temp)\n",
    "            rho_stack.append(rho_t)\n",
    "\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    #TODO: change this accordingly to include dissipation....\n",
    "    #leftmix,rightmix = eff_QDriftChann_FinJump_Factorized([Ham]+List_jumps,tmix,Ntmix,pulse_90y)\n",
    "    #pulse_mix = leftmix@rightmix\n",
    "\n",
    "    #This is the last pulse that mimics the relaxation ocurring during the mixing time, thus eliminating the need of including mixing time\n",
    "\n",
    "    ####TODO: \n",
    "\n",
    "    Hcoh = Ham+sum(IntOps)\n",
    "    eff_pulse_90y = get_last_QDriftJump([Hcoh]+JumpOps,tmix,Ntmix,pulse_90y)\n",
    "    \n",
    "\n",
    "    ###Aplication of second 90 deg pulse\n",
    "\n",
    "    print(\"Application of second 90 deg pulse\")\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1.append(pulse_90x@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90mx@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90my@rho_stack[i])\n",
    "\n",
    "\n",
    "    #####Aplication of gradient...\n",
    "    rho_stack1_1 = FieldGrad(Npts_grad,rho_stack1_1,dim,Lz)\n",
    "    rho_stack1_2 = FieldGrad(Npts_grad,rho_stack1_2,dim,Lz)\n",
    "    rho_stack1_3 = FieldGrad(Npts_grad,rho_stack1_3,dim,Lz)\n",
    "    rho_stack1_4 = FieldGrad(Npts_grad,rho_stack1_4,dim,Lz)\n",
    "\n",
    "    #print(\"Mixing time\")\n",
    "    ###aplication of mixing\n",
    "    #for i in range(Tpts1):\n",
    "    #    rho_stack1_1.append(pulse_mix@rho_stack[i])\n",
    "    #    rho_stack1_2.append(pulse_mix@rho_stack[i])\n",
    "    #    rho_stack1_3.append(pulse_mix@rho_stack[i])\n",
    "    #    rho_stack1_4.append(pulse_mix@rho_stack[i])\n",
    "\n",
    "    #aplication of gradient...\n",
    "    #rho_stack1_1 = FieldGrad(Npts_grad,rho_stack1_1,dim,Lz)\n",
    "    #rho_stack1_2 = FieldGrad(Npts_grad,rho_stack1_2,dim,Lz)\n",
    "    #rho_stack1_3 = FieldGrad(Npts_grad,rho_stack1_3,dim,Lz)\n",
    "    #rho_stack1_4 = FieldGrad(Npts_grad,rho_stack1_4,dim,Lz)\n",
    "\n",
    "    print(\"Application of third 90 deg pulse\")\n",
    "    #application of third pulse...\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1[i] = eff_pulse_90y@rho_stack1_1[i]\n",
    "        rho_stack1_2[i] = eff_pulse_90y@rho_stack1_2[i]\n",
    "        rho_stack1_3[i] = eff_pulse_90y@rho_stack1_3[i]\n",
    "        rho_stack1_4[i] = eff_pulse_90y@rho_stack1_4[i]\n",
    "\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    \n",
    "    for i in range(Tpts1):\n",
    "        rho1 = np.copy(rho_stack1_1[i])\n",
    "        rho2 = np.copy(rho_stack1_2[i])\n",
    "        rho3 = np.copy(rho_stack1_3[i])\n",
    "        rho4 = np.copy(rho_stack1_4[i])\n",
    "\n",
    "        rho1_t2 = np.copy(rho1)\n",
    "        rho2_t2 = np.copy(rho2)\n",
    "        rho3_t2 = np.copy(rho3)\n",
    "        rho4_t2 = np.copy(rho4)\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1_t2)\n",
    "\n",
    "            if j > Nmax:\n",
    "                #rho1_t2 = QDriftEvol([Ham]+JumpOps,j*dt2,Nmax,rho1)\n",
    "                rho1_t2 = CohQDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,Nmax,rho1)\n",
    "            else:\n",
    "                rho1_t2 = CohQDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,j,rho1)\n",
    "            \n",
    "            #rho1 = L_dt2@rho1\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2_t2)\n",
    "            if j > Nmax:\n",
    "                rho2_t2 = CohQDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,Nmax,rho2)\n",
    "            else:\n",
    "                rho2_t2 = CohQDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,j,rho2)\n",
    "            #rho2 = L_dt2@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3_t2)\n",
    "            if j > Nmax:\n",
    "                rho3_t2 = CohQDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,Nmax,rho3)\n",
    "            else:\n",
    "                rho3_t2 = CohQDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,j,rho3)\n",
    "\n",
    "            #rho3 = L_dt2@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4_t2)\n",
    "            if j > Nmax:\n",
    "                rho4_t2 = CohQDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,Nmax,rho4)\n",
    "            else:\n",
    "                rho4_t2 = CohQDriftEvol_fromNormOps(Norm_ops,pks,Gamma,j*dt2,j,rho4)\n",
    "\n",
    "            #rho4 = L_dt2@rho4\n",
    "        print(\"Finishing iteration: \",i)\n",
    "    \n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4=\"\"\"1      (0,0)   (0,0)   (0,0)   (0,0)   \n",
    "  2      (0,0)   (0,0)   (0,0)   (1,1)   \n",
    "  3      (0,0)   (0,0)   (0,0)   (1,0)   \n",
    "  4      (0,0)   (0,0)   (0,0)   (1,-1)  \n",
    "  5      (0,0)   (0,0)   (1,1)   (0,0)   \n",
    "  6      (0,0)   (0,0)   (1,1)   (1,1)   \n",
    "  7      (0,0)   (0,0)   (1,1)   (1,0)   \n",
    "  8      (0,0)   (0,0)   (1,1)   (1,-1)  \n",
    "  9      (0,0)   (0,0)   (1,0)   (0,0)   \n",
    "  10     (0,0)   (0,0)   (1,0)   (1,1)   \n",
    "  11     (0,0)   (0,0)   (1,0)   (1,0)   \n",
    "  12     (0,0)   (0,0)   (1,0)   (1,-1)  \n",
    "  13     (0,0)   (0,0)   (1,-1)  (0,0)   \n",
    "  14     (0,0)   (0,0)   (1,-1)  (1,1)   \n",
    "  15     (0,0)   (0,0)   (1,-1)  (1,0)   \n",
    "  16     (0,0)   (0,0)   (1,-1)  (1,-1)  \n",
    "  17     (0,0)   (1,1)   (0,0)   (0,0)   \n",
    "  18     (0,0)   (1,1)   (0,0)   (1,1)   \n",
    "  19     (0,0)   (1,1)   (0,0)   (1,0)   \n",
    "  20     (0,0)   (1,1)   (0,0)   (1,-1)  \n",
    "  21     (0,0)   (1,1)   (1,1)   (0,0)   \n",
    "  22     (0,0)   (1,1)   (1,1)   (1,1)   \n",
    "  23     (0,0)   (1,1)   (1,1)   (1,0)   \n",
    "  24     (0,0)   (1,1)   (1,1)   (1,-1)  \n",
    "  25     (0,0)   (1,1)   (1,0)   (0,0)   \n",
    "  26     (0,0)   (1,1)   (1,0)   (1,1)   \n",
    "  27     (0,0)   (1,1)   (1,0)   (1,0)   \n",
    "  28     (0,0)   (1,1)   (1,0)   (1,-1)  \n",
    "  29     (0,0)   (1,1)   (1,-1)  (0,0)   \n",
    "  30     (0,0)   (1,1)   (1,-1)  (1,1)   \n",
    "  31     (0,0)   (1,1)   (1,-1)  (1,0)   \n",
    "  32     (0,0)   (1,1)   (1,-1)  (1,-1)  \n",
    "  33     (0,0)   (1,0)   (0,0)   (0,0)   \n",
    "  34     (0,0)   (1,0)   (0,0)   (1,1)   \n",
    "  35     (0,0)   (1,0)   (0,0)   (1,0)   \n",
    "  36     (0,0)   (1,0)   (0,0)   (1,-1)  \n",
    "  37     (0,0)   (1,0)   (1,1)   (0,0)   \n",
    "  38     (0,0)   (1,0)   (1,1)   (1,1)   \n",
    "  39     (0,0)   (1,0)   (1,1)   (1,0)   \n",
    "  40     (0,0)   (1,0)   (1,1)   (1,-1)  \n",
    "  41     (0,0)   (1,0)   (1,0)   (0,0)   \n",
    "  42     (0,0)   (1,0)   (1,0)   (1,1)   \n",
    "  43     (0,0)   (1,0)   (1,0)   (1,0)   \n",
    "  44     (0,0)   (1,0)   (1,0)   (1,-1)  \n",
    "  45     (0,0)   (1,0)   (1,-1)  (0,0)   \n",
    "  46     (0,0)   (1,0)   (1,-1)  (1,1)   \n",
    "  47     (0,0)   (1,0)   (1,-1)  (1,0)   \n",
    "  48     (0,0)   (1,0)   (1,-1)  (1,-1)  \n",
    "  49     (0,0)   (1,-1)  (0,0)   (0,0)   \n",
    "  50     (0,0)   (1,-1)  (0,0)   (1,1)   \n",
    "  51     (0,0)   (1,-1)  (0,0)   (1,0)   \n",
    "  52     (0,0)   (1,-1)  (0,0)   (1,-1)  \n",
    "  53     (0,0)   (1,-1)  (1,1)   (0,0)   \n",
    "  54     (0,0)   (1,-1)  (1,1)   (1,1)   \n",
    "  55     (0,0)   (1,-1)  (1,1)   (1,0)   \n",
    "  56     (0,0)   (1,-1)  (1,1)   (1,-1)  \n",
    "  57     (0,0)   (1,-1)  (1,0)   (0,0)   \n",
    "  58     (0,0)   (1,-1)  (1,0)   (1,1)   \n",
    "  59     (0,0)   (1,-1)  (1,0)   (1,0)   \n",
    "  60     (0,0)   (1,-1)  (1,0)   (1,-1)  \n",
    "  61     (0,0)   (1,-1)  (1,-1)  (0,0)   \n",
    "  62     (0,0)   (1,-1)  (1,-1)  (1,1)   \n",
    "  63     (0,0)   (1,-1)  (1,-1)  (1,0)   \n",
    "  64     (0,0)   (1,-1)  (1,-1)  (1,-1)  \n",
    "  65     (1,1)   (0,0)   (0,0)   (0,0)   \n",
    "  66     (1,1)   (0,0)   (0,0)   (1,1)   \n",
    "  67     (1,1)   (0,0)   (0,0)   (1,0)   \n",
    "  68     (1,1)   (0,0)   (0,0)   (1,-1)  \n",
    "  69     (1,1)   (0,0)   (1,1)   (0,0)   \n",
    "  70     (1,1)   (0,0)   (1,1)   (1,1)   \n",
    "  71     (1,1)   (0,0)   (1,1)   (1,0)   \n",
    "  72     (1,1)   (0,0)   (1,1)   (1,-1)  \n",
    "  73     (1,1)   (0,0)   (1,0)   (0,0)   \n",
    "  74     (1,1)   (0,0)   (1,0)   (1,1)   \n",
    "  75     (1,1)   (0,0)   (1,0)   (1,0)   \n",
    "  76     (1,1)   (0,0)   (1,0)   (1,-1)  \n",
    "  77     (1,1)   (0,0)   (1,-1)  (0,0)   \n",
    "  78     (1,1)   (0,0)   (1,-1)  (1,1)   \n",
    "  79     (1,1)   (0,0)   (1,-1)  (1,0)   \n",
    "  80     (1,1)   (0,0)   (1,-1)  (1,-1)  \n",
    "  81     (1,1)   (1,1)   (0,0)   (0,0)   \n",
    "  82     (1,1)   (1,1)   (0,0)   (1,1)   \n",
    "  83     (1,1)   (1,1)   (0,0)   (1,0)   \n",
    "  84     (1,1)   (1,1)   (0,0)   (1,-1)  \n",
    "  85     (1,1)   (1,1)   (1,1)   (0,0)   \n",
    "  86     (1,1)   (1,1)   (1,1)   (1,1)   \n",
    "  87     (1,1)   (1,1)   (1,1)   (1,0)   \n",
    "  88     (1,1)   (1,1)   (1,1)   (1,-1)  \n",
    "  89     (1,1)   (1,1)   (1,0)   (0,0)   \n",
    "  90     (1,1)   (1,1)   (1,0)   (1,1)   \n",
    "  91     (1,1)   (1,1)   (1,0)   (1,0)   \n",
    "  92     (1,1)   (1,1)   (1,0)   (1,-1)  \n",
    "  93     (1,1)   (1,1)   (1,-1)  (0,0)   \n",
    "  94     (1,1)   (1,1)   (1,-1)  (1,1)   \n",
    "  95     (1,1)   (1,1)   (1,-1)  (1,0)   \n",
    "  96     (1,1)   (1,1)   (1,-1)  (1,-1)  \n",
    "  97     (1,1)   (1,0)   (0,0)   (0,0)   \n",
    "  98     (1,1)   (1,0)   (0,0)   (1,1)   \n",
    "  99     (1,1)   (1,0)   (0,0)   (1,0)   \n",
    "  100    (1,1)   (1,0)   (0,0)   (1,-1)  \n",
    "  101    (1,1)   (1,0)   (1,1)   (0,0)   \n",
    "  102    (1,1)   (1,0)   (1,1)   (1,1)   \n",
    "  103    (1,1)   (1,0)   (1,1)   (1,0)   \n",
    "  104    (1,1)   (1,0)   (1,1)   (1,-1)  \n",
    "  105    (1,1)   (1,0)   (1,0)   (0,0)   \n",
    "  106    (1,1)   (1,0)   (1,0)   (1,1)   \n",
    "  107    (1,1)   (1,0)   (1,0)   (1,0)   \n",
    "  108    (1,1)   (1,0)   (1,0)   (1,-1)  \n",
    "  109    (1,1)   (1,0)   (1,-1)  (0,0)   \n",
    "  110    (1,1)   (1,0)   (1,-1)  (1,1)   \n",
    "  111    (1,1)   (1,0)   (1,-1)  (1,0)   \n",
    "  112    (1,1)   (1,0)   (1,-1)  (1,-1)  \n",
    "  113    (1,1)   (1,-1)  (0,0)   (0,0)   \n",
    "  114    (1,1)   (1,-1)  (0,0)   (1,1)   \n",
    "  115    (1,1)   (1,-1)  (0,0)   (1,0)   \n",
    "  116    (1,1)   (1,-1)  (0,0)   (1,-1)  \n",
    "  117    (1,1)   (1,-1)  (1,1)   (0,0)   \n",
    "  118    (1,1)   (1,-1)  (1,1)   (1,1)   \n",
    "  119    (1,1)   (1,-1)  (1,1)   (1,0)   \n",
    "  120    (1,1)   (1,-1)  (1,1)   (1,-1)  \n",
    "  121    (1,1)   (1,-1)  (1,0)   (0,0)   \n",
    "  122    (1,1)   (1,-1)  (1,0)   (1,1)   \n",
    "  123    (1,1)   (1,-1)  (1,0)   (1,0)   \n",
    "  124    (1,1)   (1,-1)  (1,0)   (1,-1)  \n",
    "  125    (1,1)   (1,-1)  (1,-1)  (0,0)   \n",
    "  126    (1,1)   (1,-1)  (1,-1)  (1,1)   \n",
    "  127    (1,1)   (1,-1)  (1,-1)  (1,0)   \n",
    "  128    (1,1)   (1,-1)  (1,-1)  (1,-1)  \n",
    "  129    (1,0)   (0,0)   (0,0)   (0,0)   \n",
    "  130    (1,0)   (0,0)   (0,0)   (1,1)   \n",
    "  131    (1,0)   (0,0)   (0,0)   (1,0)   \n",
    "  132    (1,0)   (0,0)   (0,0)   (1,-1)  \n",
    "  133    (1,0)   (0,0)   (1,1)   (0,0)   \n",
    "  134    (1,0)   (0,0)   (1,1)   (1,1)   \n",
    "  135    (1,0)   (0,0)   (1,1)   (1,0)   \n",
    "  136    (1,0)   (0,0)   (1,1)   (1,-1)  \n",
    "  137    (1,0)   (0,0)   (1,0)   (0,0)   \n",
    "  138    (1,0)   (0,0)   (1,0)   (1,1)   \n",
    "  139    (1,0)   (0,0)   (1,0)   (1,0)   \n",
    "  140    (1,0)   (0,0)   (1,0)   (1,-1)  \n",
    "  141    (1,0)   (0,0)   (1,-1)  (0,0)   \n",
    "  142    (1,0)   (0,0)   (1,-1)  (1,1)   \n",
    "  143    (1,0)   (0,0)   (1,-1)  (1,0)   \n",
    "  144    (1,0)   (0,0)   (1,-1)  (1,-1)  \n",
    "  145    (1,0)   (1,1)   (0,0)   (0,0)   \n",
    "  146    (1,0)   (1,1)   (0,0)   (1,1)   \n",
    "  147    (1,0)   (1,1)   (0,0)   (1,0)   \n",
    "  148    (1,0)   (1,1)   (0,0)   (1,-1)  \n",
    "  149    (1,0)   (1,1)   (1,1)   (0,0)   \n",
    "  150    (1,0)   (1,1)   (1,1)   (1,1)   \n",
    "  151    (1,0)   (1,1)   (1,1)   (1,0)   \n",
    "  152    (1,0)   (1,1)   (1,1)   (1,-1)  \n",
    "  153    (1,0)   (1,1)   (1,0)   (0,0)   \n",
    "  154    (1,0)   (1,1)   (1,0)   (1,1)   \n",
    "  155    (1,0)   (1,1)   (1,0)   (1,0)   \n",
    "  156    (1,0)   (1,1)   (1,0)   (1,-1)  \n",
    "  157    (1,0)   (1,1)   (1,-1)  (0,0)   \n",
    "  158    (1,0)   (1,1)   (1,-1)  (1,1)   \n",
    "  159    (1,0)   (1,1)   (1,-1)  (1,0)   \n",
    "  160    (1,0)   (1,1)   (1,-1)  (1,-1)  \n",
    "  161    (1,0)   (1,0)   (0,0)   (0,0)   \n",
    "  162    (1,0)   (1,0)   (0,0)   (1,1)   \n",
    "  163    (1,0)   (1,0)   (0,0)   (1,0)   \n",
    "  164    (1,0)   (1,0)   (0,0)   (1,-1)  \n",
    "  165    (1,0)   (1,0)   (1,1)   (0,0)   \n",
    "  166    (1,0)   (1,0)   (1,1)   (1,1)   \n",
    "  167    (1,0)   (1,0)   (1,1)   (1,0)   \n",
    "  168    (1,0)   (1,0)   (1,1)   (1,-1)  \n",
    "  169    (1,0)   (1,0)   (1,0)   (0,0)   \n",
    "  170    (1,0)   (1,0)   (1,0)   (1,1)   \n",
    "  171    (1,0)   (1,0)   (1,0)   (1,0)   \n",
    "  172    (1,0)   (1,0)   (1,0)   (1,-1)  \n",
    "  173    (1,0)   (1,0)   (1,-1)  (0,0)   \n",
    "  174    (1,0)   (1,0)   (1,-1)  (1,1)   \n",
    "  175    (1,0)   (1,0)   (1,-1)  (1,0)   \n",
    "  176    (1,0)   (1,0)   (1,-1)  (1,-1)  \n",
    "  177    (1,0)   (1,-1)  (0,0)   (0,0)   \n",
    "  178    (1,0)   (1,-1)  (0,0)   (1,1)   \n",
    "  179    (1,0)   (1,-1)  (0,0)   (1,0)   \n",
    "  180    (1,0)   (1,-1)  (0,0)   (1,-1)  \n",
    "  181    (1,0)   (1,-1)  (1,1)   (0,0)   \n",
    "  182    (1,0)   (1,-1)  (1,1)   (1,1)   \n",
    "  183    (1,0)   (1,-1)  (1,1)   (1,0)   \n",
    "  184    (1,0)   (1,-1)  (1,1)   (1,-1)  \n",
    "  185    (1,0)   (1,-1)  (1,0)   (0,0)   \n",
    "  186    (1,0)   (1,-1)  (1,0)   (1,1)   \n",
    "  187    (1,0)   (1,-1)  (1,0)   (1,0)   \n",
    "  188    (1,0)   (1,-1)  (1,0)   (1,-1)  \n",
    "  189    (1,0)   (1,-1)  (1,-1)  (0,0)   \n",
    "  190    (1,0)   (1,-1)  (1,-1)  (1,1)   \n",
    "  191    (1,0)   (1,-1)  (1,-1)  (1,0)   \n",
    "  192    (1,0)   (1,-1)  (1,-1)  (1,-1)  \n",
    "  193    (1,-1)  (0,0)   (0,0)   (0,0)   \n",
    "  194    (1,-1)  (0,0)   (0,0)   (1,1)   \n",
    "  195    (1,-1)  (0,0)   (0,0)   (1,0)   \n",
    "  196    (1,-1)  (0,0)   (0,0)   (1,-1)  \n",
    "  197    (1,-1)  (0,0)   (1,1)   (0,0)   \n",
    "  198    (1,-1)  (0,0)   (1,1)   (1,1)   \n",
    "  199    (1,-1)  (0,0)   (1,1)   (1,0)   \n",
    "  200    (1,-1)  (0,0)   (1,1)   (1,-1)  \n",
    "  201    (1,-1)  (0,0)   (1,0)   (0,0)   \n",
    "  202    (1,-1)  (0,0)   (1,0)   (1,1)   \n",
    "  203    (1,-1)  (0,0)   (1,0)   (1,0)   \n",
    "  204    (1,-1)  (0,0)   (1,0)   (1,-1)  \n",
    "  205    (1,-1)  (0,0)   (1,-1)  (0,0)   \n",
    "  206    (1,-1)  (0,0)   (1,-1)  (1,1)   \n",
    "  207    (1,-1)  (0,0)   (1,-1)  (1,0)   \n",
    "  208    (1,-1)  (0,0)   (1,-1)  (1,-1)  \n",
    "  209    (1,-1)  (1,1)   (0,0)   (0,0)   \n",
    "  210    (1,-1)  (1,1)   (0,0)   (1,1)   \n",
    "  211    (1,-1)  (1,1)   (0,0)   (1,0)   \n",
    "  212    (1,-1)  (1,1)   (0,0)   (1,-1)  \n",
    "  213    (1,-1)  (1,1)   (1,1)   (0,0)   \n",
    "  214    (1,-1)  (1,1)   (1,1)   (1,1)   \n",
    "  215    (1,-1)  (1,1)   (1,1)   (1,0)   \n",
    "  216    (1,-1)  (1,1)   (1,1)   (1,-1)  \n",
    "  217    (1,-1)  (1,1)   (1,0)   (0,0)   \n",
    "  218    (1,-1)  (1,1)   (1,0)   (1,1)   \n",
    "  219    (1,-1)  (1,1)   (1,0)   (1,0)   \n",
    "  220    (1,-1)  (1,1)   (1,0)   (1,-1)  \n",
    "  221    (1,-1)  (1,1)   (1,-1)  (0,0)   \n",
    "  222    (1,-1)  (1,1)   (1,-1)  (1,1)   \n",
    "  223    (1,-1)  (1,1)   (1,-1)  (1,0)   \n",
    "  224    (1,-1)  (1,1)   (1,-1)  (1,-1)  \n",
    "  225    (1,-1)  (1,0)   (0,0)   (0,0)   \n",
    "  226    (1,-1)  (1,0)   (0,0)   (1,1)   \n",
    "  227    (1,-1)  (1,0)   (0,0)   (1,0)   \n",
    "  228    (1,-1)  (1,0)   (0,0)   (1,-1)  \n",
    "  229    (1,-1)  (1,0)   (1,1)   (0,0)   \n",
    "  230    (1,-1)  (1,0)   (1,1)   (1,1)   \n",
    "  231    (1,-1)  (1,0)   (1,1)   (1,0)   \n",
    "  232    (1,-1)  (1,0)   (1,1)   (1,-1)  \n",
    "  233    (1,-1)  (1,0)   (1,0)   (0,0)   \n",
    "  234    (1,-1)  (1,0)   (1,0)   (1,1)   \n",
    "  235    (1,-1)  (1,0)   (1,0)   (1,0)   \n",
    "  236    (1,-1)  (1,0)   (1,0)   (1,-1)  \n",
    "  237    (1,-1)  (1,0)   (1,-1)  (0,0)   \n",
    "  238    (1,-1)  (1,0)   (1,-1)  (1,1)   \n",
    "  239    (1,-1)  (1,0)   (1,-1)  (1,0)   \n",
    "  240    (1,-1)  (1,0)   (1,-1)  (1,-1)  \n",
    "  241    (1,-1)  (1,-1)  (0,0)   (0,0)   \n",
    "  242    (1,-1)  (1,-1)  (0,0)   (1,1)   \n",
    "  243    (1,-1)  (1,-1)  (0,0)   (1,0)   \n",
    "  244    (1,-1)  (1,-1)  (0,0)   (1,-1)  \n",
    "  245    (1,-1)  (1,-1)  (1,1)   (0,0)   \n",
    "  246    (1,-1)  (1,-1)  (1,1)   (1,1)   \n",
    "  247    (1,-1)  (1,-1)  (1,1)   (1,0)   \n",
    "  248    (1,-1)  (1,-1)  (1,1)   (1,-1)  \n",
    "  249    (1,-1)  (1,-1)  (1,0)   (0,0)   \n",
    "  250    (1,-1)  (1,-1)  (1,0)   (1,1)   \n",
    "  251    (1,-1)  (1,-1)  (1,0)   (1,0)   \n",
    "  252    (1,-1)  (1,-1)  (1,0)   (1,-1)  \n",
    "  253    (1,-1)  (1,-1)  (1,-1)  (0,0)   \n",
    "  254    (1,-1)  (1,-1)  (1,-1)  (1,1)   \n",
    "  255    (1,-1)  (1,-1)  (1,-1)  (1,0)   \n",
    "  256    (1,-1)  (1,-1)  (1,-1)  (1,-1)\"\"\"\n",
    "\n",
    "data_ala = read_spinach_info(text4)\n",
    "\n",
    "basis_ala = build_list_ISTs(data_ala)\n",
    "prefacts,Symb_ALA_basis = build_symbolic_list_ISTs(data_ala)\n",
    "\n",
    "#Normbasis = NormalizeBasis(basis,n_qubits=4,checkOrth=True) I have verified the orthonormalization of the basis\n",
    "Normbasis_ala = NormalizeBasis(basis_ala,n_qubits=4,checkOrth=False)\n",
    "Normbasis_ala = np.array(Normbasis_ala)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "###QDrift for the Hamiltonian simulation of the coherent part sounds like a simplified aapproach to this...\n",
    "\n",
    "#First we need to generate the list of operators to sample over in the QDrift channel, we need to generate the jump operators...\n",
    "\n",
    "from analytical_fit import Get_Det_And_Rates, get_chemical_shifts\n",
    "from basis_utils import  MatRepLib\n",
    "from simulation_utils import GenH0_Ham\n",
    "\n",
    "B0 = 18.78\n",
    "offset = 3759.37\n",
    "freq1 = -799607997.1075\n",
    "freq2 = -799606158.0159\n",
    "freq3 = -799606158.0159\n",
    "freq4 = -799606158.0159\n",
    "\n",
    "freqs = np.array([freq1,freq2,freq3,freq4])\n",
    "tc = 18.8e-12\n",
    "coords = np.array([\n",
    "    [0.6861   ,0.2705   ,1.5010],\n",
    "    [1.3077    ,1.1298   ,-1.3993],\n",
    "    [0.7905    ,2.2125   ,-0.0860],\n",
    "    [2.3693    ,1.3798    ,0.0233]\n",
    "]\n",
    ")\n",
    "coords =coords*1e-10\n",
    "Nspins =4\n",
    "gammaH = 2.6752e+08\n",
    "\n",
    "Jcoups = np.zeros([Nspins,Nspins])\n",
    "\n",
    "Jcoups[0,1] = 7.0\n",
    "Jcoups[0,2] = 7.0\n",
    "Jcoups[0,3] = 7.0\n",
    "\n",
    "\n",
    "####Getting the corresponding jump operators for the set of parameters chosen for the simulation of the spectrum\n",
    "\n",
    "zeeman_scalar_1 = 3.69\n",
    "zeeman_scalar_2 = 1.39\n",
    "zeeman_scalar_3 = 1.39\n",
    "zeeman_scalar_4 = 1.39\n",
    "\n",
    "zeeman_scalars = [zeeman_scalar_1,zeeman_scalar_2,zeeman_scalar_3,zeeman_scalar_4]\n",
    "\n",
    "chem_shifts = get_chemical_shifts(gammaH,B0,zeeman_scalars)\n",
    "\n",
    "#list_jumps, list_damp_rates, list_dets=Get_Det_And_Rates(2*np.pi*freqs,tc,coords,Nspins,gammaH,chem_shifts)\n",
    "#list_jumps, list_symb_rates, list_damp_rates, list_dets = Get_Det_And_Rates_latex(2*np.pi*freqs,tc,coords,Nspins,gammaH,chem_shifts)\n",
    "\n",
    "list_jumps, list_damp_rates, list_dets = Get_Det_And_Rates(freqs,tc,coords,Nspins,gammaH,chem_shifts)\n",
    "\n",
    "###We verified, as expected that the dominant relaxation channels correspond to ZZ relaxation channels Z0Z1 Z0Z2 Z1Z2\n",
    "\n",
    "#We build their corresponding matrix representation in the Pauli basis...\n",
    "#ListJumps = []\n",
    "\n",
    "\n",
    "\n",
    "#ListJumps.append(1.0813667*MatRepLib(Normbasis_ala,Sz(1)*Sz(2),Sz(1)*Sz(2),n_qubits=4))\n",
    "#ListJumps.append(1.047784*MatRepLib(Normbasis_ala,Sz(2)*Sz(3),Sz(2)*Sz(3),n_qubits=4))\n",
    "#ListJumps.append(1.0328497*MatRepLib(Normbasis_ala,Sz(1)*Sz(3),Sz(1)*Sz(3),n_qubits=4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We build the Hamiltonian fragments that comprise the coherent Hamiltonian from Spinach-computed matrices...\n",
    "\n",
    "loadMat = spio.loadmat('./data/NOESYdata_ALA_experiment_miscHJs.mat',squeeze_me=True)\n",
    "\n",
    "\n",
    "H_ala_coh_tot = loadMat['p']['H'].item().toarray()\n",
    "H_ala_noJs = loadMat['p']['H_noJs'].item().toarray()\n",
    "H_ala_J12 = loadMat['p']['H_J12'].item().toarray()\n",
    "H_ala_J13 = loadMat['p']['H_J13'].item().toarray()\n",
    "H_ala_J14 = loadMat['p']['H_J14'].item().toarray()\n",
    "\n",
    "Zeem_Ham = H_ala_noJs\n",
    "\n",
    "S1S2 = H_ala_J12 - Zeem_Ham\n",
    "S1S3 = H_ala_J13 - Zeem_Ham\n",
    "S1S4 = H_ala_J14 - Zeem_Ham\n",
    "\n",
    "ListInts = [S1S2,S1S3,S1S4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmax = 10\n",
    "#fid1_effJN10, fid2_effJN10, fid3_effJN10, fid4_effJN10  = GenFID_SingJump_noTmix_GradField_SetMaxDisc(Zeem_Ham,ListInts,JumpOps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly,Lz,Nmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Saving everything in a file for later retrieval...\n",
    "ALA_exp_params = {}\n",
    "ALA_exp_params['ZeemanH'] = Zeem_Ham\n",
    "ALA_exp_params['ListInts'] =  ListInts\n",
    "ALA_exp_params['JumpOps'] = JumpOps\n",
    "ALA_exp_params['T1'] = T1\n",
    "ALA_exp_params['T2'] = T2\n",
    "ALA_exp_params['rho0'] = rho0\n",
    "ALA_exp_params['coil'] = coil\n",
    "ALA_exp_params['tmix'] = tmix\n",
    "ALA_exp_params['dt1'] = dt1\n",
    "ALA_exp_params['dt2'] = dt2\n",
    "ALA_exp_params['Lx'] = Lx\n",
    "ALA_exp_params['Ly'] = Ly\n",
    "ALA_exp_params['Lz'] = Lz\n",
    "\n",
    "#ALA_exp_params['dt2'] = dt2\n",
    "with open('./data/ALA_expGradField_AllParams.pk', 'wb') as handle:\n",
    "    pickle.dump(ALA_exp_params, handle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "Norm_ops, List_weights = Normalize_and_weightOps([Zeem_Ham] + ListInts)\n",
    "List_weights = np.array(List_weights)\n",
    "Gamma = np.sum(List_weights)\n",
    "pks = (1.0 / Gamma) * List_weights\n",
    "\n",
    "L_dt1 = BuildCohQDriftChann_fromOps(dt1,Norm_ops,pks,Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_test = pulse_90x@np.copy(rho0)\n",
    "rho_ref = pulse_90x@np.copy(rho0)\n",
    "\n",
    "for i in range(1024):\n",
    "    rho_test = L_dt1@rho_test\n",
    "    rho_ref = expm(-1j*H_ala_coh_tot*dt1)@rho_ref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013415813273991127"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(rho_test - rho_ref)/np.linalg.norm(rho_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.967910899005311"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(L_dt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.291167361697463e-10"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(H_ala_coh_tot-Zeem_Ham-sum(ListInts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006252"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003126"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Load data \n",
    "f= open('./data/ALA_SimplifiedFIDParallel10maxLayers.pk','rb')\n",
    "dat =pickle.load(f)\n",
    "\n",
    "fid1_N10 = dat['fid1']\n",
    "fid2_N10 = dat['fid2']\n",
    "fid3_N10 = dat['fid3']\n",
    "fid4_N10 = dat['fid4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_fid = fid1_N10 - fid3_N10\n",
    "sin_fid = fid2_N10 - fid4_N10\n",
    "\n",
    "savemat('ALA_truncR_FIDcos_effJGrad_N10.mat', {'FID_cos': cos_fid})\n",
    "savemat('ALA_truncR_FIDsin_effJGrad_N10.mat', {'FID_sin': sin_fid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open('./data/ALA_SimplifiedFIDParallel_noQDrift.pk','rb')\n",
    "dat =pickle.load(f)\n",
    "\n",
    "fid1 = dat['fid1']\n",
    "fid2 = dat['fid2']\n",
    "fid3 = dat['fid3']\n",
    "fid4 = dat['fid4']\n",
    "\n",
    "cos_fid = fid1 - fid3\n",
    "sin_fid = fid2 - fid4\n",
    "\n",
    "savemat('ALA_truncR_FIDcos_effJGrad_noQdrift.mat', {'FID_cos': cos_fid})\n",
    "savemat('ALA_truncR_FIDsin_effJGrad_noQDrift.mat', {'FID_sin': sin_fid})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_fid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open('./data/ALA_SimplifiedFIDParallelmaxNQD.pk','rb')\n",
    "dat =pickle.load(f)\n",
    "\n",
    "fid1 = dat['fid1']\n",
    "fid2 = dat['fid2']\n",
    "fid3 = dat['fid3']\n",
    "fid4 = dat['fid4']\n",
    "\n",
    "cos_fid = fid1 - fid3\n",
    "sin_fid = fid2 - fid4\n",
    "\n",
    "savemat('ALA_truncR_FIDcos_effJGrad_maxQD.mat', {'FID_cos': cos_fid})\n",
    "savemat('ALA_truncR_FIDsin_effJGrad_maxQD.mat', {'FID_sin': sin_fid})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10240, 10240)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_fid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f= open('./data/ALA_SimplifiedFIDParallel_noQDrift_noJs.pk','rb')\n",
    "dat =pickle.load(f)\n",
    "\n",
    "fid1 = dat['fid1']\n",
    "fid2 = dat['fid2']\n",
    "fid3 = dat['fid3']\n",
    "fid4 = dat['fid4']\n",
    "\n",
    "cos_fid = fid1 - fid3\n",
    "sin_fid = fid2 - fid4\n",
    "\n",
    "savemat('ALA_truncR_FIDcos_effJGrad_noQD_noJs.mat', {'FID_cos': cos_fid})\n",
    "savemat('ALA_truncR_FIDsin_effJGrad_noQD_noJs.mat', {'FID_sin': sin_fid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BQSKit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
