{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Estimation of time steps and number of layers needed for a given spectrum precision using either a dterministic or qdrift open quantum system simulation of the system\n",
    "import openfermion as of\n",
    "\n",
    "import sys\n",
    "sys.path.append('./utils/')\n",
    "\n",
    "from basis_utils import Sz,Sx,Sz, Sy\n",
    "from basis_utils import read_spinach_info, build_list_ISTs, NormalizeBasis, build_symbolic_list_ISTs, MatRepLib\n",
    "from simulation_utils import GenH0_Ham, HamMatRep, GenNOESYSpectrum, sqcosbell_2d_apod, GenFIDsignals\n",
    "import scipy.io as spio\n",
    "#from \n",
    "from scipy.linalg import expm\n",
    "import cirq\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import savemat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.floor(10/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenFID_DetTrotsignals(Ham,List_jumps,T1,T2,rho0,coil,tmix,dt1,dt2,dtmix,Lx,Ly):\n",
    "    \"\"\"\n",
    "    Implement a first-order deterministic Trotter simulation of the FID NOESY signals, to numerically explore optimization of number of Trotter steps needed in the simulation\n",
    "    for a target precision\n",
    "    Args:\n",
    "    Ham: matrix representation of the \"coherent\" part of the Liouvillian siperoperator\n",
    "    List_jumps: list of the matrix representation of the jump operators\n",
    "    T1: maximal simulation time for the first phase of the protocol\n",
    "    T2: maximal simulation time for the second phase of the protocol\n",
    "    rho0: initial density matrix vector\n",
    "    coil: vector that represents the obervable we trace over to compute FID\n",
    "    tmix: total mixing time\n",
    "    \"\"\"\n",
    "\n",
    "    #This is the convention for our Trotter step: apply first the coherent part of the super-Liouvillian operator, followed by the jump operators in the order they appear in the array...\n",
    "\n",
    "    L_dt1 = expm(-1j*Ham*dt1)\n",
    "\n",
    "    for i in range(len(List_jumps)):\n",
    "        #print(\"Jump operator is\",List_jumps[i])\n",
    "        L_dt1 = expm(List_jumps[i]*dt1)@L_dt1\n",
    "\n",
    "    R = np.copy(List_jumps[0])\n",
    "    for i in range(len(List_jumps)-1):\n",
    "        R+=List_jumps[i]\n",
    "\n",
    "    print(\"Difference between Trotterized and exact L_dt1: \",np.linalg.norm(L_dt1-expm((-1j*Ham+R)*dt1)))\n",
    "\n",
    "    L_dt2 = expm(-1j*Ham*dt2)\n",
    "\n",
    "    for i in range(len(List_jumps)):\n",
    "        L_dt2 = expm(List_jumps[i]*dt2)@L_dt2\n",
    "\n",
    "    print(\"Difference between Trotterized and exact L_dt2: \",np.linalg.norm(L_dt2-expm((-1j*Ham+R)*dt2)))\n",
    "\n",
    "    #Dim = Ham.shape[0]\n",
    "    #Lnet = Ham+1j*R \n",
    "    #L_dt1 = expm(-1j*Lnet*dt1)\n",
    "    #L_dt2 = expm(-1j*Lnet*dt2)\n",
    "    L_dtmix = expm(-1j*Ham*dtmix)\n",
    "\n",
    "    for i in range(len(List_jumps)):\n",
    "        L_dtmix=expm(List_jumps[i]*dtmix)@L_dtmix\n",
    "\n",
    "\n",
    "    ###Number of Trotter steps for the simulation of the mixing free evolution...\n",
    "    Ntmix = int(np.floor(tmix/dtmix))\n",
    "    #Number of Trotter steps for simulation of T1\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    print(\"Number of Trotter steps for simulation of T1\",Tpts1)\n",
    "    print(\"Number of Trotter steps for simulation of T2\",Tpts2)\n",
    "    print(\"Number of Trotter steps for simulation of tmix\", Ntmix)\n",
    "    \n",
    "    pulse_mix = np.copy(L_dtmix)\n",
    "    for i in range(Ntmix):\n",
    "        pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*dtmix)))\n",
    "\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        rho_temp = np.dot(L_dt1,rho_temp)\n",
    "        rho_stack.append(rho_temp)\n",
    "\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1.append(pulse_90y@pulse_mix@pulse_90x@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@pulse_mix@pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90y@pulse_mix@pulse_90mx@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90y@pulse_mix@pulse_90my@rho_stack[i])\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho1 = rho_stack1_1[i]\n",
    "        rho2 = rho_stack1_2[i]\n",
    "        rho3 = rho_stack1_3[i]\n",
    "        rho4 = rho_stack1_4[i]\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1)\n",
    "            rho1 = L_dt2@rho1\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2)\n",
    "            rho2 = L_dt2@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3)\n",
    "            rho3 = L_dt2@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4)\n",
    "            rho4 = L_dt2@rho4\n",
    "    \n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n",
    "\n",
    "def GenNOESYSpectrum_fromFID(fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4,zerofill1,zerofill2,returnFID=True):\n",
    "\n",
    "    #fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4 = GenFIDsignals(Ham,R,Tpts1,Tpts2,rho0,coil,tmix,dt1,dt2,Lx,Ly)\n",
    "    \n",
    "    fid_test_cos = fid_temp_1 - fid_temp_3\n",
    "    fid_test_sin = fid_temp_2 - fid_temp_4\n",
    "\n",
    "    fid_cos = sqcosbell_2d_apod(fid_test_cos)\n",
    "    fid_sin = sqcosbell_2d_apod(fid_test_sin)\n",
    "\n",
    "    f1_cos = np.real(np.fft.fftshift(np.fft.fft2(fid_cos,[zerofill2],[0]),[0]))\n",
    "    f1_sin = np.real(np.fft.fftshift(np.fft.fft2(fid_sin,[zerofill2],[0]),[0]))\n",
    "\n",
    "\n",
    "    f1_states = f1_cos-1j*f1_sin\n",
    "\n",
    "    spectrum = np.fft.fftshift(np.fft.fft2(f1_states,[zerofill1],[1]),[1])\n",
    "    if returnFID:\n",
    "        ###NOTE: return the FID witouth post-processing\n",
    "        return spectrum, fid_test_cos-1j*fid_test_sin\n",
    "    else:\n",
    "        return spectrum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The DFG case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"1      (0,0)   (0,0)   \n",
    "  2      (0,0)   (1,1)   \n",
    "  3      (0,0)   (1,0)   \n",
    "  4      (0,0)   (1,-1)  \n",
    "  5      (1,1)   (0,0)   \n",
    "  6      (1,1)   (1,1)   \n",
    "  7      (1,1)   (1,0)   \n",
    "  8      (1,1)   (1,-1)  \n",
    "  9      (1,0)   (0,0)   \n",
    "  10     (1,0)   (1,1)   \n",
    "  11     (1,0)   (1,0)   \n",
    "  12     (1,0)   (1,-1)  \n",
    "  13     (1,-1)  (0,0)   \n",
    "  14     (1,-1)  (1,1)   \n",
    "  15     (1,-1)  (1,0)   \n",
    "  16     (1,-1)  (1,-1)  \n",
    "\"\"\"\n",
    "\n",
    "data = read_spinach_info(text)\n",
    "\n",
    "basis = build_list_ISTs(data)\n",
    "prefacts,Symb_basis = build_symbolic_list_ISTs(data)\n",
    "\n",
    "#Normbasis = NormalizeBasis(basis,n_qubits=4,checkOrth=True) I have verified the orthonormalization of the basis\n",
    "Normbasis = NormalizeBasis(basis,n_qubits=2,checkOrth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###For the direct simulation approach we consider two-approaches: deterministic Trotter formula, and QDrift...\n",
    "\n",
    "#We can perform the simulation in the Spinach basis, using the tools we already have access to...\n",
    "offset = -46681\n",
    "B0 = 9.3933\n",
    "zeeman_scalar_1 = -113.8796\n",
    "zeeman_scalar_2 = -129.8002\n",
    "zeeman_scalars = [zeeman_scalar_1,zeeman_scalar_2]\n",
    "Jcoup = 238.0633\n",
    "Jcoups = np.zeros([2,2])\n",
    "Jcoups[0,1] = Jcoup\n",
    "gammaF = 251814800\n",
    "#GenH0_Ham(offset,B0,zeeman_scalars,Jcoups,gammaF)\n",
    "\n",
    "#freqs = [-2996.74,2996.74] # we were missing a factor of 2!\n",
    "#freqs = [0.0,2*2996.74]\n",
    "#freqs = [-11968.88/(2*np.pi),6860.19/(2*np.pi)]\n",
    "\n",
    "#H0_Ham_dfg = GenH0_Ham_allparam(freqs,Jcoups,2)\n",
    "\n",
    "#zeeman_scalars = [0.0,-15.920]\n",
    "#zeeman_scalars = [0.0, -15.920599]\n",
    "#offset=0.0\n",
    "\n",
    "H0_dfg_ref = GenH0_Ham(offset,B0,zeeman_scalars,Jcoups,gammaF)\n",
    "\n",
    "\n",
    "#H0_dfg_frame =  HamMatRep(H0_Ham_dfg,Normbasis,n_qubits=2)\n",
    "\n",
    "#H0_dfg_frame =  HamMatRep(H0_Ham_dfg,Normbasis)\n",
    "H0_dfg_mat =  HamMatRep(H0_dfg_ref,Normbasis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###List of jump operators in their matrix representation...\n",
    "List_jumps=[]\n",
    "\n",
    "List_jumps.append(4.38*MatRepLib(Normbasis,Sz(0)*Sz(1),Sz(0)*Sz(1),n_qubits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Simulation to get FID signals...\n",
    "loadMat = spio.loadmat('./data/DFG.mat',squeeze_me=True)\n",
    "AuxMats = spio.loadmat('./data/DFG_NOESYmatrices.mat',squeeze_me=True)\n",
    "\n",
    "###These are the parameters generated by Spinach\n",
    "Ham = loadMat['p']['H'].item()\n",
    "R = loadMat['p']['R'].item() # We can substitute this by any approximation to the relaxation matrix\n",
    "t_grid1 = loadMat['p']['time_grid1'].item()\n",
    "t_grid2 = loadMat['p']['time_grid2'].item()\n",
    "\n",
    "###Dynamical evolution for calculation of 2D spectra...\n",
    "##TODO: we can simply modify the script to incorporate 1) retrieval of synthesized circuits,\n",
    "#and 2) the already-developed circuit simulator\n",
    "\n",
    "Tpts1 = len(t_grid1)\n",
    "Tpts2 = len(t_grid2)\n",
    "\n",
    "Dim = Ham.shape[0]\n",
    "\n",
    "rho0 = np.array(AuxMats['rho0'].toarray())\n",
    "rho0 = rho0.flatten()\n",
    "coil = AuxMats['coil']\n",
    "\n",
    "\n",
    "tmix = 0.5\n",
    "dt1 = 1.1561e-04\n",
    "dt2 = 1.1561e-04\n",
    "\n",
    "##Parameters for Fourier transform\n",
    "zerofill1 = 1024\n",
    "zerofill2 = 1024\n",
    "\n",
    "##Definition of pulses in the experiment...\n",
    "#This also depends on the definition of the basis....\n",
    "Lx = AuxMats['Lx'].toarray()\n",
    "Ly = AuxMats['Ly'].toarray()\n",
    "\n",
    "\n",
    "\n",
    "#GenFID_DetTrotsignals(H0_dfg_mat,List_jumps,T1,T2,rho0,coil,tmix,dt1,dt2,dtmix,Lx,Ly)\n",
    "fid_1_ref, fid_2_ref, fid_3_ref, fid_4_ref =  GenFIDsignals(Ham,List_jumps[0],Tpts1,Tpts2,rho0,coil,tmix,dt1,dt2,Lx,Ly)\n",
    "#GenNOESYSpectrum(Ham,R,Tpts1,Tpts2,rho0,coil,tmix,dt1,dt2,zerofill1,zerofill2,Lx,Ly,returnFID=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between Trotterized and exact L_dt1:  1.1863596207543848e-15\n",
      "Difference between Trotterized and exact L_dt2:  1.1863596207543848e-15\n",
      "Number of Trotter steps for simulation of T1 512\n",
      "Number of Trotter steps for simulation of T2 1024\n",
      "Number of Trotter steps for simulation of tmix 49999\n",
      "Difference between Trotterized pulse_mix and reference pulse_mix: 4.983979294968198\n"
     ]
    }
   ],
   "source": [
    "T1 = Tpts1*dt1\n",
    "T2 = Tpts2*dt2\n",
    "dtmix = 1e-5\n",
    "fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4 = GenFID_DetTrotsignals(H0_dfg_mat,List_jumps,T1,T2,rho0,coil,tmix,dt1,dt2,dtmix,Lx,Ly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving results for plotting in Matlab...\n",
    "\n",
    "savemat('Ref_truncR_FID_DFG_cos.mat', {'FID_cos': fid_1_ref-fid_3_ref})\n",
    "savemat('Ref_truncR_FID_DFG_sin.mat', {'FID_sin': fid_2_ref-fid_4_ref})\n",
    "\n",
    "savemat('Trot_truncR_FID_DFG_cos.mat', {'FID_cos': fid_temp_1-fid_temp_3})\n",
    "savemat('Trot_truncR_FID_DFG_sin.mat', {'FID_sin': fid_temp_2-fid_temp_4})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Alanine case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4=\"\"\"1      (0,0)   (0,0)   (0,0)   (0,0)   \n",
    "  2      (0,0)   (0,0)   (0,0)   (1,1)   \n",
    "  3      (0,0)   (0,0)   (0,0)   (1,0)   \n",
    "  4      (0,0)   (0,0)   (0,0)   (1,-1)  \n",
    "  5      (0,0)   (0,0)   (1,1)   (0,0)   \n",
    "  6      (0,0)   (0,0)   (1,1)   (1,1)   \n",
    "  7      (0,0)   (0,0)   (1,1)   (1,0)   \n",
    "  8      (0,0)   (0,0)   (1,1)   (1,-1)  \n",
    "  9      (0,0)   (0,0)   (1,0)   (0,0)   \n",
    "  10     (0,0)   (0,0)   (1,0)   (1,1)   \n",
    "  11     (0,0)   (0,0)   (1,0)   (1,0)   \n",
    "  12     (0,0)   (0,0)   (1,0)   (1,-1)  \n",
    "  13     (0,0)   (0,0)   (1,-1)  (0,0)   \n",
    "  14     (0,0)   (0,0)   (1,-1)  (1,1)   \n",
    "  15     (0,0)   (0,0)   (1,-1)  (1,0)   \n",
    "  16     (0,0)   (0,0)   (1,-1)  (1,-1)  \n",
    "  17     (0,0)   (1,1)   (0,0)   (0,0)   \n",
    "  18     (0,0)   (1,1)   (0,0)   (1,1)   \n",
    "  19     (0,0)   (1,1)   (0,0)   (1,0)   \n",
    "  20     (0,0)   (1,1)   (0,0)   (1,-1)  \n",
    "  21     (0,0)   (1,1)   (1,1)   (0,0)   \n",
    "  22     (0,0)   (1,1)   (1,1)   (1,1)   \n",
    "  23     (0,0)   (1,1)   (1,1)   (1,0)   \n",
    "  24     (0,0)   (1,1)   (1,1)   (1,-1)  \n",
    "  25     (0,0)   (1,1)   (1,0)   (0,0)   \n",
    "  26     (0,0)   (1,1)   (1,0)   (1,1)   \n",
    "  27     (0,0)   (1,1)   (1,0)   (1,0)   \n",
    "  28     (0,0)   (1,1)   (1,0)   (1,-1)  \n",
    "  29     (0,0)   (1,1)   (1,-1)  (0,0)   \n",
    "  30     (0,0)   (1,1)   (1,-1)  (1,1)   \n",
    "  31     (0,0)   (1,1)   (1,-1)  (1,0)   \n",
    "  32     (0,0)   (1,1)   (1,-1)  (1,-1)  \n",
    "  33     (0,0)   (1,0)   (0,0)   (0,0)   \n",
    "  34     (0,0)   (1,0)   (0,0)   (1,1)   \n",
    "  35     (0,0)   (1,0)   (0,0)   (1,0)   \n",
    "  36     (0,0)   (1,0)   (0,0)   (1,-1)  \n",
    "  37     (0,0)   (1,0)   (1,1)   (0,0)   \n",
    "  38     (0,0)   (1,0)   (1,1)   (1,1)   \n",
    "  39     (0,0)   (1,0)   (1,1)   (1,0)   \n",
    "  40     (0,0)   (1,0)   (1,1)   (1,-1)  \n",
    "  41     (0,0)   (1,0)   (1,0)   (0,0)   \n",
    "  42     (0,0)   (1,0)   (1,0)   (1,1)   \n",
    "  43     (0,0)   (1,0)   (1,0)   (1,0)   \n",
    "  44     (0,0)   (1,0)   (1,0)   (1,-1)  \n",
    "  45     (0,0)   (1,0)   (1,-1)  (0,0)   \n",
    "  46     (0,0)   (1,0)   (1,-1)  (1,1)   \n",
    "  47     (0,0)   (1,0)   (1,-1)  (1,0)   \n",
    "  48     (0,0)   (1,0)   (1,-1)  (1,-1)  \n",
    "  49     (0,0)   (1,-1)  (0,0)   (0,0)   \n",
    "  50     (0,0)   (1,-1)  (0,0)   (1,1)   \n",
    "  51     (0,0)   (1,-1)  (0,0)   (1,0)   \n",
    "  52     (0,0)   (1,-1)  (0,0)   (1,-1)  \n",
    "  53     (0,0)   (1,-1)  (1,1)   (0,0)   \n",
    "  54     (0,0)   (1,-1)  (1,1)   (1,1)   \n",
    "  55     (0,0)   (1,-1)  (1,1)   (1,0)   \n",
    "  56     (0,0)   (1,-1)  (1,1)   (1,-1)  \n",
    "  57     (0,0)   (1,-1)  (1,0)   (0,0)   \n",
    "  58     (0,0)   (1,-1)  (1,0)   (1,1)   \n",
    "  59     (0,0)   (1,-1)  (1,0)   (1,0)   \n",
    "  60     (0,0)   (1,-1)  (1,0)   (1,-1)  \n",
    "  61     (0,0)   (1,-1)  (1,-1)  (0,0)   \n",
    "  62     (0,0)   (1,-1)  (1,-1)  (1,1)   \n",
    "  63     (0,0)   (1,-1)  (1,-1)  (1,0)   \n",
    "  64     (0,0)   (1,-1)  (1,-1)  (1,-1)  \n",
    "  65     (1,1)   (0,0)   (0,0)   (0,0)   \n",
    "  66     (1,1)   (0,0)   (0,0)   (1,1)   \n",
    "  67     (1,1)   (0,0)   (0,0)   (1,0)   \n",
    "  68     (1,1)   (0,0)   (0,0)   (1,-1)  \n",
    "  69     (1,1)   (0,0)   (1,1)   (0,0)   \n",
    "  70     (1,1)   (0,0)   (1,1)   (1,1)   \n",
    "  71     (1,1)   (0,0)   (1,1)   (1,0)   \n",
    "  72     (1,1)   (0,0)   (1,1)   (1,-1)  \n",
    "  73     (1,1)   (0,0)   (1,0)   (0,0)   \n",
    "  74     (1,1)   (0,0)   (1,0)   (1,1)   \n",
    "  75     (1,1)   (0,0)   (1,0)   (1,0)   \n",
    "  76     (1,1)   (0,0)   (1,0)   (1,-1)  \n",
    "  77     (1,1)   (0,0)   (1,-1)  (0,0)   \n",
    "  78     (1,1)   (0,0)   (1,-1)  (1,1)   \n",
    "  79     (1,1)   (0,0)   (1,-1)  (1,0)   \n",
    "  80     (1,1)   (0,0)   (1,-1)  (1,-1)  \n",
    "  81     (1,1)   (1,1)   (0,0)   (0,0)   \n",
    "  82     (1,1)   (1,1)   (0,0)   (1,1)   \n",
    "  83     (1,1)   (1,1)   (0,0)   (1,0)   \n",
    "  84     (1,1)   (1,1)   (0,0)   (1,-1)  \n",
    "  85     (1,1)   (1,1)   (1,1)   (0,0)   \n",
    "  86     (1,1)   (1,1)   (1,1)   (1,1)   \n",
    "  87     (1,1)   (1,1)   (1,1)   (1,0)   \n",
    "  88     (1,1)   (1,1)   (1,1)   (1,-1)  \n",
    "  89     (1,1)   (1,1)   (1,0)   (0,0)   \n",
    "  90     (1,1)   (1,1)   (1,0)   (1,1)   \n",
    "  91     (1,1)   (1,1)   (1,0)   (1,0)   \n",
    "  92     (1,1)   (1,1)   (1,0)   (1,-1)  \n",
    "  93     (1,1)   (1,1)   (1,-1)  (0,0)   \n",
    "  94     (1,1)   (1,1)   (1,-1)  (1,1)   \n",
    "  95     (1,1)   (1,1)   (1,-1)  (1,0)   \n",
    "  96     (1,1)   (1,1)   (1,-1)  (1,-1)  \n",
    "  97     (1,1)   (1,0)   (0,0)   (0,0)   \n",
    "  98     (1,1)   (1,0)   (0,0)   (1,1)   \n",
    "  99     (1,1)   (1,0)   (0,0)   (1,0)   \n",
    "  100    (1,1)   (1,0)   (0,0)   (1,-1)  \n",
    "  101    (1,1)   (1,0)   (1,1)   (0,0)   \n",
    "  102    (1,1)   (1,0)   (1,1)   (1,1)   \n",
    "  103    (1,1)   (1,0)   (1,1)   (1,0)   \n",
    "  104    (1,1)   (1,0)   (1,1)   (1,-1)  \n",
    "  105    (1,1)   (1,0)   (1,0)   (0,0)   \n",
    "  106    (1,1)   (1,0)   (1,0)   (1,1)   \n",
    "  107    (1,1)   (1,0)   (1,0)   (1,0)   \n",
    "  108    (1,1)   (1,0)   (1,0)   (1,-1)  \n",
    "  109    (1,1)   (1,0)   (1,-1)  (0,0)   \n",
    "  110    (1,1)   (1,0)   (1,-1)  (1,1)   \n",
    "  111    (1,1)   (1,0)   (1,-1)  (1,0)   \n",
    "  112    (1,1)   (1,0)   (1,-1)  (1,-1)  \n",
    "  113    (1,1)   (1,-1)  (0,0)   (0,0)   \n",
    "  114    (1,1)   (1,-1)  (0,0)   (1,1)   \n",
    "  115    (1,1)   (1,-1)  (0,0)   (1,0)   \n",
    "  116    (1,1)   (1,-1)  (0,0)   (1,-1)  \n",
    "  117    (1,1)   (1,-1)  (1,1)   (0,0)   \n",
    "  118    (1,1)   (1,-1)  (1,1)   (1,1)   \n",
    "  119    (1,1)   (1,-1)  (1,1)   (1,0)   \n",
    "  120    (1,1)   (1,-1)  (1,1)   (1,-1)  \n",
    "  121    (1,1)   (1,-1)  (1,0)   (0,0)   \n",
    "  122    (1,1)   (1,-1)  (1,0)   (1,1)   \n",
    "  123    (1,1)   (1,-1)  (1,0)   (1,0)   \n",
    "  124    (1,1)   (1,-1)  (1,0)   (1,-1)  \n",
    "  125    (1,1)   (1,-1)  (1,-1)  (0,0)   \n",
    "  126    (1,1)   (1,-1)  (1,-1)  (1,1)   \n",
    "  127    (1,1)   (1,-1)  (1,-1)  (1,0)   \n",
    "  128    (1,1)   (1,-1)  (1,-1)  (1,-1)  \n",
    "  129    (1,0)   (0,0)   (0,0)   (0,0)   \n",
    "  130    (1,0)   (0,0)   (0,0)   (1,1)   \n",
    "  131    (1,0)   (0,0)   (0,0)   (1,0)   \n",
    "  132    (1,0)   (0,0)   (0,0)   (1,-1)  \n",
    "  133    (1,0)   (0,0)   (1,1)   (0,0)   \n",
    "  134    (1,0)   (0,0)   (1,1)   (1,1)   \n",
    "  135    (1,0)   (0,0)   (1,1)   (1,0)   \n",
    "  136    (1,0)   (0,0)   (1,1)   (1,-1)  \n",
    "  137    (1,0)   (0,0)   (1,0)   (0,0)   \n",
    "  138    (1,0)   (0,0)   (1,0)   (1,1)   \n",
    "  139    (1,0)   (0,0)   (1,0)   (1,0)   \n",
    "  140    (1,0)   (0,0)   (1,0)   (1,-1)  \n",
    "  141    (1,0)   (0,0)   (1,-1)  (0,0)   \n",
    "  142    (1,0)   (0,0)   (1,-1)  (1,1)   \n",
    "  143    (1,0)   (0,0)   (1,-1)  (1,0)   \n",
    "  144    (1,0)   (0,0)   (1,-1)  (1,-1)  \n",
    "  145    (1,0)   (1,1)   (0,0)   (0,0)   \n",
    "  146    (1,0)   (1,1)   (0,0)   (1,1)   \n",
    "  147    (1,0)   (1,1)   (0,0)   (1,0)   \n",
    "  148    (1,0)   (1,1)   (0,0)   (1,-1)  \n",
    "  149    (1,0)   (1,1)   (1,1)   (0,0)   \n",
    "  150    (1,0)   (1,1)   (1,1)   (1,1)   \n",
    "  151    (1,0)   (1,1)   (1,1)   (1,0)   \n",
    "  152    (1,0)   (1,1)   (1,1)   (1,-1)  \n",
    "  153    (1,0)   (1,1)   (1,0)   (0,0)   \n",
    "  154    (1,0)   (1,1)   (1,0)   (1,1)   \n",
    "  155    (1,0)   (1,1)   (1,0)   (1,0)   \n",
    "  156    (1,0)   (1,1)   (1,0)   (1,-1)  \n",
    "  157    (1,0)   (1,1)   (1,-1)  (0,0)   \n",
    "  158    (1,0)   (1,1)   (1,-1)  (1,1)   \n",
    "  159    (1,0)   (1,1)   (1,-1)  (1,0)   \n",
    "  160    (1,0)   (1,1)   (1,-1)  (1,-1)  \n",
    "  161    (1,0)   (1,0)   (0,0)   (0,0)   \n",
    "  162    (1,0)   (1,0)   (0,0)   (1,1)   \n",
    "  163    (1,0)   (1,0)   (0,0)   (1,0)   \n",
    "  164    (1,0)   (1,0)   (0,0)   (1,-1)  \n",
    "  165    (1,0)   (1,0)   (1,1)   (0,0)   \n",
    "  166    (1,0)   (1,0)   (1,1)   (1,1)   \n",
    "  167    (1,0)   (1,0)   (1,1)   (1,0)   \n",
    "  168    (1,0)   (1,0)   (1,1)   (1,-1)  \n",
    "  169    (1,0)   (1,0)   (1,0)   (0,0)   \n",
    "  170    (1,0)   (1,0)   (1,0)   (1,1)   \n",
    "  171    (1,0)   (1,0)   (1,0)   (1,0)   \n",
    "  172    (1,0)   (1,0)   (1,0)   (1,-1)  \n",
    "  173    (1,0)   (1,0)   (1,-1)  (0,0)   \n",
    "  174    (1,0)   (1,0)   (1,-1)  (1,1)   \n",
    "  175    (1,0)   (1,0)   (1,-1)  (1,0)   \n",
    "  176    (1,0)   (1,0)   (1,-1)  (1,-1)  \n",
    "  177    (1,0)   (1,-1)  (0,0)   (0,0)   \n",
    "  178    (1,0)   (1,-1)  (0,0)   (1,1)   \n",
    "  179    (1,0)   (1,-1)  (0,0)   (1,0)   \n",
    "  180    (1,0)   (1,-1)  (0,0)   (1,-1)  \n",
    "  181    (1,0)   (1,-1)  (1,1)   (0,0)   \n",
    "  182    (1,0)   (1,-1)  (1,1)   (1,1)   \n",
    "  183    (1,0)   (1,-1)  (1,1)   (1,0)   \n",
    "  184    (1,0)   (1,-1)  (1,1)   (1,-1)  \n",
    "  185    (1,0)   (1,-1)  (1,0)   (0,0)   \n",
    "  186    (1,0)   (1,-1)  (1,0)   (1,1)   \n",
    "  187    (1,0)   (1,-1)  (1,0)   (1,0)   \n",
    "  188    (1,0)   (1,-1)  (1,0)   (1,-1)  \n",
    "  189    (1,0)   (1,-1)  (1,-1)  (0,0)   \n",
    "  190    (1,0)   (1,-1)  (1,-1)  (1,1)   \n",
    "  191    (1,0)   (1,-1)  (1,-1)  (1,0)   \n",
    "  192    (1,0)   (1,-1)  (1,-1)  (1,-1)  \n",
    "  193    (1,-1)  (0,0)   (0,0)   (0,0)   \n",
    "  194    (1,-1)  (0,0)   (0,0)   (1,1)   \n",
    "  195    (1,-1)  (0,0)   (0,0)   (1,0)   \n",
    "  196    (1,-1)  (0,0)   (0,0)   (1,-1)  \n",
    "  197    (1,-1)  (0,0)   (1,1)   (0,0)   \n",
    "  198    (1,-1)  (0,0)   (1,1)   (1,1)   \n",
    "  199    (1,-1)  (0,0)   (1,1)   (1,0)   \n",
    "  200    (1,-1)  (0,0)   (1,1)   (1,-1)  \n",
    "  201    (1,-1)  (0,0)   (1,0)   (0,0)   \n",
    "  202    (1,-1)  (0,0)   (1,0)   (1,1)   \n",
    "  203    (1,-1)  (0,0)   (1,0)   (1,0)   \n",
    "  204    (1,-1)  (0,0)   (1,0)   (1,-1)  \n",
    "  205    (1,-1)  (0,0)   (1,-1)  (0,0)   \n",
    "  206    (1,-1)  (0,0)   (1,-1)  (1,1)   \n",
    "  207    (1,-1)  (0,0)   (1,-1)  (1,0)   \n",
    "  208    (1,-1)  (0,0)   (1,-1)  (1,-1)  \n",
    "  209    (1,-1)  (1,1)   (0,0)   (0,0)   \n",
    "  210    (1,-1)  (1,1)   (0,0)   (1,1)   \n",
    "  211    (1,-1)  (1,1)   (0,0)   (1,0)   \n",
    "  212    (1,-1)  (1,1)   (0,0)   (1,-1)  \n",
    "  213    (1,-1)  (1,1)   (1,1)   (0,0)   \n",
    "  214    (1,-1)  (1,1)   (1,1)   (1,1)   \n",
    "  215    (1,-1)  (1,1)   (1,1)   (1,0)   \n",
    "  216    (1,-1)  (1,1)   (1,1)   (1,-1)  \n",
    "  217    (1,-1)  (1,1)   (1,0)   (0,0)   \n",
    "  218    (1,-1)  (1,1)   (1,0)   (1,1)   \n",
    "  219    (1,-1)  (1,1)   (1,0)   (1,0)   \n",
    "  220    (1,-1)  (1,1)   (1,0)   (1,-1)  \n",
    "  221    (1,-1)  (1,1)   (1,-1)  (0,0)   \n",
    "  222    (1,-1)  (1,1)   (1,-1)  (1,1)   \n",
    "  223    (1,-1)  (1,1)   (1,-1)  (1,0)   \n",
    "  224    (1,-1)  (1,1)   (1,-1)  (1,-1)  \n",
    "  225    (1,-1)  (1,0)   (0,0)   (0,0)   \n",
    "  226    (1,-1)  (1,0)   (0,0)   (1,1)   \n",
    "  227    (1,-1)  (1,0)   (0,0)   (1,0)   \n",
    "  228    (1,-1)  (1,0)   (0,0)   (1,-1)  \n",
    "  229    (1,-1)  (1,0)   (1,1)   (0,0)   \n",
    "  230    (1,-1)  (1,0)   (1,1)   (1,1)   \n",
    "  231    (1,-1)  (1,0)   (1,1)   (1,0)   \n",
    "  232    (1,-1)  (1,0)   (1,1)   (1,-1)  \n",
    "  233    (1,-1)  (1,0)   (1,0)   (0,0)   \n",
    "  234    (1,-1)  (1,0)   (1,0)   (1,1)   \n",
    "  235    (1,-1)  (1,0)   (1,0)   (1,0)   \n",
    "  236    (1,-1)  (1,0)   (1,0)   (1,-1)  \n",
    "  237    (1,-1)  (1,0)   (1,-1)  (0,0)   \n",
    "  238    (1,-1)  (1,0)   (1,-1)  (1,1)   \n",
    "  239    (1,-1)  (1,0)   (1,-1)  (1,0)   \n",
    "  240    (1,-1)  (1,0)   (1,-1)  (1,-1)  \n",
    "  241    (1,-1)  (1,-1)  (0,0)   (0,0)   \n",
    "  242    (1,-1)  (1,-1)  (0,0)   (1,1)   \n",
    "  243    (1,-1)  (1,-1)  (0,0)   (1,0)   \n",
    "  244    (1,-1)  (1,-1)  (0,0)   (1,-1)  \n",
    "  245    (1,-1)  (1,-1)  (1,1)   (0,0)   \n",
    "  246    (1,-1)  (1,-1)  (1,1)   (1,1)   \n",
    "  247    (1,-1)  (1,-1)  (1,1)   (1,0)   \n",
    "  248    (1,-1)  (1,-1)  (1,1)   (1,-1)  \n",
    "  249    (1,-1)  (1,-1)  (1,0)   (0,0)   \n",
    "  250    (1,-1)  (1,-1)  (1,0)   (1,1)   \n",
    "  251    (1,-1)  (1,-1)  (1,0)   (1,0)   \n",
    "  252    (1,-1)  (1,-1)  (1,0)   (1,-1)  \n",
    "  253    (1,-1)  (1,-1)  (1,-1)  (0,0)   \n",
    "  254    (1,-1)  (1,-1)  (1,-1)  (1,1)   \n",
    "  255    (1,-1)  (1,-1)  (1,-1)  (1,0)   \n",
    "  256    (1,-1)  (1,-1)  (1,-1)  (1,-1)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ala = read_spinach_info(text4)\n",
    "\n",
    "basis_ala = build_list_ISTs(data_ala)\n",
    "prefacts,Symb_ALA_basis = build_symbolic_list_ISTs(data_ala)\n",
    "\n",
    "#Normbasis = NormalizeBasis(basis,n_qubits=4,checkOrth=True) I have verified the orthonormalization of the basis\n",
    "Normbasis_ala = NormalizeBasis(basis_ala,n_qubits=4,checkOrth=False)\n",
    "Normbasis_ala = np.array(Normbasis_ala)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 1500\n",
    "B0 = 14.1\n",
    "zeeman_scalar_1 = 3.4938\n",
    "zeeman_scalar_2 = 1.7947\n",
    "zeeman_scalar_3 = 1.7947\n",
    "zeeman_scalar_4 = 1.7947\n",
    "zeeman_scalars = [zeeman_scalar_1,zeeman_scalar_2,zeeman_scalar_3,zeeman_scalar_4]\n",
    "\n",
    "\n",
    "#Jcoup = 238.0633\n",
    "\n",
    "Jcoups = np.zeros([4,4])\n",
    "#First, in Hz...\n",
    "Jcoups[0,1] = 3.82\n",
    "Jcoups[0,2] = 3.82\n",
    "Jcoups[0,3] = 3.82\n",
    "Jcoups[1,2] = -7.0\n",
    "Jcoups[1,3] = -7.0\n",
    "Jcoups[2,3] = -7.0\n",
    "\n",
    "gammaH = 2.6752e8\n",
    "\n",
    "\n",
    "H0_ala_ref = GenH0_Ham(offset,B0,zeeman_scalars,Jcoups,gammaH)\n",
    "\n",
    "\n",
    "#H0_dfg_frame =  HamMatRep(H0_Ham_dfg,Normbasis,n_qubits=2)\n",
    "\n",
    "#H0_dfg_frame =  HamMatRep(H0_Ham_dfg,Normbasis)\n",
    "#H0_ala_mat =  HamMatRep(H0_ala_ref,Normbasis_ala,n_qubits=4)\n",
    "\n",
    "\n",
    "####Construction of the jump operators...\n",
    "\n",
    "#List_ala_jumps = []\n",
    "\n",
    "#List_ala_jumps.append(1.44*MatRepLib(Normbasis_ala,Sz(0)*Sz(1),Sz(0)*Sz(1),n_qubits=4))\n",
    "#List_ala_jumps.append(1.39*MatRepLib(Normbasis_ala,Sz(1)*Sz(2),Sz(1)*Sz(2),n_qubits=4))\n",
    "#List_ala_jumps.append(1.37*MatRepLib(Normbasis_ala,Sz(0)*Sz(2),Sz(0)*Sz(2),n_qubits=4))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Saving the list of jump operators....\n",
    "#import pickle\n",
    "\n",
    "#Dict_jump = {'JOps':List_ala_jumps}\n",
    "\n",
    "#with open('./data/ALA_JOps.pk', 'wb') as handle:\n",
    "#    pickle.dump(Dict_jump, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.256"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tpts1*0.25e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.256/0.00512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadMat = spio.loadmat('./data/NOESYdata_ALA_withGradients.mat',squeeze_me=True)\n",
    "\n",
    "t_grid1 = loadMat['p']['time_grid1'].item()\n",
    "t_grid2 = loadMat['p']['time_grid2'].item()\n",
    "\n",
    "R_ala = loadMat['p']['R'].item()\n",
    "H_ala = loadMat['p']['H'].item().toarray()\n",
    "\n",
    "rho0 = np.array(loadMat['p']['rho0'].item().toarray())\n",
    "\n",
    "coil = np.array(loadMat['p']['coil'].item())\n",
    "\n",
    "Lx = loadMat['p']['Lx'].item().toarray() \n",
    "Ly = loadMat['p']['Ly'].item().toarray() \n",
    "\n",
    "###Dynamical evolution for calculation of 2D spectra...\n",
    "#Tpts1 = len(t_grid1)\n",
    "#Tpts2 = len(t_grid2)\n",
    "\n",
    "#Parameters taken from Spinach script\n",
    "tmix = 1.0\n",
    "#dt1 = 0.25e-3\n",
    "#dt2 = 0.25e-3\n",
    "dt1 = 0.00512\n",
    "dt2 = 0.00512\n",
    "Tpts1 = 50\n",
    "Tpts2 = 50\n",
    "\n",
    "##Parameters for Fourier transform\n",
    "zerofill1 = 4096\n",
    "zerofill2 = 4096\n",
    "\n",
    "#Defining the truncated version of the Relaxation matrix...\n",
    "R_trunc = np.copy(List_ala_jumps[0])\n",
    "\n",
    "R_trunc += List_ala_jumps[1]\n",
    "R_trunc += List_ala_jumps[2]\n",
    "\n",
    "\n",
    "\n",
    "#R_trunc is going to be the sum of the matrix representation of the three jump operators\n",
    "fid_1_ref, fid_2_ref, fid_3_ref, fid_4_ref =  GenFIDsignals(H_ala,R_trunc,Tpts1,Tpts2,rho0,coil,tmix,dt1,dt2,Lx,Ly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3= 27.21*np.array([[0.0027068883,-0.0019635208],[-0.0019635208,0.0027068883]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12708183, 0.02022703])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvals(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003927041528849687"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.12708183-0.02022703)/27.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 27.21*np.array([[0.0026801601,-0.0019902009],[-0.0019902009,0.0026801601]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12708052, 0.01877379])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvals(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "J12 = 27.21*(-0.0001385854-0.0000716364)\n",
    "J23 = 27.21*(0.0000729342+0.0000118255)\n",
    "J13 = 27.21*(0.0141751091+0.0148969739)\n",
    "\n",
    "test2 = J12*of.get_sparse_operator(Sz(0)*Sz(1)+Sy(0)*Sy(1)+Sx(0)*Sx(1),n_qubits=3)\n",
    "test2+= J23*of.get_sparse_operator(Sz(1)*Sz(2)+Sy(1)*Sy(2)+Sx(1)*Sx(2),n_qubits=3)\n",
    "test2+= J13*of.get_sparse_operator(Sz(0)*Sz(2)+Sy(0)*Sy(2)+Sx(0)*Sx(2),n_qubits=3)\n",
    "\n",
    "eigvals, eigvects =np.linalg.eig(test2.toarray())\n",
    "#of.eigenspectrum(Sz(0)*Sz(1)+Sy(0)*Sy(1)+Sx(0)*Sx(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.52450534+0.j,  0.26570782+0.j,  0.26828342+0.j, -0.52450534+0.j,\n",
       "        0.26828342+0.j,  0.26570782+0.j,  0.26570782+0.j,  0.26570782+0.j])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals+(-0.52450534+0.59330377)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.52450534,  0.25762079,  0.26688455])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####The tri-radical state:\n",
    "\n",
    "test_tri = 27.21*np.array([[0.0094728395,-0.0001385854,0.0000729342],\n",
    "                     [-0.0000716364,-0.0052157853,0.0141751091],\n",
    "                     [0.0000118255,0.0148969739,-0.0042570542]])\n",
    "\n",
    "np.linalg.eigvals(test_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.57287566+0.j,  0.07287566+0.j,  1.25      +0.j, -2.57287566+0.j,\n",
       "        1.25      +0.j,  0.07287566+0.j,  1.25      +0.j,  1.25      +0.j])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.        -0.j, -0.70710678-0.j,  0.70710678+0.j, -0.        -0.j])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvects[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25+0.j, -0.75+0.j,  0.25+0.j,  0.25+0.j])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between Trotterized and exact L_dt1:  0.0004972498640126282\n",
      "Difference between Trotterized and exact L_dt2:  0.0004972498640126282\n",
      "Number of Trotter steps for simulation of T1 1024\n",
      "Number of Trotter steps for simulation of T2 1024\n",
      "Number of Trotter steps for simulation of tmix 1000\n",
      "Difference between Trotterized pulse_mix and reference pulse_mix: 19.689629706283515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_8809/1472797926.py:105: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_1[j,i] = np.dot(coil,rho1)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_8809/1472797926.py:108: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_2[j,i] = np.dot(coil,rho2)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_8809/1472797926.py:111: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_3[j,i] = np.dot(coil,rho3)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_8809/1472797926.py:114: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_4[j,i] = np.dot(coil,rho4)\n"
     ]
    }
   ],
   "source": [
    "T1 = Tpts1*dt1\n",
    "T2 = Tpts2*dt2\n",
    "dtmix = 1e-3\n",
    "fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4 = GenFID_DetTrotsignals(H_ala,List_ala_jumps,T1,T2,rho0,coil,tmix,dt1,dt2,dtmix,Lx,Ly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('Ref_truncR_FID_ALA_cos.mat', {'FID_cos': fid_1_ref-fid_3_ref})\n",
    "savemat('Ref_truncR_FID_ALA_sin.mat', {'FID_sin': fid_2_ref-fid_4_ref})\n",
    "\n",
    "#savemat('Trot_truncR_FID_ALA_cos.mat', {'FID_cos': fid_temp_1-fid_temp_3})\n",
    "#savemat('Trot_truncR_FID_ALA_sin.mat', {'FID_sin': fid_temp_2-fid_temp_4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDrift implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QDrift implementation.\n",
    "\n",
    "def Samp_Gates(ListGates,List_weights,N):\n",
    "    #Return a QDrift product formula that simulates a target time T using N samples drawn from the probability distribution...\n",
    "\n",
    "    Gamma = np.sum(List_weights)\n",
    "    prob_dist = (1.0/Gamma)*np.array(List_weights)\n",
    "\n",
    "    #Draw a sample of size N for the implementation of the product formula...\n",
    "    values = np.arange(len(ListGates))\n",
    "    samples = np.random.choice(values, size=N, p=prob_dist)\n",
    "    \n",
    "    #print(\"Indixes of gates sampled:\",samples)\n",
    "    drawn_jumps = []\n",
    "    for i in range(len(samples)):\n",
    "        if samples[i]!=0:\n",
    "            drawn_jumps.append(samples[i])\n",
    "\n",
    "    print(\"Indices of jump operators drwan during construction of QDrift channel\", drawn_jumps)\n",
    "\n",
    "    ProdF = np.copy(ListGates[samples[0]])\n",
    "    for i in range(1,N):\n",
    "        ProdF=ListGates[samples[i]]@ProdF\n",
    "\n",
    "    return ProdF\n",
    "\n",
    "\n",
    "def Normalize_and_weightOps(ListOps):\n",
    "    \"\"\"\n",
    "    ListOps contains the generators of evolution, either the representation of the coherent part of evolution or the jump operators \n",
    "    \"\"\"\n",
    "    List_weights=[]\n",
    "\n",
    "    for i in range(len(ListOps)):\n",
    "        List_weights.append(np.max(np.abs(np.linalg.eigvals(ListOps[i]))))\n",
    "\n",
    "    #Normalize the operator according to the weights...\n",
    "    Norm_ops =[]\n",
    "\n",
    "    for i in range(len(ListOps)):\n",
    "        Norm_ops.append(ListOps[i]/List_weights[i])\n",
    "\n",
    "    return Norm_ops, List_weights\n",
    "\n",
    "\n",
    "def QDrift(H0,List_jumps,T,N):\n",
    "\n",
    "\n",
    "    Norm_ops, List_weights= Normalize_and_weightOps([H0]+List_jumps)\n",
    "\n",
    "    ###Definition of gates...\n",
    "    List_Gates = []\n",
    "\n",
    "    #for i in range(len(List_jumps)):\n",
    "    #    List_weights.append(rates[i])\n",
    "    Gamma = np.sum(np.array(List_weights))\n",
    "\n",
    "    deltaT = T*Gamma/N\n",
    "\n",
    "    #List_Gates.append(expm(-1j*H0*deltaT))\n",
    "\n",
    "    for i in range(len(Norm_ops)):\n",
    "        if i==0:###I assume that the first element of the operators correspond to H0!!!\n",
    "            List_Gates.append(expm(-1j*Norm_ops[i]*deltaT))\n",
    "        else:\n",
    "            List_Gates.append(expm(Norm_ops[i]*deltaT))\n",
    "        \n",
    "\n",
    "    ProdF = Samp_Gates(List_Gates,List_weights,N)\n",
    "\n",
    "    return ProdF\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Generation of QDrift-based NOESY spectrum..\n",
    "\n",
    "def GenFID_DetQDriftsignals(Ham,List_jumps,T1,T2,rho0,coil,tmix,dt1,dt2,Ntmix,Lx,Ly):\n",
    "    \"\"\"\n",
    "    Implement a first-order deterministic Trotter simulation of the FID NOESY signals, to numerically explore optimization of number of Trotter steps needed in the simulation\n",
    "    for a target precision\n",
    "    Args:\n",
    "    Ham: matrix representation of the \"coherent\" part of the Liouvillian siperoperator\n",
    "    List_jumps: list of the matrix representation of the jump operators\n",
    "    T1: maximal simulation time for the first phase of the protocol\n",
    "    T2: maximal simulation time for the second phase of the protocol\n",
    "    rho0: initial density matrix vector\n",
    "    coil: vector that represents the obervable we trace over to compute FID\n",
    "    Ntmix: number of samples to drawn in QDrift for the simulation of the system for tmix\n",
    "    \"\"\"\n",
    "\n",
    "    #This is the convention for our Trotter step: apply first the coherent part of the super-Liouvillian operator, followed by the jump operators in the order they appear in the array...\n",
    "\n",
    "    L_dt1 = expm(-1j*Ham*dt1)\n",
    "\n",
    "    for i in range(len(List_jumps)):\n",
    "        #print(\"Jump operator is\",List_jumps[i])\n",
    "        L_dt1 = expm(List_jumps[i]*dt1)@L_dt1\n",
    "\n",
    "    R = np.copy(List_jumps[0])\n",
    "    for i in range(len(List_jumps)-1):\n",
    "        R+=List_jumps[i]\n",
    "\n",
    "    print(\"Difference between Trotterized and exact L_dt1: \",np.linalg.norm(L_dt1-expm((-1j*Ham+R)*dt1)))\n",
    "\n",
    "    L_dt2 = expm(-1j*Ham*dt2)\n",
    "\n",
    "    for i in range(len(List_jumps)):\n",
    "        L_dt2 = expm(List_jumps[i]*dt2)@L_dt2\n",
    "\n",
    "    print(\"Difference between Trotterized and exact L_dt2: \",np.linalg.norm(L_dt2-expm((-1j*Ham+R)*dt2)))\n",
    "\n",
    "    #Dim = Ham.shape[0]\n",
    "    #Lnet = Ham+1j*R \n",
    "    #L_dt1 = expm(-1j*Lnet*dt1)\n",
    "    #L_dt2 = expm(-1j*Lnet*dt2)\n",
    "    #L_dtmix = expm(-1j*Ham*dtmix)\n",
    "\n",
    "    #for i in range(len(List_jumps)):\n",
    "    #    L_dtmix=expm(List_jumps[i]*dtmix)@L_dtmix\n",
    "\n",
    "\n",
    "    ###Number of Trotter steps for the simulation of the mixing free evolution...\n",
    "    #Ntmix = int(np.floor(tmix/dtmix))\n",
    "    #Number of Trotter steps for simulation of T1\n",
    "    Tpts1 = int(np.floor(T1/dt1))\n",
    "    Tpts2 = int(np.floor(T2/dt2))\n",
    "\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T1\",Tpts1)\n",
    "    print(\"Number of Trotter steps for deterministic simulation of T2\",Tpts2)\n",
    "    print(\"Number of Trotter steps for QDrift simulation of tmix\", Ntmix)\n",
    "    \n",
    "    pulse_mix = QDrift(Ham,List_jumps,tmix,Ntmix)\n",
    "    #for i in range(Ntmix):\n",
    "    #    pulse_mix = L_dtmix@pulse_mix\n",
    "\n",
    "    print(\"Difference between Trotterized pulse_mix and reference pulse_mix:\", np.linalg.norm(pulse_mix-expm((-1j*Ham+R)*tmix/Ntmix)))\n",
    "\n",
    "\n",
    "    pulse_90x = expm(-1j*Lx*np.pi/2)\n",
    "    pulse_90y = expm(-1j*Ly*np.pi/2)\n",
    "    pulse_90mx = expm(1j*Lx*np.pi/2)\n",
    "    pulse_90my = expm(1j*Ly*np.pi/2)\n",
    "\n",
    "    #First 90x pulse:\n",
    "    rho_t = np.copy(rho0)\n",
    "    rho_t = np.dot(pulse_90x,rho_t)\n",
    "\n",
    "    rho_stack = []\n",
    "    rho_stack.append(rho_t)\n",
    "\n",
    "    rho_temp = np.copy(rho_t)\n",
    "    for i in range(1,Tpts1):\n",
    "        rho_temp = np.dot(L_dt1,rho_temp)\n",
    "        rho_stack.append(rho_temp)\n",
    "\n",
    "\n",
    "    rho_stack1_1 = []\n",
    "    rho_stack1_2 = []\n",
    "    rho_stack1_3 = []\n",
    "    rho_stack1_4 = []\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho_stack1_1.append(pulse_90y@pulse_mix@pulse_90x@rho_stack[i])\n",
    "        rho_stack1_2.append(pulse_90y@pulse_mix@pulse_90y@rho_stack[i])\n",
    "        rho_stack1_3.append(pulse_90y@pulse_mix@pulse_90mx@rho_stack[i])\n",
    "        rho_stack1_4.append(pulse_90y@pulse_mix@pulse_90my@rho_stack[i])\n",
    "\n",
    "\n",
    "    fid_temp_1 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_2 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_3 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "    fid_temp_4 = np.zeros([Tpts2,Tpts1],dtype=complex)\n",
    "\n",
    "    for i in range(Tpts1):\n",
    "        rho1 = rho_stack1_1[i]\n",
    "        rho2 = rho_stack1_2[i]\n",
    "        rho3 = rho_stack1_3[i]\n",
    "        rho4 = rho_stack1_4[i]\n",
    "\n",
    "        for j in range(Tpts2):\n",
    "            fid_temp_1[j,i] = np.dot(coil,rho1)\n",
    "            rho1 = L_dt2@rho1\n",
    "\n",
    "            fid_temp_2[j,i] = np.dot(coil,rho2)\n",
    "            rho2 = L_dt2@rho2\n",
    "\n",
    "            fid_temp_3[j,i] = np.dot(coil,rho3)\n",
    "            rho3 = L_dt2@rho3\n",
    "\n",
    "            fid_temp_4[j,i] = np.dot(coil,rho4)\n",
    "            rho4 = L_dt2@rho4\n",
    "    \n",
    "    return fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.24288, 5.24288)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1*Tpts1,dt2*Tpts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00512"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".256/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between Trotterized and exact L_dt1:  0.010718667393298666\n",
      "Difference between Trotterized and exact L_dt2:  0.010718667393298666\n",
      "Number of Trotter steps for deterministic simulation of T1 50\n",
      "Number of Trotter steps for deterministic simulation of T2 50\n",
      "Number of Trotter steps for QDrift simulation of tmix 50\n",
      "Indices of jump operators drwan during construction of QDrift channel []\n",
      "Difference between Trotterized pulse_mix and reference pulse_mix: 22.415751301267022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_8809/424463602.py:107: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_1[j,i] = np.dot(coil,rho1)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_8809/424463602.py:110: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_2[j,i] = np.dot(coil,rho2)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_8809/424463602.py:113: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_3[j,i] = np.dot(coil,rho3)\n",
      "/var/folders/rm/xdxcjr7n7_13f9m1905zyf6c0000gq/T/ipykernel_8809/424463602.py:116: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  fid_temp_4[j,i] = np.dot(coil,rho4)\n"
     ]
    }
   ],
   "source": [
    "loadMat = spio.loadmat('./data/NOESYdata_ALA_withGradients.mat',squeeze_me=True)\n",
    "\n",
    "t_grid1 = loadMat['p']['time_grid1'].item()\n",
    "t_grid2 = loadMat['p']['time_grid2'].item()\n",
    "\n",
    "R_ala = loadMat['p']['R'].item()\n",
    "H_ala = loadMat['p']['H'].item().toarray()\n",
    "\n",
    "rho0 = np.array(loadMat['p']['rho0'].item().toarray())\n",
    "\n",
    "coil = np.array(loadMat['p']['coil'].item())\n",
    "\n",
    "Lx = loadMat['p']['Lx'].item().toarray() \n",
    "Ly = loadMat['p']['Ly'].item().toarray() \n",
    "\n",
    "###Dynamical evolution for calculation of 2D spectra...\n",
    "Tpts1 = len(t_grid1)\n",
    "Tpts2 = len(t_grid2)\n",
    "\n",
    "#Parameters taken from Spinach script\n",
    "tmix = 1.0\n",
    "#dt1 = 0.25e-3\n",
    "dt1 = 0.00512\n",
    "#dt2 = 0.25e-3\n",
    "dt2 = 0.00512\n",
    "\n",
    "##Parameters for Fourier transform\n",
    "zerofill1 = 4096\n",
    "zerofill2 = 4096\n",
    "\n",
    "#Defining the truncated version of the Relaxation matrix...\n",
    "#R_trunc = np.copy(List_ala_jumps[0])\n",
    "\n",
    "#R_trunc += List_ala_jumps[1]\n",
    "#R_trunc += List_ala_jumps[2]\n",
    "\n",
    "\n",
    "#fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4=GenFID_DetQDriftsignals(H_ala,List_ala_jumps,T1,T2,rho0,coil,tmix,dt1,dt2,2000,Lx,Ly)\n",
    "fid_temp_1, fid_temp_2, fid_temp_3, fid_temp_4=GenFID_DetQDriftsignals(H_ala,List_ala_jumps,T1,T2,rho0,coil,tmix,dt1,dt2,50,Lx,Ly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('QDrift_truncR_FID_ALA_cos.mat', {'FID_cos': fid_temp_1-fid_temp_3})\n",
    "savemat('QDrift_truncR_FID_ALA_sin.mat', {'FID_sin': fid_temp_2-fid_temp_4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        ...,\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j]]),\n",
       " array([[0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        ...,\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j]]),\n",
       " array([[0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        ...,\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, ..., 0.+0.j, 0.+0.j, 0.+0.j]])]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List_ala_jumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        +0.00000000e+00j,  0.        +0.00000000e+00j,\n",
       "         0.        +0.00000000e+00j, ...,  0.        +0.00000000e+00j,\n",
       "         0.        +0.00000000e+00j,  0.        +0.00000000e+00j],\n",
       "       [ 0.        +0.00000000e+00j, -0.31198002+4.34526476e-01j,\n",
       "         0.        +0.00000000e+00j, ...,  0.        +0.00000000e+00j,\n",
       "         0.        +0.00000000e+00j,  0.        +0.00000000e+00j],\n",
       "       [ 0.        +0.00000000e+00j,  0.        +0.00000000e+00j,\n",
       "         0.5564925 +9.77348966e-18j, ...,  0.        +0.00000000e+00j,\n",
       "         0.        +0.00000000e+00j,  0.        +0.00000000e+00j],\n",
       "       ...,\n",
       "       [ 0.        +0.00000000e+00j,  0.        +0.00000000e+00j,\n",
       "         0.        +0.00000000e+00j, ..., -0.07305135+5.50753289e-01j,\n",
       "         0.        +0.00000000e+00j,  0.        +0.00000000e+00j],\n",
       "       [ 0.        +0.00000000e+00j,  0.        +0.00000000e+00j,\n",
       "         0.        +0.00000000e+00j, ...,  0.        +0.00000000e+00j,\n",
       "         0.11078198-8.42101033e-02j,  0.        +0.00000000e+00j],\n",
       "       [ 0.        +0.00000000e+00j,  0.        +0.00000000e+00j,\n",
       "         0.        +0.00000000e+00j, ...,  0.        +0.00000000e+00j,\n",
       "         0.        +0.00000000e+00j, -0.91151645-4.11263611e-01j]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####We consider weights equivalent to the spectral norm of each of the operators...\n",
    "\n",
    "List_weights = []\n",
    "\n",
    "List_weights.append(np.max(np.abs(np.linalg.eigvals(H_ala))))\n",
    "\n",
    "for i in range(len(List_ala_jumps)):\n",
    "    List_weights.append(np.max(np.abs(np.linalg.eigvals(List_ala_jumps[i]))))\n",
    "\n",
    "###Renormalize the generators of evolution...\n",
    "H0_renorm = H_ala/List_weights[0]\n",
    "\n",
    "List_renorm_jumps = []\n",
    "\n",
    "for i in range(3):\n",
    "    List_renorm_jumps.append(List_ala_jumps[i]/List_weights[i+1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#QDrift(H0_renorm,List_renorm_jumps,List_weights,0.25,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indixes of gates sampled: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.681063691566985"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####Some numerical testing of the QDrift channel....\n",
    "T = 1.0\n",
    "\n",
    "np.linalg.norm(expm((-1j*H_ala+R_trunc)*T)-QDrift(H0_renorm,List_renorm_jumps,List_weights,T,100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indixes of gates sampled: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.9975486980419697"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(expm((-1j*H_ala)*T)-QDrift(H0_renorm,List_renorm_jumps,List_weights,T,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.985878157568836e-13"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(expm(-1j*H_ala*T)@rho0-expm(-1j*H0_renorm*np.sum(List_weights)*T)@rho0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000447965989938"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(List_weights)/List_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8675275638659836"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(expm((-1j*H_ala+R_trunc)*T)-expm(-1j*H_ala*T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11719.639700179749,\n",
       " 0.1800000000000003,\n",
       " 0.1737500000000001,\n",
       " 0.17125000000000018]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11719.639700179749,\n",
       " 0.1800000000000003,\n",
       " 0.1737500000000001,\n",
       " 0.17125000000000018]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.993760773198927"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(expm((-1j*H_ala+R_trunc)*T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1800000000000003"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(np.linalg.eigvals(List_ala_jumps[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BQSKit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
